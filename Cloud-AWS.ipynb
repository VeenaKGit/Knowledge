{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a AWS account:\n",
    "1. https://www.youtube.com/watch?v=gA9pl-A9gDM&list=PLIUhw5xEbE-UIt62T_qb8l-sf3eft5M4F\n",
    "    * username : veenakalburgi pp:\\*ice_****1 email:veena.kalburgi@gmail.com\n",
    "    * So sign in as Root user - these are the owner of the account. \n",
    "    \n",
    "2. Account is created with free tier:\n",
    "    * 12 months free limited usage.\n",
    "    * 1 lakh lambda service free\n",
    "    * 25GB of DynamoDB storage is free\n",
    "    * Always make sure to launch EC2 T2 micro instance which is free..\n",
    "    * More details - https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc\n",
    "    <img src=images/image138.png align='middle' style='width:600px; heigh:600px'/>\n",
    "3. I have setup the billing alarm - using AWS **CloudWatch** service. Go to **CloudWatch** service in AWS and you can create  billing for almost all the services you use.\n",
    "* https://www.youtube.com/watch?v=p3i4NSCVTT4&list=PLIUhw5xEbE-UIt62T_qb8l-sf3eft5M4F&index=4\n",
    "4. Creating IAM user:\n",
    "    * Its not a good practice to also use teh Root user to login, its better to have an IAM account for each user different permission. Root user is like the main Admin of the AWS account, who can terminate teh AWS users or the entire AWS account.\n",
    "    * Some services are specific to AWS Regions say once you create a IAM user, he/she has access to all AWS Region/global services. Those are called as **Global Services** ex are IMA, S3, Route53\n",
    "    <img src=images/image139.png align='middle' style='width:600px; heigh:600px'/>\n",
    "    * IAM allows you to securely access to AWS Services (here means say different AWS services like EC2, S3) and Resources(here means instances of EC2 service)\n",
    "    <img src=images/image140.png align='middle' style='width:600px; heigh:600px'/>\n",
    "    * How to create a IAM user - https://www.youtube.com/watch?v=qYelauL9s5Q&list=PLIUhw5xEbE-UIt62T_qb8l-sf3eft5M4F&index=5\n",
    "    * created IAM user :veena pp: same as rootpp\n",
    "    * access path : https://737131938691.signin.aws.amazon.com/console  -- 737131938691 veena - *ice_****1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Global Data Centers:\n",
    "https://www.youtube.com/watch?v=Z3SYDTMP3ME&list=PLTURy9xVU09lTSTjwvQaxfEtrJCLc1dhf&index=1&t=515s\n",
    "1. There are around 25+ Global regions (places where Amazon Data centers are located)\n",
    "2. Each Region will have 1 or 2 or 3 data centers called as Avalability Zones(AZ) where we can deploy over \n",
    "<img src=images/image124.png align='middle' style='width:500px; heigh:400px'/>\n",
    "3. https://www.infrastructure.aws/\n",
    "4. https://aws.amazon.com/about-aws/global-infrastructure/\n",
    "5. Edge Location - These are like Cache devices which hold content like media, video, pics which are most frequently accessed. These contents are held in Edge Locations are delivered to end user which help teh performance by lowering the network latency.\n",
    "6. AWS has around 130+ services.\n",
    "<img src=images/image125.png align='middle' style='width:500px; heigh:400px'/>\n",
    "7. As you can see above you can keep your program in mulyiple AZ's if one goes down their is a backup option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Services:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The AWS Account( you create one) its the top level entity. Once you have the account you can deploy your infrastructure into any of the AWS region.\n",
    "<img src=images/image126.png align='middle' style='width:500px; heigh:400px'/>\n",
    "2. AWS has different services and each service has its own scope. Like Billing, IAM(Identity and Access Management), Route53 is at Account level. Similarly S3, DynamoDB are at Region level, so when you create a S3 bucket you select which Region it in. Likewise, EC2, RDS, EBS are at AZ level, meaning one EC2 instance cannot be in two AZ's either it can be in AZ1 or AZ2 or AZ3.\n",
    "3. Different AWS services:\n",
    "<img src=images/image127.png align='middle' style='width:500px; heigh:400px'/>\n",
    "<img src=images/image128.png align='middle' style='width:500px; heigh:400px'/>\n",
    "<img src=images/image129.png align='middle' style='width:500px; heigh:400px'/>\n",
    "<img src=images/image130.png align='middle' style='width:500px; heigh:400px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional Vs AWS services for a Social Media Application (ex Fb.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional Way:\n",
    "1. We will require a company Private Network (every company has one) to work with (for security reasons).\n",
    "2. Then say we have a simple web application writen in PHP or Java we require say 1 or more of Web server to host our Web application\n",
    "    * Difference between web and application server - https://stackoverflow.com/questions/936197/what-is-the-difference-between-application-server-and-web-server#:~:text=The%20main%20difference%20between%20Web,e.g.%20JSP%2C%20Servlet%20or%20EJB.\n",
    "    * So say we have a web application server up and running. Clients are accesssing it using a IP address.\n",
    "    * Now we have more users and we want to add more logic like Business logic, User login and admin processing, adding Databases and handilng more logic etc. So here we will need application server to do this job.\n",
    "    * Below image is a **three teir web architecture**.\n",
    "    <img src=images/image131.png align='middle' style='width:200px; heigh:200px'/>\n",
    "3. Now your website having more users, so to handle the traffic you sclae your application: Either **vertically (increase the processing power of that one server you are having)** or **scale horizontally(have mutiple servers)**. Typically horizontal scaling is done- lets assume we go with this. since we now have multple IP address, we need something called **Load Balancer** to route the traffic to each server ex: **Haproxy, Nginx**. \n",
    "4. Also now that the website is gaining popularity you don't want to customers to access it using IP address so yuo want to provide a domain name say \"fb.com\", so we need **DNS(Domain Name Service)**.\n",
    "5. So now your website is growing more, you need NoSQL database(like MongoDB, Casandra) to store different data. Also the one relational database is causing a bottle neck (say with requent read operations). So you bring in **DB Cache** (these store frequently accessed data and reduce database queries) **ex: Redis.**\n",
    "<img src=images/image132.png align='middle' style='width:200px; heigh:200px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now say you are receiving lots of media files(pics videos) which you want to start storing. We never store media files on web server or application server. You can store images in databse but not preferred. The best place to store media files are **External Storage** like google drive. \n",
    "7. So say we integrate a external storage now. But before we store media we will have to do a **Content filtering** say for nudity etc etc. So we use some Content filtering service.\n",
    "8. So now our website has grown so much that, we are getting Advertisement calls. So based on customer searches or interests we want to create a login to display relevant Advs to them. So this is called as **Click Stream Analysis**. Clicks are tracked and data associated with each click of user is collected using some CSA Engine. To store this data we will need another external storage and further you want to take this data and do some processing (Cleaning,aggregations, data wrangling etc but not Analysing)on the data. For this you need **Hadoop/Spark** platform which work with large data in distributed system.\n",
    "    * https://logz.io/blog/hadoop-vs-spark/#:~:text=Spark%20has%20been%20found%20to,Naive%20Bayes%20and%20k%2Dmeans.\n",
    "    * **Apache Hadoop** is a collection of open-source software utilities that facilitates using a network of many computers to solve problems involving massive amounts of data and computation. It provides a software framework for **distributed storage and processing of big data using the MapReduce programming model**.\n",
    "9. Now you will start collecting data over time so that you can make some predictions or Analysis. For this you keep collecting Click Stream Analysis Data and store in what is called as **\"Data WareHouse\"**. DWH is where **Data Analysis/Reporting** is done called as **Business Intelligence** tools. \n",
    "<img src=images/image133.png align='middle' style='width:500px; heigh:400px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Now that our media is stored in a exernal storage, FB users can directly see the media using web browser from the storage. But for mobile users seeing the video probably we need to replicate the media storage with converted video.\n",
    "11. Say one video gets viral, you don't want all the million users hitting the external storage. SO we need something called **Content Delivery Network(CDN) Cache**.  So these will cache the viral video/media to the nearest cashing devices, so users in that zone can be servered from Cache than storage.\n",
    "12. So next upgrade for our application is **SMS Mobile Push Notifications** service that required these days for say updates, friends request. Also **Email services**, additional chatting service called **Message Queue**\n",
    "13. Now since our system is so big, we want to Monitor the Health of our services to see now different elements are doing. For this we use **Monitoring and Dashboard** services. And also some **ETL** Extract, Transfer and Load processing too.\n",
    "14. Below is our Final Architecture of our web application.\n",
    "<img src=images/image134.png align='middle' style='width:600px; heigh:600px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with AWS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In AWS, the private network is called **VPC - Virtual Private Cloud**\n",
    "2. The VM are now the **EC2** Machines and the on device disk are now the **EBS - Elastic Block Storage** where we deploy our web sever or application server. Alos you can enable **auto-scaling** on AWS, which scales EC2 horizontally if the load increases or they scale down as well.\n",
    "3. For relational DB AWS offers **RDS-Relational Database Services** and for NoSQL it offers **DynamoDB** and for DBCache there is **ElastiCache service** with AWS - which comes with **Redis and Memchahed** in that.\n",
    "4. FOR Load balancer AWS provides **ELS-Elastic Load Balancer** service and DNS service of AWS is called **route53**\n",
    "5. For External Storage AWS provide **S3 buckets** service and **Rekognition** filters your data. And AWS provides **Lambda** services to run tasks like Video converting from one format to another.\n",
    "6. To convert video from say MP4 format to MP3(for mobile user) format, either you can write code in your EC2's to keep watching  when new videos come to Externa Storage(Red dot bucket in above image) and convert to MP3format(for mobile user) and save it in another storage(greed dot). Or its better to use the **Lambda** AWS service which is a **serverless** service from AWS which can run your small code to watch for left S3 bucket(if it recieves a new video) convert and save to new format in right bucket.\n",
    "7. For click stream analysis AWS provides **Kinesis** Services\n",
    "8. For ETL operations AWS provide **Glue** services and for Spark/Hadoop platform AWS provide **EMR** service. EMR does operations like aggregation, sorting and distributedjobs\n",
    "9. For doing BI task AWS provide **QucikSight** which is for reporting and **Athena** which is basically gives interface for SQL queries.\n",
    "10. For CDN Caches AWS uses something called as **CloudFront which caches data in Edge Location**\n",
    "11. For SMS/Push Notification AWS provides a service called as **SNS-Simple Notification Service**. Similarly for emails it has **SES-Simple EMail Service** and for Messaeg Queue it has **SQS - Simple Queue Service**.\n",
    "12. FOr health monitoring AWS provide **CloudWatch**, with alarm for alerts.\n",
    "<img src=images/image135.png align='middle' style='width:600px; heigh:600px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Other Services :\n",
    "1. Most large web applications exposes all their services using REST API for the third party application to integrate with the web application. Basically AWS provide a service called **API Gateway**, so write your API code and deploy in API gateway, the API gateway service will take care of any scaling, security etc. For user management service to your API's AWS provide a service called **Cognito**\n",
    "2. For data transfer between services say (EC2 to S3) permission, authenticity needs to be defined. All the accounts, permissions and access management is done through the **IAM - Identity Access Management** service of AWS.\n",
    "3. For security you can encript the data at differet level say at EC2, S3,  etc using **KMS - Key Management Service** service.\n",
    "4. Other AWS services are\n",
    "    * WAF - Web Application Firewall\n",
    "    * ACM - Amazon Certificate Manager\n",
    "    * Inspector - To identify vulerability\n",
    "    <img src=images/image136.png align='middle' style='width:600px; heigh:600px'/>\n",
    "5. AWS DevOps services:\n",
    "    * There are different services offered by AWS. Think you will have to deploy alll of this by hand, thats too much overhead so AWS provides DevOps services, where you can code all this different deployemnts and monitor. This is called as **Infrastructure as a Code**.\n",
    "    * **CloudFormation** -This is AWS's Infrastructure as a Code service. This takes a template in the form of json or YML file and it will create the whole infrastructure for you with in 30 mins. Its very powerful service.\n",
    "    * Then for maintaining code AWS gives **CodeCommit** service where you check in your code. Probably codeCommit is a wrap around git.\n",
    "    * To build your code at the production level you need **CodeBuild** service which AWS offers. Then to deploy to different buckets say EC2 you need **CodeDeploy** service.\n",
    "    * Now say you pretty much change your code every week, so you want to automate the method of code build, code test code deploy which is called as CI/CD pipeline. FOr that AWS provides **CodePipeline** service.\n",
    "    * NOw if you want say start tracking your developemnt progress or start tracking issues say with Jira. AWS provide **Code Star - PM Issue tracking Continuous Delivery** service which integrated with Jira.\n",
    "    <img src=images/image137.png align='middle' style='width:600px; heigh:600px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EC2 :\n",
    "- Udemy - https://www.udemy.com/course/amazon-web-services-aws/learn/lecture/5833230#overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. As we know we have Multiple AZ's(2 or 3 or upto6 these days) in each region. We can launch our web server in 1 AZ or multiple AZ for redundency. Say like this, so in case Master fails we can switch to slave.\n",
    "<img src=images/image141.png align='middle' style='width:400px; heigh:400px'/>\n",
    "2. **Elastic Compute Cloud** - These are Virtual Server like VM in AWS cloud used to deploy application.\n",
    "    * What is VM/Virtual Server - https://www.youtube.com/watch?v=wAsWnP4T7v8 @2:07\n",
    "    <img src=images/image142.png align='middle' style='width:400px; heigh:400px'/>\n",
    "3. EC2 Components: \n",
    "    * **AMI - Amazon Machine Image** - this is the operating system image for your EC2/VM. Lots of base AMI's like Windows AMI, LINUX AMI are laready provided by Amazon, but you can buy and use third party AMI too.\n",
    "    * **Instance Type(CPU and Memeory)** - AWS provide more than 400 instance type. Use T2 Micro for free tier\n",
    "    * **Elastic Block Storage(Disk)** - AWS provides options like SSD's or HDD's\n",
    "    * **Key Pair(SSH)** - For authenticating users who log into this EC2's\n",
    "    * **IP Address(Private/Public/Elastic)** - \n",
    "    * **Security Group(Firewall)** - You need to create a security group and open port 22 to connect via SSH.\n",
    "    * **Tags** - You can provide Tags to your EC2 instance like name, owner, dat created, last updated, dev or Pro etc.\n",
    "6. **SSH - Secure Shell** mostly in Linux world\n",
    "    * SSH is a network communication protocol that enables two computer(client - server) to communicate and share data.\n",
    "    * You can SSH into a remote server like (>> ssh veenak@192.168.56.100) which will require you to authenticate using password\n",
    "    * Another better way is you can SSH using key based authentication. Where the private key is present in your host machine in /.ssh and another public key is placed in the remote server, which you want to connect to.\n",
    "    * If your workstation(your laptop) is Linux you can use **pem file** and if **Windows** you can use **ppk file** to connect to your EC2 instance.\n",
    "    * https://www.youtube.com/watch?v=S7jD6nnYJy0 - setting VM and SSH using passowrd\n",
    "    * https://www.youtube.com/watch?v=vpk_1gldOAE - SSH using key based authentication.\n",
    "    * Port 22 is reserved for SSH on Linux. \n",
    "    * https://en.wikipedia.org/wiki/SSH_(Secure_Shell)#:~:text=The%20protocol%20specification%20distinguishes%20between,be%20used%20on%20Microsoft%20Windows.\n",
    "4. **TCP vs HTTP**: \n",
    "    * https://en.wikipedia.org/wiki/Port_(computer_networking)\n",
    "    * Every computer on the Internet is identified by a unique, 4-byte(32 bit) IP address . This is typically written in dotted quad format like 128.250.25.158 where each byte is an unsigned value between 0 and 255.This representation is not user friendly i.e user cannot remember it hence IP addressed are mapped to names like www.google.com. These mapping are maintained by Domain Name System(DNS).\n",
    "    * Present day, Internet is widely implemented using IPv4(32 bit IP address). Because of shortage of address spaces, it is gradually migrating from IPv4 to IPv6(128 bit IP address).\n",
    "    * However, computers often need to communicate and provide more than one type of service or to talk to multiple hosts/computers at a time. For example, there may be multiple ftp sessions, web connections, and chat programs all running at the same time. To distinguish these services, a concept of **ports**, a logical access point, represented by a **16-bit integer** number is used. Each Internet packet contains both the destination **host address** and the **port number** on that host to which the message/request has to be delivered. The host computer dispatches the packets it receives to programs by looking at the port numbers specified within the packets.\n",
    "    * Basically out of 0-2^16 ports, there are some ports reserved for specific use at the system level. Those are below.\n",
    "    * <img src=images/image150.png align='middle' style='width:600px; heigh:500px'/>\n",
    "\n",
    "5. Process to launch EC2:\n",
    "<img src=images/image143.png align='middle' style='width:600px; heigh:500px'/>\n",
    "<img src=images/image144.png align='middle' style='width:600px; heigh:500px'/>\n",
    "5. Launch a EC2 instance with Linux AMI - https://www.youtube.com/watch?v=wAsWnP4T7v8\n",
    "    * Video will show you how to setupu EC2, access it from your workbench, then install a web server - httpd and run a hello.html through it.\n",
    "6. Launch EC2 insrance with WIndows AMI - https://www.youtube.com/watch?v=SBf4n8ryLnQ\n",
    "<img src=images/image145.png align='middle' style='width:600px; heigh:500px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker - https://www.youtube.com/watch?v=iqqDU2crIEQ&feature=emb_logo:\n",
    "1. Why docker ? Ship software faster --> Standardize Operations --> Seamlessly move --> Save Money\n",
    "1. **Dockerfile** : Dockerfile is basically a specification of bunch of things you need to run your application.\n",
    "2. **Docker image** : An image is a read-only template with instructions for creating a Docker container.You might create your own images or you might only use those created by others and published in a registry. To build your own image, you create a Dockerfile with a simple syntax for defining the steps needed to create the image and run it. Each instruction in a Dockerfile creates a layer in the image. When you change the Dockerfile and rebuild the image, only those layers which have changed are rebuilt. This is part of what makes images so lightweight, small, and fast, when compared to other virtualization technologies.\n",
    "2. Steps: Steps to work with docker:\n",
    "    * Create a dockerfile and write your setup code.\n",
    "    * **docker build --tag hello-world docker_folder_path**  --> Using docker CLI build the image. use '.(dot)' is for current working directory.\n",
    "    * with CLI you can run, start, stop, remove check all the images, running images, check the logs etc.\n",
    "3. **Docker Hub** - docker hub is a image repository where your all your docker images can live.It has some auto build capabilities, CICD capabilities. You can setup teams and rules based access control. You can sign up at the dockerhub to start using it.\n",
    "    * You can create a repository optionally link it to your github or bitbucket\n",
    "    * Add push your local docker image to the hub using - docker push pmckee/hello-world\n",
    "    * We can then use this latest docker push and use it in CICD\n",
    "    * Or we can share the image in dockerhub with our team memebers.\n",
    "    * Similarly we can do - docker pull docker-name to pull a docker from hub to local. \n",
    "4. The above steps are good if we have only one microservices. Assume we have serral microservices. Its little tedious to run and maintain so many docker images. Docker provides another tool called **docker compose**.\n",
    "5. **Docker Compose** : Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a **YAML** file to configure your applicationâ€™s services. Then, with a single command, you create and start all the services from your configuration. You have to install it first.\n",
    "4. **Docker Container** : A container is a runnable instance of an image. You can create, start, stop, move, or delete a container using the Docker API or CLI. You can connect a container to one or more networks, attach storage to it, or even create a new image based on its current state.\n",
    "5. https://stackoverflow.com/questions/23735149/what-is-the-difference-between-a-docker-image-and-a-container - An instance of an image is called a container. You have an image, which is a set of layers as you describe. If you start this image, you have a running container of this image. You can have many running containers of the same image. You can see all your images with docker images whereas you can see your running containers with docker ps (and you can see all containers with docker ps -a).\n",
    "6. https://blog.octo.com/en/docker-registry-first-steps/\n",
    "7. **Docker Registry vs Docker Repository** :\n",
    "    * Docker Registry - Docker registry is a service that is storing your docker images. Ex: DockerHub, Google Container Registry, AWS Elastic Contianer Registry etc. This can be imagined like Github, bitbucket etc...\n",
    "    * Docker Repository - Docker repository is a collection of different docker images with same name, that have different tags. This can be imagined like different git repositories or one git repo with differetn tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Container Registry - ECR\n",
    "1. ECR is a docker registry service provided by AWS. You can create a new Repository in the ECR, push your docker image to the AWS ECR repo to store and manage your docker images.\n",
    "2. <img src=images/image148.png align='middle' style='width:600px; heigh:500px'/>\n",
    "3. https://www.youtube.com/watch?v=zs3tyVgiBQQ --> simple example\n",
    "4. https://aws.amazon.com/ecr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Contianer Service - ECS\n",
    "1. https://aws.amazon.com/ecs/\n",
    "2. Amazon Elastic Container Service (Amazon ECS) is a fully managed container orchestration service.Its a great choice to run containers.\n",
    "3. You can run your ECS cluster (docker image) using AWS Fargate (which is serverless compute service for containers) or EC2 or Lambda also not sure.\n",
    "4. <img src=images/image149.png align='middle' style='width:600px; heigh:500px'/>\n",
    "5. <img src=images/image146.png align='middle' style='width:400px; heigh:400px'/>\n",
    "6. https://logz.io/blog/aws-eks-vs-ecs-vs-fargate-understand-differences/\n",
    "7. https://www.youtube.com/watch?v=zs3tyVgiBQQ - SImple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Gateway:\n",
    "1. https://www.youtube.com/watch?v=uFsaiEhr1zs --> This video will show you how to create a Restful API endpoint using APIGateway that would involve a Lambda function which returns a JSON response all the way back to the client.\n",
    "<img src=images/image147.png align='middle' style='width:400px; heigh:400px'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
