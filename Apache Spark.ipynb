{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Spark \n",
    "* https://www.youtube.com/watch?v=cYL42BBL3Fo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course: Big Data Analytics using Spark\n",
    "* Course-->Introduction and Course Information-->Installing Software for the course and online workbench tutorial-->Software Installation Directions\n",
    "* The above course path will give you steps to install spark using Docker\n",
    "* Docker - Docker is a set of platform as a service products that uses OS-level virtualization to deliver software in packages called containers. Containers are isolated from one another and bundle their own software, libraries and configuration files; they can communicate with each other through well-defined channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage Latency:\n",
    "1. General computation latency for a multiplication involves, moving A and B from memory to regists in CPU. Then pereforming computation, then moving back the result to memory.  \n",
    "<img src=\"images/image41.png\" align=\"middle\" style=\"width:200p ;height:200px\" />  \n",
    "2. In analyzing Big Data the latency of read and write operations dominate the computational latecy.\n",
    "3. Different types of storage offer different latency, capacity and price.\n",
    "4. Big data analytics revolves around methods for organising storage and computation in ways that maximize speed while minimizing cost.\n",
    "5. Depending upon budget we have to trade between small-fast memory and large-slow memory. Another option is using Cache. \n",
    "<img src=\"images/image42.png\" align=\"middle\" style=\"width:200p ;height:200px\" /> \n",
    "6. Every time a CPU looks for a memory location ex. 67 and its found in Cache then its a Cache hit and if CPU looks for a value which is not in Cache its a Cache miss(because it involves additional work of emptying cache space and getting the value from memory into cache). We need Cache hit rate to be high.\n",
    "7. Temporal locality: Multiple accesses to same address within a short time period.\n",
    "8. Spatial localoty: Multiple accesses to close-together(blocks) addresses in short time period. Since memory is parttioned into blocks/lines than single bytes. Transfering blocks is faster than chuck of data in different locations. And memory locations close to each other are more likely to fall in the same block and thus increase the hit rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
