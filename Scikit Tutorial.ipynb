{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To install jupyter extensions:\n",
    "* Extensions are like add-ons can make your work on notebooks significantly easier. Follow the steps in below link.\n",
    "* https://github.com/Jupyter-contrib/jupyter_nbextensions_configurator\n",
    "* Hit Tab after . to see all the functions like np. TAB\n",
    "* Hit Shift+Tab after ( opening bracket to see function definition. Like pd.read_csv(  SHIFT+TAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbs\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn import datasets, tree\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold, ShuffleSplit,cross_validate, \\\n",
    "cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, adjusted_rand_score, mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets use the Titanic dataset where ever applicable \n",
    "tnic_df = pd.read_csv('data/titanic_kaggle_dataset.csv', header=0, dtype={'Age':np.float64})\n",
    "tnic_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning:\n",
    "\n",
    "1. Machine learning is a subset of Artificial Intelligence(AI), which provides machines the ability to learn automatically and improve from experience without being explicitly programmed. \n",
    "2. Applying ML techniques to dig into large amounts of data can help discover patterns that were not immediately apparent. This is called __data mining__.\n",
    "3. Types of Machine Learning Systems:\n",
    "    * __Supervised, Unsupervised, Semi-supervised and Reinforcement Learning__\n",
    "    * __Online Vs Batch Learning__\n",
    "    * __Instance-based vs Model-base learning__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised vs Unsupervised SemiSupervised vs Reinforcement Learning:\n",
    "1. __Supervised__: We give the machine Labelled data and teach them this is what is the output.\n",
    "2. __Unsupervised__: Data provided is not labelled and machine has to learn without any supervision. It has to discover hidden pattern and discover the data. Ex photo-hosting services, such as Google Photos, are good examples of this. Once you upload all your family photos to the service, it automatically recognizes that the same person A shows up in photos 1, 5, and 11, while another person B shows up in photos 2, 5, and 7. This is the unsupervised part of the algorithm (clustering).Now all the system needs is for you to tell it who these people are. Just one label per person,4 and it is able to name everyone in every photo, which is useful for searching photos.\n",
    "3. __Semi-Supervised__: Some algorithms can deal with partially labeled training data, usually a lot of unlabeled data and a little bit of labeled data. This is called semisupervised learning.\n",
    "3. __Reinforcement__: Here the machine is put in an unknown environment and it has to learn by itself based on trial and error.For example, many robots implement Reinforcement Learning algorithms to learn how to walk.\n",
    "<img src='images/image95.png' style='width:500px;height:400px' />\n",
    "<img src='images/image96.png' style='width:500px;height:400px' />\n",
    "4. Here in Unsupervised learning the machine learns by itself to classify the different animals that we feed as belonging to either of the two types by studying the animals features that we feed. Of course it will not know that the animals it categorised on left is known as dogs and the right is known as cats. But it learns by itself how cats look and how dogs look and group the fed data  into specific groups.\n",
    "<img src='images/image97.png' style='width:500px;height:400px' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised:\n",
    "1. __Classification Algorithms__: Classification Algorithms could be broadly classified as the following:\n",
    "    * https://analyticsindiamag.com/7-types-classification-algorithms/\n",
    "    * https://dzone.com/articles/introduction-to-classification-algorithms\n",
    "    * Linear Classifiers\n",
    "        * Logistic regression\n",
    "        * Naive Bayes classifier\n",
    "        * Fisher’s linear discriminant\n",
    "    * Support vector machines\n",
    "        * Least squares support vector machines\n",
    "    * Quadratic classifiers\n",
    "    * Kernel estimation\n",
    "        * k-nearest neighbor\n",
    "    * Decision trees\n",
    "        * Random forests\n",
    "    * Neural networks\n",
    "    * Learning vector quantization\n",
    "2. __Regression Algorithms__: \n",
    "    * Simple Linear Regression model8\n",
    "    * Lasso Regression\n",
    "    * Logistic regression\n",
    "    * Support Vector Machines\n",
    "    * Multivariate Regression algorithm\n",
    "    * Multiple Regression Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Algorithms\n",
    "*https://www.newtechdojo.com/list-machine-learning-algorithms/\n",
    "1. __Clustering__: You may want to run a clustering algorithm to try to detect groups of similar visitors. Ex say you want to cluster your blog's visitors and have lot of data about your blog’s visitors.\n",
    "    * K-means\n",
    "    * C-means\n",
    "    * Hierarchical Cluster Analysis (HCA)\n",
    "    * mixture models\n",
    "    * DBSCAN\n",
    "2. __Association__:  association rule learning, in which the goal is to dig into large amounts of data and discover interesting relations between attributes. Ex you may want to run a Association on your sales logs Shopping mall sales logs \n",
    "    * Apriori algorithms for assiciation rule\n",
    "    * Eclat\n",
    "2. __Anomaly detection and novelty detection__: __anomaly detection__—for example, detecting unusual credit card transactions to prevent fraud, catching manufacturing defects, or automatically removing outliers from a dataset before feeding it to another learning algorithm. A very similar task is __novelty detection__: the difference is that novelty detection algorithms expect to see only normal data during training, while anomaly detection algorithms are usually more tolerant, they can often perform well even with a small percentage of outliers in the training set.  \n",
    "    * One-Class SVM\n",
    "    * Isolation Forest\n",
    "4. __Visualization and dimensionality reduction__: __Visualization algorithms__ are also good examples of unsupervised learning algorithms: you feed them a lot of complex and unlabeled data, and they output a 2D or 3D representation of your data that can easily be plotted. A related task is __dimensionality reduction__, in which the goal is to simplify the data without losing too much information.  One way to do this is to merge several correlated features into one. For example, a car’s mileage may be very correlated with its age, so the dimensionality reduction algorithm will merge them into one feature that represents the car’s wear and tear. This is called __feature extraction__.\n",
    "    * Principle Component analysis(PCA)\n",
    "    * Kernel PCA\n",
    "    * Locally-Linear Embedding (LLE)b\n",
    "    * t-distributed Stochastic Neighbor Embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Vs Online Laerning:\n",
    "1. Another criterion used to classify Machine Learning systems is whether or not the system can learn incrementally from a stream of incoming data.\n",
    "2. __Batch Learning__ :First the system is trained, and then it is launched into production and runs without learning anymore; it just applies what it has learned. This is called __offline learning__. If you want a batch learning system to know about new data (such as a new type of spam), you need to train a new version of the system from scratch on the full dataset (not just the new data, but also the old data), then stop the old system and replace it with the new one. Fortunately, the whole process of training, evaluating, and launching a Machine Learning system can be automated fairly easily.\n",
    "3. This solution is simple and often works fine, but training using the full set of data can take many hours, so you would typically train a new system only every 24 hours or even just weekly. If your system needs to adapt to rapidly changing data (e.g., to predict stock prices), then you need a more reactive solution. If your resources are limited then you better go for Online Learning.\n",
    "5. __Linear Least Square__ is a Batch learning AL.\n",
    "4. __Online/Incremental Learning__: In online learning, you train the system incrementally by feeding it data instances sequentially, either individually or by small groups called mini-batches. Each learning step is fast and cheap, so the system can learn about new data on the fly, as it arrives. Online learning is great for systems that receive data as a continuous flow (e.g., stock prices) and need to adapt to change rapidly or autonomously.\n",
    "5. One important parameter of online learning systems is how fast they should adapt to changing data: this is called the learning rate. If you set a high learning rate, then your system will rapidly adapt to new data, but it will also tend to quickly forget the old data. Same is other way around.\n",
    "6. A big challenge with online learning is that if bad data is fed to the system, the system’s performance will gradually decline. To reduce this risk, you need to monitor your system closely and promptly switch learning off (and possibly revert to a previously working state) if you detect a drop in performance. You may also want to monitor the input data and react to abnormal data (e.g., using an anomaly detection algorithm).\n",
    "7. __Recursive Least Squares (RLS)__ algorithm is a Online Learning AL.\n",
    "8. https://en.wikipedia.org/wiki/Online_machine_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance Vs Model based Learning:\n",
    "1. Generalization — usually refers to a ML model’s ability to perform well on new unseen data rather than just the data that it was trained on.\n",
    "2. One more way to categorize Machine Learning systems is by how they generalize. Most Machine Learning tasks are about making predictions. This means that given a number of training examples, the system needs to be able to generalize to examples it has never seen before. Having a good performance measure on the training data is good, but insufficient; the true goal is to perform well on new instances There are two main approaches to generalization: __instance-based learning and model-based learning.__\n",
    "2. __Insatance based__ : sometimes called memory-based learning is a family of learning algorithms that, instead of performing explicit generalization, compares new problem instances with instances seen in training, which have been stored in memory. Ex: Decision Tree, \n",
    "3.  Instance-based learning: the system learns the examples by heart, then generalizes to new cases by comparing them to the learned examples (or a subset of them), using a similarity measure. For example: Instead of just flagging emails that are identical to known spam emails, your spam filter could be programmed to also flag emails that are very similar to known spam emails. This requires a measure of similarity between two emails. A (very basic) similarity measure between two emails could be to count the number of words they have in common. The system would flag an email as spam if it has many words in common with a known spam email. This is called Instanced based learning.\n",
    "3. __Model based__ : Another way to generalize from a set of examples is to build a model of these examples, then use that model to make predictions. This is called model-based learning. Ex: All Rregression ALs.\n",
    "4. In a ML project you gather data in a training set, and you feed the training set to a learning algorithm. If the algorithm is model-based it tunes some parameters to fit the model to the training set (i.e., to make good predictions on the training set itself), and then hopefully it will be able to make good predictions on new cases as well. If the algorithm is instance-based, it just learns the examples by heart and generalizes to new instances by comparing them to the learned instances using a similarity measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "1. Feature engineering is the addition and construction of additional variables, or features, to your dataset to improve machine learning model performance and accuracy. The most effective feature engineering is based on sound knowledge of the business problem and your available data sources.\n",
    "2. As the saying goes: garbage in, garbage out. Your system will only be capable of learning if the training data contains enough relevant features and not too many irrelevant ones. A critical part of the success of a Machine Learning project is coming up with a good set of features to train on. This process, called feature engineering, involves:\n",
    "    * __Feature Selection__ : selecting the most useful feature.\n",
    "    * __Feature Extraction__ : combining existing features to produce a more useful one (as we saw earlier, dimensionality reduction algorithms can help).\n",
    "    * Creating new feature by gathering new data.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of ALs:\n",
    "1. The only way to know how well a model will generalize to new cases is to actually try it out on new cases. Thats done by dividing the traings set into train and test sets. The error rate on new cases is called the __generalization error__ (or out of __sample error__), and by evaluating your model on the test set, you get an estimate of this error. This value tells you how well your model will perform on instances it has never seen before.\n",
    "10. Accuracy scores cannot be used for regression, its is basically meant for classification. We have 'Mean Squared Error' for regression.\n",
    "12. Reference\n",
    "    * https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    * https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn Preprocessing data\n",
    "* https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "* __Standardization__ of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "* For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might __dominate__ the objective function and make the estimator unable to learn from other features correctly as expected.\n",
    "* Normalization Vs Standardization:\n",
    "    * https://stats.stackexchange.com/questions/10289/whats-the-difference-between-normalization-and-standardization\n",
    "    * Normalization rescales the values into a range of [0,1]. This might be useful in some cases where all parameters need to have the same positive scale. However, the outliers from the data set are lost.\n",
    "        Xchanged = (X−Xmin) / (Xmax−Xmin)\n",
    "    * Standardization rescales data to have a mean (μ) of 0 and standard deviation (σ) of 1 (unit variance).\n",
    "\n",
    "        Xchanged = X−Mean(μ) / Std Deviation(σ)\n",
    "    For most applications standardization is recommended. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.preprocessing.scale\n",
    "* sklearn.preprocessing.scale(X, axis=0, with_mean=True, with_std=True, copy=True) --> This will __Standardize__ (Mean = 0 and unit variance) a dataset along any axis\n",
    "* The function scale provides a quick and easy way to perform this operation on a single array-like dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "Sample_train = np.array([[1,2,3],[4,5,6],[1,2,3]])\n",
    "Sample_scale = scale(Sample_train)\n",
    "print(Sample_scale.mean(axis = 0)) # axis = 0 because standardization happen on each col/feature.\n",
    "print(Sample_scale.std(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.preprocessing.StandardScaler\n",
    "* sklearn.preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True) --> Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Mean and standard deviation are then stored to be used on later data using transform..\n",
    "* This class has the following methods:  \n",
    "<img src=\"images/image5.png\" align=\"middle\" style=\"width:400px; height:200px\" />  \n",
    "* Difference between scale and standardScaler\n",
    "    Those are doing exactly the same, but:\n",
    "    preprocessing.scale(x) is just a function, which transforms some data\n",
    "    to Standrd data. StandardScaler() is a class supporting the Transformer API\n",
    "    I would always use the latter, even if i would not need inverse_transform and co. supported by StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [1 2 3]]\n",
      "[[1 1 1]\n",
      " [2 2 2]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "sample_train = np.array([[1,2,3],[4,5,6],[1,2,3]])\n",
    "sample_test = np.array([[1,1,1],[2,2,2],[3,3,3]])\n",
    "print(sample_train)\n",
    "print(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70710678 -0.70710678 -0.70710678]\n",
      " [ 1.41421356  1.41421356  1.41421356]\n",
      " [-0.70710678 -0.70710678 -0.70710678]]\n",
      "*** train mean -  [0. 0. 0.]\n",
      "*** train std -  [1. 1. 1.]\n",
      "[[-0.70710678 -1.41421356 -2.12132034]\n",
      " [ 0.         -0.70710678 -1.41421356]\n",
      " [ 0.70710678  0.         -0.70710678]]\n",
      "*** test mean -  [ 0.         -0.70710678 -1.41421356]\n",
      "*** test std -  [0.57735027 0.57735027 0.57735027]\n"
     ]
    }
   ],
   "source": [
    "my_scaler = StandardScaler()\n",
    "my_scaler.fit(Sample_train) # Computes the mean and std deviation and stores in its class attributes\n",
    "scaled_train = my_scaler.transform(Sample_train)# Perform Standardization using fit data stored\n",
    "#my_scaler.fit_transform(Sample_train) # first fit (computes and stores), then apply to sample_train \n",
    "scaled_test = my_scaler.transform(sample_test) # apply the same standardization to testing data\n",
    "print(scaled_train)\n",
    "print(\"*** train mean - \", scaled_train.mean(axis=0))\n",
    "print(\"*** train std - \", scaled_train.std(axis=0))\n",
    "print(scaled_test)\n",
    "print(\"*** test mean - \", scaled_test.mean(axis=0)) # won't be 0 as we are using mean is from train data\n",
    "print(\"*** test std - \", scaled_test.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [1. 2. 3.]]\n",
      "[[1. 1. 1.]\n",
      " [2. 2. 2.]\n",
      " [3. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "rescaled_train = my_scaler.inverse_transform(scaled_train)\n",
    "rescaled_test = my_scaler.inverse_transform(scaled_test)\n",
    "print(rescaled_train)\n",
    "print(rescaled_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Decision Tree algorithm belongs to the family of supervised learning algorithms. Unlike other supervised learning algorithms, the decision tree algorithm can be used for solving __regression__ and __classification__ problems too.\n",
    "2. Decision trees are most commonly used. It is one of the few classifier algorithms that is easy to interpret and analyze. We actually know how it works and how it classifies a given data.\n",
    "3. Decision trees use the features( columns) that you provide to build the tree and make the best prediction. So it's important that you choose your features that you feed the decision tree precisely.\n",
    "\n",
    "#### Reference:\n",
    "1. https://www.youtube.com/watch?v=tNa99PG8hR8&list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal&index=2\n",
    "2. John Gordon - https://www.youtube.com/watch?v=eKD5gxPPeY0\n",
    "3. __*IMP* must listen__ John Gordon - https://www.youtube.com/watch?v=LDRbO9a6XPU&list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal&index=8\n",
    "4. https://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    " ### Important Terminology: \n",
    "1. __Root Node__: It represents the entire population or sample and this further gets divided into two or more homogeneous sets.\n",
    "2. __Leaf / Terminal Node__: Nodes do not split is called Leaf or Terminal node.\n",
    "3. __Pruning__: When we remove sub-nodes of a decision node, this process is called pruning. You can say the opposite process of splitting.\n",
    "4. __Branch / Sub-Tree__: A subsection of the entire tree is called branch or sub-tree.\n",
    "5. __Decision/Internal Node__: When a sub-node splits into further sub-nodes, then it is called the decision node.\n",
    "6. The root and the decision/internal node have test conditions.\n",
    "\n",
    "<img src=\"images/image1.png\" style=\"width:400px; height:200px; float:left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://en.wikipedia.org/wiki/Decision_tree_learning\n",
    "\n",
    "2. __Gini Impurity__ : \n",
    "    * https://www.youtube.com/watch?v=LDRbO9a6XPU&list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal&index=8 at time 5:00\n",
    "    * Gini Impurity is a measurement of the likelihood of an incorrect classification of a new instance of a random variable, if that new instance were randomly classified according to the distribution of class labels from the data set. or in simple terms GINI Impurity gives us the probability of being incorrect.\n",
    "    * it ranges  between 0-1. Lower values indicate less uncertanity or mixing and higher value indicate more uncertanity\n",
    "    * It reaches its minimum (zero) when all cases in the node fall into a single target category.\n",
    "    * Gini Impurity : Calculated as         \n",
    "                            j                         j\n",
    "                    G(k) =  Σ P(i) * (1 - P(i)) = 1 - Σ P(i)^2\n",
    "                            i=1                       i=1\n",
    "      \n",
    "    * Gini Gain / Information Gain: (GI of Total dataset) - (Sum of weighted GI of each branch)\n",
    "    Basically Information gain will give us how much impurity will be reduced if we split with this question in the feature comapred to other question in a feature. And this will tell the decision tree to split on specific feature first. Checkout the video.\n",
    "<img src=\"images/image11.png\" align=\"middle\" style=\"width:350px; height:180px\"/>\n",
    "<img src=\"images/image12.png\" align=\"middle\" style=\"width:350px; height:50px\"/>\n",
    "3. https://victorzhou.com/blog/gini-impurity/ --> This will explain how to calculate Gini Impurity and Gini Gain and how it is used to make a split in decision tree. Also read about Information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apple and Orange classification. Oranges are bumpy and heavier. \n",
    "#training_data = [[140, \"smooth\"], [170, \"bumpy\"], [135, \"smooth\"], [155, \"bumpy\"], [165, \"bumpy\"]] \n",
    "#labels = [\"apple\", \"orange\", \"apple\", \"orange\", \"orange\"]\n",
    "training_data = [[140, 0], [170, 1], [135, 0], [155, 1], [165, 1]]\n",
    "labels = [2, 3, 2, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(training_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[135, 0]])  # answer is 2 as its smooth and light weight so it's apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a decision tree\n",
    "__sklearn.tree.plot_tree__ for the above example we can use tree.plot_tree(clf) to get the decision tree visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(clf);  # ; will remove the text from output cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier can be thought as a function y=f(x) with y being target output/label and f(x) as our features.\n",
    "<img src=\"images/image2.png\" style=\"width:150px; height:100px; float:left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn provide some datasets to work with, one of which is iris\n",
    "iris = datasets.load_iris() #iris is a dict with keys as 'data', 'target', 'feature_name' etc\n",
    "#iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use train_test_split to partition the data into training and testing group.\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5) # split 50-50 between test and train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its pretty easy to switch between different classifier as shown below. 90% of the code flow remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=11, p=2, metric='euclidean')\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest neighbors classifier algorithm\n",
    "A powerful Supervised machine learning algorithm used for classification and regression (mostly classification). KNN is based on __feature similarity__. It classifies a data point based on how its neighbors are classified.\n",
    "* Algorithm : \n",
    "    * As the name suggest the KNN first studies the training data. \n",
    "    * The for each new test data (a row in iris data set), it will try to find the nearest neighbour( a row in iris training data set) using euclidean distance. \n",
    "    * The nearest neighbour label is assigned to the test data set.\n",
    "    * If two nearest neighour have the same distance, then the k value is used to get a voting.\n",
    "\n",
    "* _k_ in the KNN is a parameter that refers to the number of nearest neighbors to include in the majority voting process. It uses EUCLIDEAN distance to find the nearest neighbor.\n",
    "* Choosing a right value of _k_ is a process called as __parameter tuning__, and is important for better accuracy.  \n",
    "<img src=\"images/image3.png\" align = \"middle\" style=\"width:400px; height:200px;\"/>   \n",
    "* Choose th evalue of _k_:\n",
    "    * __sqrt(n)__ where n is the total number of data points\n",
    "    * after sqrt(n) if the number of feature are even make the _k_ odd and vise-versa\n",
    "* When to use KNN:\n",
    "    * For classification\n",
    "    * Data is labeled.\n",
    "    * Data is noise free \n",
    "    * Dataset is small \n",
    "<img src=\"images/image4.png\" align = \"middle\" style=\"width:400px; height:200px;\"/>\n",
    "\n",
    "\n",
    "__Pros__:\n",
    "* KNN is a __non-parametric__. When we say a technique is non-parametric , it means that it does not make any assumptions on the underlying data distribution. A __parametric model__ is one where we assume the 'shape' of the data, and therefore only have to estimate the coefficients of the model. A __non-parametric model__ is one where we do not assume the 'shape' of the data, and we have to estimate the most suitable form of the model, along with the coefficients.\n",
    "* __parametri model__ : Y = a + bX is a parametric model with parameters \"a\" and \"b\". To find the value of Y at a new value of X, the values of \"a\" and \"b\" are sufficient. We don't need the data that had been used to estimate \"a\" and \"b\". __Ex: Linear/logistic Regression, Perceptron, Naive Bayes.__\n",
    "* __non-parametric model__ :However, in the non-parametric approach, all of the previously used training data need to used along with the untrained value and the estimated quantities in order to perform prediction. Such \"quantities\" in the non-parametric method are sometimes referred to as __\"hyper-parameters\"__. __Ex: k-Nearest Neighbors, Decision Trees like CART and Support Vector Machines__\n",
    "\n",
    "__Cons__:\n",
    "* Its a __lazy__ algorithm. To be more exact, all (or most) the training data is needed during the testing phase.Basically the KNN iterate over every training set data to make a new test prediction.\n",
    "* If your _k_ is too __low__, your predict is not that accurate. If _k_ is too __high__ then its gonna take for ever to process and you are gonna run into processing/resource issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN classifier from scratch with k=1:\n",
    "reference: https://www.youtube.com/watch?v=AoeEHqVSNOw&list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal&index=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrappyKNN():\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for row in X_test:\n",
    "            label = self.closest(row)\n",
    "            predictions.append(label)\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def closest(self, row):\n",
    "        #from scipy.spatial import distance to calculate the euclidean distance\n",
    "        best_dist = distance.euclidean(row, self.X_train[0])  \n",
    "        best_index = 0\n",
    "        for i in range(1, len(self.X_train)):\n",
    "            dist = distance.euclidean(row, self.X_train[i])\n",
    "            if  dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_index = i   \n",
    "        return self.y_train[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,1,1,1]\n",
    "b=[2,2,2,2]\n",
    "c=[2,3,4,5]\n",
    "distance.euclidean(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "clf = ScrappyKNN()\n",
    "clf.fit(X_train, y_train);\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  0,  0],\n",
       "       [ 0, 21,  1],\n",
       "       [ 0,  4, 26]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy and its Limitations\n",
    "* Classification accuracy is the ratio of correct predictions to total predictions made.  \n",
    "    classification accuracy = $\\frac{correct predictions} {total predictions} * 100$\n",
    "* Classification accuracy can also easily be turned into a misclassification rate or error rate by inverting the value, such as: error rate = (1 - (correct predictions / total predictions)) * 100\n",
    "* The main problem with classification accuracy is that it hides the detail you need to better understand the performance of your classification model. There are two examples where you are most likely to encounter this problem:\n",
    "    1. When your data has more than 2 classes. With 3 or more classes you may get a classification accuracy of 80%, but you don’t know if that is because all classes are being predicted equally well or whether one or two classes are being neglected by the model.\n",
    "    2. When your data does not have an even number of data in classes. You may achieve accuracy of 90% or more, but this is not a good score if 90 records for every 100 belong to one class and you can achieve this score by always predicting the most common class value. Ex: Would you believe someone who claimed to create a model entirely in their head to identify terrorists trying to board flights with greater than 99% accuracy? Well, here is the model: simply label every single person flying from a US airport as not a terrorist. Given the 800 million average passengers on US flights per year and the 19 (confirmed) terrorists who boarded US flights from 2000–2017, this model achieves an astounding accuracy of 99.9999999%!\n",
    "* Classification accuracy can hide the detail you need to diagnose the performance of your model. But thankfully we can tease apart this detail by using a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix: \n",
    "* A confusion matrix is a technique for summarizing the performance of a classification algorithm.\n",
    "* The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\n",
    "<img src=\"images/image6.png\" align = \"middle\" style=\"width:200px; height:120px;\"/>\n",
    "* True Positive (TP) : these are the events that were correctly predicted by the model as \"occurred = Yes.\"\n",
    "* True Nagative (TN) : These are the events that were correctly predicted by the model as \"occurred = No.\"\n",
    "* False Positive (FP) : These are the events that were predicted as \"occurred = Yes,\" but in reality, it was \"occurred = No.\" __eqv. to false alarm, Type I error__\n",
    "* False Negative (FN) : This is the opposite of FP, i.e. predicted as \"occurred = No,\" but in reality, it was \"occurred = Yes.\" __eqv. to miss, Type II error__\n",
    "\n",
    "#### Reference:\n",
    "1. https://en.wikipedia.org/wiki/Confusion_matrix --> Check this for all the calcualtion\n",
    "2. https://www.youtube.com/watch?v=vP06aMoz4v8 --> Josh Starmer\n",
    "3. https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c -- VVIMP must read\n",
    "\n",
    "\n",
    "1. __recall/ sensitivity/ hit rate/ true pos rate (TPR)__: the ability of a model to find all the relevant cases within a dataset.\n",
    "\\begin{equation*}\n",
    "TPR = \\frac{TP}{TP + FN} = 1 - FNR\n",
    "\\end{equation*}\n",
    "<img src=\"images/image7.png\" align = \"middle\" style=\"width:300px; height:200px;\"/>\n",
    "2. __specificity, selectivity or true negative rate (TNR)__:\n",
    "\\begin{equation*}\n",
    "TNR = \\frac{TN}{TN + FP} = 1 - FPR\n",
    "\\end{equation*}\n",
    "<img src=\"images/image8.png\" align = \"middle\" style=\"width:300px; height:200px;\"/>\n",
    "\n",
    "Check the above video to calculate sensitivity and specificity of a model with more than 2 predicting value.\n",
    "\n",
    "3. __precision__ :  the ability of a classification model to identify only the relevant data points.\n",
    "\\begin{equation*}\n",
    "TPR = \\frac{TP}{TP + FP}\n",
    "\\end{equation*}\n",
    "4. __F1-score__ : It combines precision and recall into a single measure. Mathematically it’s the harmonic mean of precision and recall.\n",
    "$F1-score = 2*\\frac{Precision*Recall}{Precision+Recall}$\n",
    "    * We use the harmonic mean instead of a simple average because it punishes extreme values.\n",
    "    * In some situations, we might know that we want to maximize either recall or precision at the expense of the other metric. For example, in preliminary disease screening of patients for follow-up examinations, we would probably want a recall near 1.0 — we want to find all patients who actually have the disease — and we can accept a low precision if the cost of the follow-up examination is not significant. \n",
    "    * If we want to create a balanced classification model with the optimal balance of recall and precision, then we try to maximize the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmatic Vs Goemetric Vs Harmonic Mean:\n",
    "1. https://towardsdatascience.com/on-average-youre-using-the-wrong-average-geometric-harmonic-means-in-data-analysis-2a703e21ea0\n",
    "4. There are lot of ways to represent the average of a dataset. Like Arithmetic mean, Geometric mean, Harmonic mean. Differetn kind of dataset require different avearges to be used.\n",
    "2. The arithmetic mean is just one among many ways of arriving at an “average” value. Sum / num of elements. AM is very well suited for linearly realated dataset. AM is ill suited if we have large outliers in dataset or exponentila.\n",
    "3. Geometric mean : Assume we have a dataset sqaure of 3 --> [1,3,9,27,81,243,729]. This is a exponential curve. In this situation, the arithmetic mean is ill-suited to produce an “average” number to summarize this data. The arithmetic mean = 156.1. 156 isn’t particularly close to most of the numbers in our dataset. In fact it’s more than 5x the median (middle number), which is 27. Here is where we use Geometric means comes handy\n",
    "<img src='images/image91.png' style='width:200px;height:200px' />\n",
    "4. __Geometric mean__: Since the relationship is multiplicative, to find the geometric mean we multiply rather than add all the numbers. Then to rescale the product back down to the range of the dataset, we have to take the nth root, rather than simply dividing. In our case GM will be 7th root of 1*3*..*729 = 27.  the geometric mean will not always equal the median, only in cases where there is an exact consistent multiplicative relationship between all numbers (e.g. multiplying each previous number by 3, as we did).\n",
    "$GM = {^n}\\sqrt{x_1*x_2..*x_n}$\n",
    "5. It turns out that there are many practical uses for the geometric mean, as multiplicative-ish relationships abound in the real world. One Ex: Assume we have dollar 100,000 that accrues a varying rate of interest each year for 5 years: annual interest rates: 1%, 9%, 6%, 2%, 15%. Similar datatset which has rate equation we use GM.\n",
    "6. A fancy feature of the geometric mean is that you can actually average across numbers on completely different scales. Read the coffeshop rating example from the above link.\n",
    "7. __Harmonic Mean__: Whereas the arithmetic mean requires addition & the geometric mean employs multiplication, the harmonic mean utilizes reciprocals. Another way to think about reciprocals is: two numbers that equal 1 when multiplied together. So when finding the reciprocal of a number n, we are simply asking: what number must we multiply with n in order to get 1. (This is why the reciprocal is also sometimes called the multiplicative inverse.)EX. A simple example from wikipedia: the harmonic mean of 1, 4, and 4 is 2.   \n",
    "$\\frac{3}{\\frac{1}{1}+\\frac{1}{4}+\\frac{1}{4}}$ = 2\n",
    "8. Notice, what we are saying here is: if the reciprocal of every number in our dataset was the same number, what number would it have to be in order to have the same reciprocal sum as our actual dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Practical application of sensitivity and specificity__ : If we calculate the sensistivity and specficity for two ML models say Random forest and Logistic Regression and here are the numbers.\n",
    "LR: Sensi: 0.81 and Speci: 0.85\n",
    "RF: Sensi: 0.83 and Speci: 0.82\n",
    "A high Sensitivity in RF tell us that the RF can predict the True Positive slightly higher than the LR. So RF is better at predicting people with Heart Desease. So use the RF model if its more important for you to know which patient is going to have a heart disease.\n",
    "A high Specificity in LR tells us that the LR can predict the True Negative slightly higher than the RF. So use the LR model if its more important for you to know which patient is not going to have a heart disease.\n",
    "<img src=\"images/image9.png\" align = \"left\" style=\"width:200px; height:300px;\"/>\n",
    "<img src=\"images/image10.png\" align = \"middle\" style=\"width:200px; height:300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC - Reciever Operating Characterstics(ROC) curve\n",
    "1. The other main other than recall and precision technique for showing the performance of a classification model is the Receiver Operating Characteristic (ROC) curve.\n",
    "2. The ROC curve shows how the recall vs precision relationship changes as we vary the threshold for identifying a positive in our model.\n",
    "3. An ROC curve plots the true positive rate on the y-axis versus the false positive rate on the x-axis. The true positive rate (TPR) is the recall and the false positive rate (FPR) is the probability of a false alarm. Both of these can be calculated from the confusion matrix:   \n",
    "$ROC = \\frac{True Positive Rate}{False Positive Rate}$ $TPR = \\frac{TP}{TP+FN}$ $FPR = \\frac{FP}{FP+TN}$\n",
    "4. <img src='images/image90.png' style='width:200px;height:200px'/>\n",
    "5. The black diagonal line indicates a random classifier and the red and blue curves show two different classification models. For a given model, we can only stay on one curve, but we can move along the curve by adjusting our threshold for classifying a positive case. Generally, as we decrease the threshold, we move to the right and upwards along the curve. With a threshold of 1.0, we would be in the lower left of the graph because we identify no data points as positives leading to no true positives and no false positives (TPR = FPR = 0). As we decrease the threshold, we identify more data points as positive, leading to more true positives, but also more false positives (the TPR and FPR increase). Eventually, at a threshold of 0.0 we identify all data points as positive and find ourselves in the upper right corner of the ROC curve (TPR = FPR = 1.0).\n",
    "6. Finally, we can quantify a model’s ROC curve by calculating the total __Area Under the Curve (AUC)__, a metric which falls between 0 and 1 with a higher number indicating better classification performance. In the graph above, the AUC for the blue curve will be greater than that for the red curve, meaning the blue model is better at achieving a blend of precision and recall. A random classifier (the black line) achieves an AUC of 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[23  0  0]\n",
      " [ 0 21  1]\n",
      " [ 0  4 26]]\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Recall:  [1.         0.95454545 0.86666667]\n",
      "Precision:  [1.         0.84       0.96296296]\n",
      "F1-score:  [1.         0.89361702 0.9122807 ]\n",
      "\n",
      "\n",
      "Micro Precision: 0.93\n",
      "Micro Recall: 0.93\n",
      "Micro F1-score: 0.93\n",
      "\n",
      "Macro Precision: 0.93\n",
      "Macro Recall: 0.94\n",
      "Macro F1-score: 0.94\n",
      "\n",
      "Weighted Precision: 0.94\n",
      "Weighted Recall: 0.93\n",
      "Weighted F1-score: 0.93\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00        23\n",
      "   Verginica       0.84      0.95      0.89        22\n",
      "  Versicolor       0.96      0.87      0.91        30\n",
      "\n",
      "    accuracy                           0.93        75\n",
      "   macro avg       0.93      0.94      0.94        75\n",
      "weighted avg       0.94      0.93      0.93        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix for above Iris dataset with ScrappyKNN\n",
    "# https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = predictions\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, predictions)))\n",
    "\n",
    "# scores for each class of setosa, verginica, versicolor\n",
    "# precision_score(y_test, y_pred, average=None)\n",
    "print('Recall: ',recall_score(y_test, y_pred, average=None))\n",
    "print('Precision: ',precision_score(y_test, y_pred, average=None))\n",
    "print('F1-score: ',f1_score(y_test, y_pred, average=None))\n",
    "print('\\n')\n",
    "\n",
    "# Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "# Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "# Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). \n",
    "# This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=['Setosa', 'Verginica', 'Versicolor']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis : An unsupervised ML \n",
    "1. The goal of Cluster Analysis is to organise similar items in your data set into groups or clusters.\n",
    "2. Ex application : In a retail industry segment/cluster your customer base into groups/clusters based on their purchase history. Grouping latest news articles into topics of the day, to itendify the trending topic of the day.\n",
    "3. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features.\n",
    "4. Eucledean Distance / Manhattan Distance or Cosine Similarity is used in Clustering Algorithm to measure similarity between data points. \n",
    "5. Since clustering is a unsupervised learning technique (there is no labelled data), there is no \"correct\" clustering data. we are just trying to get the best clustering possible. Also clustering can result into numerous groups/clusters without a label. It requires further interpretation and analysis of the cluster we can come with some labels to the cluster and make use of this data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering Algorithm\n",
    "1. A very important question to ask yourself before starting clustering is, What are you trying to cluster and on what basis. You should know the question you are trying to answer. Ex: given a set of alphabets[A..Z]. We can cluster them based on there phenetic sounds. based on position, based on simplicity of writing them , most commonly used etc etc. So its important to know waht clustering you want.\n",
    "1. Steps in K-Means Algorithm:  https://en.wikipedia.org/wiki/K-means_clustering  \n",
    "    a. To begin, we first select a number of classes/groups(_k_) to use and randomly initialize their respective centroids.  \n",
    "    b. Assign each sample to the closest centroid using Eucledian distance  \n",
    "    c. Calculate mean of cluster which will be your new centroid.  \n",
    "    d. Repeat (b) and (c) until stopping criteria is reached.  \n",
    "<img src=\"images/image13.png\" align = \"middle\" style=\"width:600px; height:300px;\"/>\n",
    "2. How to select Initial Centroid: Lots of sophesticated methods are there, one of the easy method is below.  \n",
    "    a. __Issue__: Final Cluster are sensitive to Initial centroids selected.  \n",
    "    b. __Solution__: Run k-means multiple times with different initial centroid and choose the best results.\n",
    "3. __Evaluating Cluster Results__: error = distance between sample and centroid\n",
    "squared error of all the samples and all the cluster gives us what is called as __WSSE (Within-cluster Sum of Squared Error)__\n",
    "    So __WSSE 1 < WSSE2__, the clsutering with smaller error is better and can be used for further processing.\n",
    "    Note: Larger values of _k_ always reduces the WSSE. So while comparing WSSE of two things we will need to maka sure we are using same _k_  \n",
    "    <img src=\"images/image14.png\" align = \"middle\" style=\"width:400px; height:300px;\"/>\n",
    "4. __Choosing the value of _k___: There are different techniques to determine the vaue of _k_, some of which are  \n",
    "    a. __Visualization__: Visualize the dataset and see if we can fidn some natural grouping of the sample data based on domain knowledge. We can use scattered plots and dimensionality reduction here to visualize the data \n",
    "    b. __Application -depedant__: sometimes ot depends on applicatipn and domain knowledge.  \n",
    "    c. __Elbow Method__: \n",
    "    <img src=\"images/image15.png\" align = \"middle\" style=\"width:400px; height:300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and running the Clustering Model with iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "#X = scale(iris.data) # with just scale we don't get a inverse_scale() method.\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(iris.data)\n",
    "y = pd.DataFrame(iris.target) \n",
    "# y.columns = ['Target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2,\n",
       "       2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we know iris dataset has 3 different flowers info so k=3\n",
    "# random_state - Determines random number generation for centroid initialization. \n",
    "# Use an int to make the randomness deterministic\n",
    "kmeans = KMeans(n_clusters=3, random_state=5) \n",
    "kmeans.fit(X); # computes KMeans clustering\n",
    "kmeans.labels_# predicted labels of each data point\n",
    "# kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.80188679, 2.67358491, 4.36981132, 1.41320755],\n",
       "       [5.006     , 3.428     , 1.462     , 0.246     ],\n",
       "       [6.78085106, 3.09574468, 5.5106383 , 1.97234043]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 8,4  # this parameter is used to resize your figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal length', 'sepal width', 'petal length', 'petal width'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(iris.data)\n",
    "iris_df.columns = [i.split(' (cm)')[0] for i in iris.feature_names]\n",
    "iris_df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'a', 'a', 'b'], dtype='<U1')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explanation of what is happening at c=color_theme[iris.target]\n",
    "a=np.array(['a', 'b'])\n",
    "b=np.array([0,1,0,0,1]) #'b' holds the indexes of elements\n",
    "a[b] # selecting your elements from a using b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'K-Means Clustering')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color_theme = np.array(['darkgray', 'lightsalmon', 'powderblue'])\n",
    "\n",
    "plt.subplot(1,2,1)  # creates a subplot with rows=1,cols=2,index=1 selected\n",
    "plt.scatter(x=iris_df['petal length'], y=iris_df['petal width'], c=color_theme[iris.target], s=50)\n",
    "plt.title(\"Ground Truth Classification\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(x=iris_df['petal length'], y=iris_df['petal width'], c=color_theme[kmeans.labels_], s=50)\n",
    "plt.title(\"K-Means Clustering\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 6, 6, 7, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with np.choose(a, choices) we are creating a array with elements from 'choices' choosen/sequenced with index from 'a'.\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.choose.html\n",
    "#choices = [[0, 1, 2, 3], [10, 11, 12, 13],[20, 21, 22, 23], [30, 31, 32, 33]]\n",
    "choices = [6,7,8]\n",
    "correction_index = [2,1,0,0,1,2] # the index should not exceed the number of elements in choices.\n",
    "np.choose(correction_index, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'K-Means Clustering')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEICAYAAABs9Jx5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABeNklEQVR4nO29d5hk13XY+TvvvUqd40xPzoOZAQaYAQaJAEiQBEGQhERKpETJlLWiraVJWZa1ltfSendlSpZ3vfJaXkXStCiRlChRiYIo5gAiEJHAYAImAZPzdE/Hququ8N67+8et7q7urupY3dXh/L6vv6l+4d7zeurcc9+9J4gxBkVRFEVRqodTbQEURVEUZaWjxlhRFEVRqowaY0VRFEWpMmqMFUVRFKXKqDFWFEVRlCqjxlhRFEVRqowa4wVERDaLiBERrwp9nxeRRyrYnhGR7ZVqb1zbHxGRbxf9/oCIvCkiKRH5gIh8Q0T+p3no99Mi8n9Wul1FWSyIyOdE5LcWgRwbC/rsVluWxcKyM8Yi8lMi8pKIpEWks/D5F0REqi3bZBS+mMM/oYgMFf3+kRm2NWeFE5E1IvJZEbkmIkkROSkivyEitXNpdzoYY75ojHm06NBvAn9gjKkzxjxhjHmPMebzc+lDRH5ORH4wrt+PG2P+41zaVZYG4yenhXGjV0TeVuJaIyI3iifRIuIVxpdFlahBLL8kIq8XxsDLIvI3IrK3gn08LCKX59KGMeZiQZ+DSsm11FlWxlhEfgX4XeC/AB3AauDjwANAtMw9i2JmVvhi1hlj6oCLwI8UHfvi8HUL8VYtIi3AC0ACuN8YUw+8C2gCts13/yXYBByrQr/KCqCwyvKHwPuMMU+XuawPeE/R7+8FeudZtNnwu8C/Bn4JaAF2Ak8A76uiTGOoxsrgksAYsyx+gEYgDXxwius+B3wK+Hrh+keA3cBTWIU7Bvxo0fVPAT9f9PvPAT8o+t1gDf6bWOX8Q0AK51zg/wVuAmeBf1m43ptCxvPAI4XPDwOXgV8FrgN/Nl6GIjm2Ax8D8kAOSAH/WNTmvwWOAP3AXwHxMv3/FnAUcCaR0QDbC5/fB7wGDACXgE8WXRcH/hzoLvx9fwisLvpbngWSwDngI+P/xsAZIASGCs8TK/F/8j8DJwrtHAfuLBz/tcL9w8d/rHB8N5ABgkKbfUXfjd8a1+5poAf4CrB2Ov/v+rP4f4Z1rKAvN4EDU3zX/w/gb4qO/S3wvwOm6Fgj8FngGnCloEdu4dw24MmCHtwEvgg0jZOnpH4CbcBXC/rTAzxbSjeBHYXv9D2TPMvId5xJxpHC5/cW9CZZeJ5/C9QWdDEs6E4KWIt9sRvWt27gr4GWQjubC+3+c+yLxjNFx7zCNU8B/xF4rtDft4G2Irl+FrhQaPv/pGiMXC4/y+nN+H7sQP0P07j2nwD/CagHXgL+Efufvwr4V8AXReSWGfT9OHA3cAfwk8C7C8f/58K5/cAB4EMzaLOYDuwsdxN28CiLMeYzWEX/bWPfqn+k6PRPAo8BW4DbscpYikeALxtjwmnKl8YqSxPWMH9CRD5QOPc/YQepDUAr1oANFZa7fw94j7Fv3m8BDpV4nm2MXSnIFp8XkZ8APlnovwH4UazCgh0YHir0/xvAn4vIGmPMiYIcLxTabBrfr4i8A/i/sX+zNdiB4EvjLiv3/64sDT6BNQDvNMa8MsW1TwBvFZEmEWnCfq/GjzWfB3zspHg/8Cjw84Vzgv0+rcVOBjdgv7fFlNPPX8FOyNuxq33/HmvIxvNO4LIx5uUpnmW6fBb4FwX9vA140hiTxq4QXDWjK3dXsW/iHwDehn3G4QlqMW/DPns5PfknwEex43AUa/wRkT3AHwEfwepiI7CuQs+4aFhOxrgNuGmM8YcPiMjzItJX2H99a9G1/2CMea5gbPYBdcB/NsbkjDFPYmehPz2Dvv+zMabPGHMR+H6hTbDK9f8ZYy4ZY3qwyjgbQuA/GGOyxpihWbYB8HvGmKsFWf6xSM7xtGJn99PCGPOUMeaoMSY0xhwB/hKreGDf0luxs+3AGPOqMWagcC4EbhORhDHmmjFmNkvRP4+dePzQWE4bYy4U5PqbwvOGxpi/wr7F3jPNdj8C/Ikx5mBhAvC/AfeLyOaia8r9vytLg3cBL2JXgaYig9WZDwM/hV0pyQyfFJHVWCP1y8aYtDGmE/hvhWspfC+/U9DhLuB3GNWRYcrpZx5rhDYZY/LGmGdN4XVxHDPS22mQB/aISIMxptcYc3CSa/8F8L8bYy4X9OWTwIfGLUl/svC3KTeG/akx5o3C+b9m9Pk/hF3h+4ExJgf8OqUnI0ua5WSMu4G24v98Y8xbCm893Yx91ktFn9cCl8a9BV5gZjOv60WfB7HGfaTtce3Ohi5jTGbqy6aknJzj6cYq/7QQkXtF5Psi0iUi/di3zrbC6T8DvgV8SUSuishvi0ikMMP+cOHaayLyNRHZNdMHwr5hnCkj18+KyKHChKwPO7tvK3VtCdZS9P9ljElh/y7F34vp/j2VxcnHsXuqfzzs4Ckix4ocJx8ad/0XsCswP1v4XMwmIIL9Lg9/3/479i0PEVklIl8SkSsiMoDduhn/XSz3ffov2O2Sb4vIWRH5tTLPMyO9nQYfxC5VXxCRp0Xk/kmu3QT8fdGzn8Auma8uuuZSqRuLmNY4aowZZHT1a9mwnIzxC0AWeP80ri2eVV0FNohI8d9iI3aPBOwSbE3RuY4ZyHQNayyK250N42eBY2QSkfEyzXXW+F3gx8b9TSbjL7BvChuMMY3Ap7HLchRm8r9hjNmDXYp+HDuYYYz5ljHmXdgB5CTwP2Yh6yVKOJWJyKZCe78ItBYmZa8Py8XUf6Or2AFmuL1a7JvHlbJ3KEuNTuzS7kPYZVCMMbcWLb8+O+76Z7Hf1dXAD8adu4Qdf9qMMU2FnwZjzK2F8/839jt3uzGmAfgZRr+Lk2KMSRpjfsUYsxX4EeDfiMg7S1z6PWC9iByYTrtMMY4UVpvej51QPIF9W4XSunMJu+XUVPQTN8YU68tsx6VrwPoiORNYXVxWLBtjbIzpw+4L/pGIfEhE6kTEEZF9WKeDcryE/VL+OxGJiMjD2C/88P7gIeDHRaRGbFztP5+BWH8N/JKIrBeRZqyDQyU4DNwqIvtEJM7EvacbwNY5tP872P3XzxeMGiKyTkR+R0RuL3F9PdBjjMmIyD3YvR8K971dRPYWvNYHsEtfgYisFpEfLRi5LNYRZDZhDn8M/FsRuasQ1rG9IHMtVvm7CnJ8FPtmPMwN7MBV0sseO8H4aOFvHAP+L+AlY8z5WcioLFIK+53vAB4Tkf82xbUGOzb86PhlYmPMNazfyX8VkYbC2LOtKFSqnoKzoIisA/7X6cooIo8XvteC1aGAErpijHkTO6n4y0L4UVRE4mLDtkqNPWXHkcK9HxGRRmNMvqhfsLrTKiKNRW19GvhPReNFu4hM58VoOvwt8CMi8paCvv4G05zILCWWjTEGMMb8NvBvgH+HnfXewC4V/SrwfJl7clinn/dgvRz/CPhZY8zJwiX/DeuZfAProPHFUu2U4X9gl2gPAweBL8/siUpjjHkDG3v7Xew+6PhZ+mexez19IvLELNrvwb7F5oGXRCSJnXX3Y5fLxvMLwG8Wrvt1RmfQYFcS/harzCeAp7FLdA7WMeUq1kP0bYV2Zirr32Cd8f4C64X5BNaL8zjwX7ErJjeAvVhPzWGexHrOXxeRmyXa/R7Wa/PvsDPzbRT2/5TlhTHmEtYgf0hEJvXrMMYcm8S34WexjkfHsQ5Mf8vosvFvAHdidehrzGws2IHV9RT2+/xHxpinylz7S8AfYJ2n+rBbOD+G3YMe/yxTjSP/FDhfWFb/OPZtnsLY+JfA2cIYsxYbUvUV7FJ6ErsXf+8MnrEshb/3v8K+IF3D6nkndhK/bBBT0g9AURRFURYfIlKHnWjsMMacq7I4FWNZvRkriqIoyw8R+ZHCVmEtNnfDUWys8bJBjbGiKIqy2Hk/dkvrKnbZ/qfKhHctWXSZWlEURVGqjL4ZK4qiKEqVqVrC7ra2NrN58+Zqda8oS4ZXX331pjGmvdpyTIbqs6JMj3L6XDVjvHnzZl55Zap0sIqiiMhsM7ctGKrPijI9yumzLlMriqIoSpVRY6woiqIoVUaNsaIoiqJUGTXGiqIoilJlqubApSjzjTGGG0NZziTTZPyApliE7Q11NEYjY65L531OD6S5mcnhORB3XdK+jyPCptoaNtbX4Mqyy0uvKEuKIT/gbDLNjaEsrggb6xJsrBurm6ExXEkPcS41SM4PqY245ENDPgzL6v9iYUpjLCIbsLU7O7DF4D9jjPndcdc8DPwDMJwn9MvGmN+sqKSKMgOMMRzuGeByepCgkNcm7QdcG8ywv7WJdbUJALozOV7o7CE0pqi+mz/y6Vh+gPOpQR7qaMNzlrZBVl1WlirJfJ5nrnUTGsNw4flkb54LqUEeWt2G6wihMbzU2UN3Nk9QSGaVDkaLW5XS/8XEdN6MfeBXjDEHRaQeeFVEvlOoilPMs8aYxysvoqLMnJ5snsvpoRFDDLaeYmDgte5+VifiuAKv3OwdUdxSBAZSeZ8zAyluaaqff8HnF9VlZUly8GY//jg9DQwkcz5nkml2NtZxJT1EdzY3RueLKdb/jkQcd5FNrqfcMzbGXDPGHCx8TmLL4K2bb8EUZS5cSA2WNbICdA5l6MvlyYdTp4MNC+0tdVSXlaXIkB8wkMuXPFesm+eSg2UNcTEC3MhkKidghZiRA5eIbAb2Ay+VOH2/iBwWkW+IyK1l7v+YiLwiIq90dXXNXFpFmSa5MCx7zkBhH8lMu0K5Pw2jvZSYqy4X2lB9VuYd34TIJD4b+YKu5yfR+WKG9X+xMW1jXKgh+XfALxtjBsadPghsMsbcAfw+tsD7BIwxnzHGHDDGHGhvX9TZ/ZQlTnssWtbpymBojkVojHqE0yyU0hxbnE4fs6ESugyqz8rCUON5k06aW2JRANrisWlNrg2G5kXoxDUtYywiEazyftEY8+Xx540xA8aYVOHz14GIiLRVVFJFmQEb62sotSXkYJW3IRoh5rqsr02UvK4YV1gO+8WA6rKy9HBF2N5QW3Jy7Qrc0lgHwPaGWpwpoh6K9X+xMaUxFrs+8FnghDHmd8pc01G4DhG5p9BudyUFVZSZEHEcHupooy7i4gp4IjjAqkSMe9qbR667o7WR9TUJHMCFkZn18D1RR7irrXlk9r2UUV1Wlio7G+vYWphgeyIjunmgrZnmgm7WRjzuX9VC3HVwRXAL9wrl9X8xMR1v6geAfwocFZFDhWP/HtgIYIz5NPAh4BMi4gNDLMPCz8rC4YeGq4ND9OfyJFyXDXUJYq479Y0Fbg5lOdWfJBcaVidirEsk8I2hLuKR8Ma244iwv62JPc0NDOTyRByHWs+hL+/jitAcjUy6X7XEUF1WFp6e63DhKAQ+rNsJHVthmjrlhyEn+pLczOSIOcI9bc04jpTVzdZ4lEfXraI/55MPQxqjETJBQDYIS+r/YkKqpWcHDhwwWuVFGU9/Ls9zN7oJDQTG2KUbgTunGRv4/I1uujK5MccEeKijdWQGvdQQkVeNMQeqLcdkqD4rEzAhPPf3cL5giDHgRaFpFTz6zyASm/T27kyOH9yYuCizKh7l/tWt8yT0/FNOnzUdprJoMMbwwo0e8qEZCUsKgdDAa919DPr+pPefGUhNMMRgvSefu9EzDxIrilKWN18tGOI8DKfU8XP2Tfmlr055+/MlDDFAZybH+WS6goIuDtQYK4uGzky2bGxwaOB8cvJY3zf6yytoYAydQ9k5yacoygx4/dmCIR5H6MP5I9Ywl+FaeojJApVO9aXmLt8iQ42xsmgY9IOyoUYGmwlrMqaKM+wrkzhAUZR5YGh81FwRIpApP3nun0LXJ8sjsFRRY6wsGmo9r2xoggPUTxGOEHUm/zq3LMJwBkVZttQ2lT9nDMTryp5umiKuP+YuP9O1/J5IWbK0x6NlizGIwOa6mknv39VYXrk9EdoSkzuMKIpSQfa+DbwSRtX1YNv+0ucKdCTik1ZK27VM4v6LUWOsLBpEhLesbiXmOHgFRXTFhjEcaGueMixhc0MtHYmJHtPD3tSKoiwgW/fB9rus8XUcQKw3ddsGuPt9U97+0OqWkhm11tXE2DjFxHwpovWMlUVFfcTj0fWrOJdM05vNU+O5rKuJMxSEdGdy1Hkuvbk8rgiNUY/ewj5wayyK5zjcu6qV/myOk/0p8mFIezxGWyxC2g9wRaiNjH7lU3mfZN4n7jo0FcUs5oKQnmwOV4TWeHTKrD6zYbgPp9CH1ktWlh0icO+PEOy6j+6r5wlDQ3PbGpINq/BzAY0IQ0FINghpiHj4xjDoB9R6Lg3RCI2xKI9vWM0bA2luZrJEHYdt9bXkjaFrKDtGNwNj6M7kCI2hJRYlWljGNsbQl8uTKfRRrP+VolJ9qDFWFhW5IOSHXb305HKIgQB4cyCNK9aj2mAzZYXYz46Ag2CA3U11bGuoozEW5d5VLfTn8rzc2cubA2kECLGKur+1kde6+60xLNwbcx3uaWviYnqI88nBMQb4jpYG1ldoJm6M4VhvknPJ9Jg+bm9pYMMynO0rK5uLqUGO9gdQu8HWIs6AZHpwhJEKSw6MeE57Ihhsgp5721tIeC67muoxpo7Xewd4vrNnjN7sa20kNIYjPaPOYqExbKmvZX1tnJe7+siFodV/Y2iJR7mnvZnIFP4l02Ugl+elrl6yQThmjLm7rXlkQjBd1Bgri4oXOnvoz+UZ71NdXBotKDoeGqsAACf6UsRdl3W1CXJByHPXu8mP887uyeR48upNQmMwjN476Ac8c93GNdrY5tH7DvX0k/A8WuNzTxryRn+K86n0hD4O9/ST8Fza4rqvrSwPuoayHOnpn1DWcLiu8DDFftHDNYsHcj4/uNHNI2vbERFO9iW5kBqcoDcHb/ZNaAPgfCrN2WR6wjjSk8nxYmcPD3XMPd16Lgj5QYkxprvQx1vXzKwP3TNWFg292RzJvD9BgaZLYAwn+pJAoZ5xiZbCwnWl+giZqNS2XTjZn5ylVEXtG8PpgXTJmquBgZN9c+9DURYLJ/uT06ovXAoDZIOQG0M298CZMrWKJ9PZcjren8vTX4Ewx4tlxhgDDOTzMw6lVGOsLBr6cnnmmp417QcYY+jO5qhkydL+7NyVd8gvpbpFfeQmj61UlKXEXL/PQWEvdtD3p113fHpIRXIOTDXG9M1wzFBjrCwaoo4zZ2cpt3B7rEJ7QsN4FWgv4jiTTjYiU9VyVJQlxFy/z47YMSHiONOuOz4dhKlzEkyHyWKdBVtVaiaoMVYWDasT8VkvUYNVsg21CUSETfU1I4Z5rjjAlvq5O1dFXadsKUYH2FyBPhRlsbCprmZuBsbAuto4cdelsUzCHoFZvTWvqkDOgU115ccYgx3PZoIaY2XR4DnCXW1NuDJzBXMFajyX3U0NgC0gPl5ZpHDdzkKhchlzv7CxNkHUEYontK5AYzTC1oba2T7WGPa1NhZWAMb20RCNsK2+fNISRVlqbG+ooz7qzSpszxHY29IwUjr1zrYmIo6MMVhWNz0aImP7GH6j3lAbL6n/doyZ+0y9ORZlc13tmLaG+zjQ1oQ7wzdj9aZWFhVrauK8bU07ZwZS9OV8YiJ4rsOgH+CJEHMdUnkfT4SE55L2AwRYV5tgY11iZDk5MIZbGutZHY9xLjXIUBDSHI2wpb5mxOP6bDJNX84n4TpsbailPR4jF4ScS6a5PpTFFWFTXYJ1tYlZL58bY8iHBs8RnEKc8zvXtnM+lebaoO1jY12C9XPoQ1EWI54jPNTRxpX0EBdTg/ihDVnKBCGBCanxPPJhSC401LgOoYFMGFAf8djWUEdT4W3YGEPUcXj7mnYupga5PpTFE2FjXQ2rElEEuD6U5WJqiMAY1tTE2FxXS9R12DCU5WwyPaL/2xpqqZtDrLEfGgwGTwQR4baWBlYnYiN9NEWt7PWz6EONsbLoqI947GttmtW9Q37AkZ5+bhQqNMVch12N9ayvS3C8d4BnrndjjEFE2FxXw0MdrWNmtlHX4Zamem6ZY7o9U/CcfnMgRVDw8lhXm2BvSwNR12FnYz07G5dfSj9FKcYtGM3ZZMwyxnAhNcjJ/hS5wPpMdyRi3NveTNoPONrTz2vd1kmsMRphb0vDhG2g9kSM9gosSQ/k8hztGaA7aytN1XgutzU30FETr1gfaoyVZUMuCHn62k2yRRVdMkHI0d5+3hhIkvHD0TAIYziXTJPM57lvVctI9q1KcaRngEvpseEYV9JD9GZzvH1tu74FK8oUvDmQ5o3+1JiyqteGsnRf68IPzZiQpr5cnudvdPPA6laay/hlzJZ03ufZ690jMdBgozZeudnLna1NrK1NVKQf3TNWlg1nk+mSZRQDA4PFhrhACHRnZx4POBVDfmBjEMd5o4XAUBBydTBT0f4UZbnhhyFv9CdL1jfPjTPEwwQGjvVOUrZxlpzsT44xxMX9He0dmHM45jBqjJVlw7XBzKQFyUsRGMP1ChvHrky27Jt2YAxX00MV7U9Rlhs92TwyCz/p7uzccxWMZ3jLqxT5MGTQD8qenwlqjJUVT6WXjG1r5QeESi+JK8pyY7YaMh+aNdmkwFA5fVZjrCwbNtQmZvyFdsV6cFeSVYk45SbnrgjrK7THpCjLlZZZ5oFvj8cqPtldWxMva44TrktihgUhyqHGWFk2bKqvIe65ExTHFWiKeBMC9IcNcUOZhAKzJeY67GismxDL6AANEY+OCnheKspyxhXhtub6CTorQMJ1ShouT4RbmysfobCzsa5kNjFX4I6WxooZf/WmVpYNEcfhbR1tnOxLciltYw4bIh67m+tZFY9xdiDN6WSaTBASdx22N9Sytb4yyTzGs6upnrqIx8m+JIN+QMQRNtfXsrOxTpepFWUabKqvJea6nOhLksz7IzH5u5rqGfIDjvcl6Srs565OxNjd3DCr+N6pSHguD69p53jfgPVLMdASi7CneWIo1VxQY6wsSTJBwJmBtPVMNpDwHIb8gNDYGMCY6xAYgyPCsZ4BDhlDYyTC3W3NtMSjdGdyvNmf4vRAmrjrsq2hlnU18TkbyhtDGd7sT5EuFEkfjkVUFKU81wczvDmQYtAPRvLKZ8OQiDh4jk3244nQl83x5JUuXEfYVFfDgbYmDHAumealzh5CYw3zjsZaary5mbdsYYy5UnDwXFcT513rVo1kBas0aoyVJceQH/DUtZv44Wi40mAw6tGYyY2NMx79nOVmNsvaRJyrQ5mR0KNMEHKou48bQ3HubG2atUE+0ZfkzEBqTLt9N/vYVl/D7uaGWbWpKMudY70DnEsOjoQxjdHZcvERISM1jo0xZMJwpILShdQgl9NDPNTROustqFJjzJmBNBdSQzy8po2EV3mDrHvGypLjaM8AuXBi3PB0CAxcGsxMiAEODFwbzI5k2Jkp6bzP6f5UiXYNp5Np0nktj6go40nlfc4m0yXjiaciBAb9gMEgHFPK0AC+MbzW3T9ruV7vnTjGhEAuDHl9HmKZQY2xssQwxnB9aH6SZgTGcCk1uxjgq4OZssFMxtjsW4qijOVyeqhs5MF0mOzWgVyebDDzGGBjDNcmyT1wbTBT8VhmUGOsLDFCJlfAuZIrkcFrOvhhWN4YA/l5UF5FWerYwgvzg4jM6o3bMPkYM9X52aLGWFlSuCLUzcN+jW179nVOW+OxsmXZXBHaZhk3qSjLmbZ4tCLlDEvhio0DnimOCHWR8vfVR7x5yS2vxlhZcuxpbihb1HsqHJhQsxhs/KInDhtmmZCjPR6lpkSMswA1nsOquMYWK8p4VidiJFxn1pmzHEobMVdseOFsnTFvbSo9xrgCe+ZY0a0caoyVJceamjh3tDQScQRXRg2rAMPz2eEi38O42C/7utoE71yzirU1cRxsogAHaIpGeOua1pF6yDNFRHhwdSurErEx7bbHozy4uk1jixWlBCLCgx2ttMWjI3ozTLEmujKalNJl9K33vtUt3Luqhbjr4IrgFX52N9WzeRZlG4fpKIwx0cIY44oQdYR9LY3zFqqooU1K1UjnfS6kBhkKAuo8j8AYhoKAGtfFEUj5AXHXJeoIybxP1HHZWJegIRphQ10N62oTJAteyvWeS6oQZ1wf9RjyA/JhSH3EIxeGZIOQWs8jWkhdd1dbM3ubQ9K+T8x1qZnh0vdALs/F1BC5MKA1HmN9TYKo63DfqhYyQcCQH+A5QtdQlqO9/SRcl011NdTOQ1ICRak6gQ8Xj8OVN8GLQH0r9HdiEJJrd3GuroMQq5uD+QDfGNriUdbVJoi5Lm9Z3UrGDxgKAhKei4OQ9n3irovnCKm8T9RxiHsuyZyPI3a5eHiS++i6VSTz/oj+z2Tp2w8NVwaH6M5kJ4wx62sTDOR9jDEExnA5naEr08fqRIyOmnhFl6unHBlEZAPwBaAD6z/zGWPM7467RoDfBd4LDAI/Z4w5WDEplWXH2YE0x/oGMGb6zhACnEul2V5fy+7mBhwRGoviCBuio3PpuiKj5zkONSW+6VHXIerOfC/3eO9AIRzD/n51MMuJ3iQPdbRSG/GIuy4ZP+SZa90YrJe2AGeSaW5rbmDLPGX9mgrVZWVeGErBN/67/defGBpYc/YQa+pX8cId7wcZ1dGrgxlO9CV5qKONGs8lXvgZplg3i2sUN8Umxg6LyKxiiotrFQ87e51PpdlaX8ue5gbbbsTj1Zt9XB/KjlxzZTBDoiB7dAFzU/vArxhjdgP3Af9SRPaMu+Y9wI7Cz8eAT1VEOmVZMpDLc6xvgHAGhhjstaGBM8lBujLly5rNJ11DWc4mx9YqDowhG4a83NVr5TSGFzt7xij4sOyv9w6MvM1XAdVlpfI893eQ6itpiAXwgjy+G0XGeTYHxpANQn5Y0Jvx9PfDrbfaf+eLl7t6yYbhGK/rwMDZ5OBIqs0LqUGuD2XGXWNI+wGHuvsqJsuUxtgYc214ZmyMSQIngHXjLns/8AVjeRFoEpE1FZNSWVacSw6OCdKfKYExnB1IV06gGXBmoHyCgrQfMJDL05XJlb3GGJu6rxqoLisVJ5OGa2fBTB4SeG7dXowzcSvIAAP5PKkSE9SvfhWOH4evfa1Swo5lIJcnXaYWcWAMZwp6anV+4jUGW+s4P8twyPHM6P1aRDYD+4GXxp1aB1wq+v0yE5UcEfmYiLwiIq90dXXNUFRluZD25/5mWKmC3jPud5IkAoJN5TfkB5SLnjRUT/Zi5qrLhTZUn1c6Q0mYRvjQULx8OlgHIVNCrz7/+bH/VppMEE7qxT2sp8XpOccjImQnOT8Tpu1NIiJ1wN8Bv2yMGZ8PrNQzTRiNjDGfAT4DcODAAc2CsEJpikbozuRmlc4S7JetIVodR6iGiFd2mTk0hrqIW3AeEUotwjswZp+7GlRCl0H1WQFqmyCcenLZkO4mnWgYs2c8TGgMtZ7Hl78MTz01evyZZ+y/Tz8Nv/RLo8cffhh+/MfnJDUAtZ5LOElSkIaC30ltxKU/V+4FwhCv0J7xtEY0EYlglfeLxpgvl7jkMrCh6Pf1wNW5i6csRzbX13I2Ochs8+A5Atsb6ios1fTY3lBX2D8ae1ywBdFrPI+Ea0i4DqkSb8AiMqeQi7miuqxUlGgcNt8O549Yj+oybLl8mOutWzDjpnoO0J6IkfBc8nn41Kdg/MJZNgu///v2s+fBgw9WRvTaiDdSwW38SOQKbG+0Y8wtjfW8erNvwtaTA2yorZl1OOR4pmyl4F35WeCEMeZ3ylz2FeBnxXIf0G+MuVYRCZVlR43ncnd700j83nSCA4bjhp1CQe9qvV02xSLc3tKII1YeK5fQEPW4u63ZyirC/atbqfFcvMLzDT/rPe3N81LxZTqoLivzwn0/Aqs2gRsBx4XhcB8RQscjcFxSta2YwvHhdSO34AF9V1sTAB/+MBw+DFu3QmJc7p1Ewh4/fBh+8icrJ/rdbc00FEKhiseY21saaSqMMWtq4uxoqMUZPo+9pi0e5baWylVjk6kSXovIg8CzwFEYWVn898BGAGPMpwtK/gfAY9hwiI8aY16ZrN0DBw6YV16Z9BJlmeOHIdcGs2TDgDrPpS+XJ5UPaIh4ZIOA3pxPjWuzYiWDgKjj0BSNMJD3cURYFY9WbFZazJAf0J3NTdpHPgy5OpghH4a0RKM0xyITEnsYY+jK5BjI54m7Lh2JON741F/TQEReNcYcmPUDjbYzL7oMqs8K0HMVrp+zccY1TXD+KAhkNu2l//pFCAIim24lWdeCH4Y0RSP4oSEXhjREIyMT7L4+aGuD4m1k14XubmhsnJlIwzqYDYIxfYy/pjebpyeXI+I4rK2JEymh85kg4Hqh4lt7PDrr8ozl9HlKYzxfqPIqwyTzPi929pANQgympKf1/pZGbmazXElnEAFBMMDe5no2VShuNzSGw939XE4PFfVhuK25gc1Vig2Gyhnj+UT1WQHs1tPBb8HxF8Bx7NL1eE/rhnZ6Hv0YL/UkCc2wq6OhIRLh3lUtfPvrDh/5CAwN2eZE7JvxX/wFPP749EXpyeZ4qbN3TB/1kQj3rWomNouc1ZWinD5rOkylqgTG8Nz1bgb9gMCUNsQAr/X0czltS40HhpEY3qO9yYrFHJ/oS3JlcGhcHzY2uHOoOnHNirKkOPkinHgRQt/GHZcIeTIDXXS9/E1yYTiix4GBvlyeFzt7+MIXIJWC/fvh+eftv6kUfOEL0xcjGwQ8f6NnQh/9uTwvdPZU8IErhxpjpapcTWfwp7k6U+qqwBje6EvNWY7AGM6NS+Yxeg5O9Sfn3IeiLGuMgSNPQZCf9DIBtl45gozzwjZAMp/n5KmQX/91eOEFuOce+++v/zq8+eb0RTmfHCxZc9gAqbxPX3ZyGauBGmOlqvTl8rOqOVpMf37uijU0Rexvsmxog6IogH0Tzg5O61IxhniuVPIb4WvPZ/jkJ0fDl10XPvlJeO216YvSk81PGjpZiTGj0qgxVqpK3HXm/CWMVsCJK+o4JWfSw0QqFEuoKMsW17P7xNNATEjem1j9SIBYBXQt4ZVvQxBi8+D4OVcWn0TKimK29YOHcQW21s89bjfqOrTEoyXDrJwK9aEoyxrHtTHHJdJeFmOAm80b8L2JRVpEoL0Ctb8319WWrXkuAqsSi6++uBpjparEPXckbneyoJ+WWISY44ytUSxCSyxaMU/nO1ubiLol+ohGq1ZpSVGWFHe/F+qabXhTGUSEgX2PjilzaGN4bRx+JcoSNsUibG+oG6PLw33cXaE+Ko0WV1UWnFQ6STaXo7m+kQxQF3F5cHUrF1NDpPI+EUdI5vNk/JCo67CrqYENdQnyYcil1CDXh7J4Imysq2F1IjYS3zuQyxOEhsaoh2/ANyFx1x2jeDauMSDquGNifm34g+Gtq1u5PpTl+lAGt9BHR1Ef2cDWTI67zoS4YkVZaYT5LLmuK7h1jXh1TWSyQziP/ByxG+fg3BF7keNA5yXrWb12O9zzODtq6mnL5jiXHGTID2iORdhSXzuSECcXhiRzeWo8l5jrkgkCPHHGlCs0xozkl46PS6STC0I21iVYFY9xPlW6D1s1KiDiOCXjihcaNcbKgtF5s5MfDmTwncLXrr/T/lswas3RCG9Z1czJgTSdmRyIkAlCrg1mWJ2IEXUdtjbUsXVcKsyLqUEOd/dPcNiw2XSEWxrr2Fib4PXeJJcHh0bihzfUJLi1uYELqUHeGEhZg2ygJRZlX2sjtUU1kfuyeQ5199m81GL3mPc01bOhiqktFaVamCAg/a0/pbbrHHbBV+hu7ODQzrczlGikIR9j375304gPLzwBftbqeddFuHEOttxOcyw6pk4x2ERAP7jeTf+4/O/DWbta4lH2tTSS9gOO9PSPOF7WFFbYEp7Loe5+erM5pEj/97c2jkyeQ2M40ZfkXNI6mxljWJ2IcUdrU0X2q2eLJv1QFoT+gT6e6il4Wk7yRjm8rFQcYiRYZXv72vYxS1sA19JDvHyzb9K+HeyecC4Ixxjs4eP5MJwQ0hRxhHeubSfmuiTzPk9fuznB69stpOacb4OsST+UxcbgP/wBib5rY7aWQoR8JM737vkIeS9G88ANHjryBDI+Z7UbgQd+HLbcPqHdb12+MWmVJABPbPq48TkJhlNsjg+VdAV2NNRxS1M9AK909U7ILy9AwnN5R4kxptJo0g+lqhy6USixN8UXPTBMMIwGRt6Qx3OkZ3zRoYmEhfvHq/jw8ZKxxaGxxSyAU33JkuFXgYFjvclJvbAVZbmR67s5wRADOBjcIM/mq8dAhO0XXyldPCLIwyvfmFAopnMoM6UhBvDNREMMdpwolbMgMPDmQBo/DEnnfa4NTiz0YoBsEHI1PTRl//OFGmNlQej3ElMa4skIjClpjDMVKuw9nhC4Xuivc5IMX74xi6I+saIsFNnTB8ue80KfNTfPANDed6W8U2Z2EAbHTqQvpebPEAo2p8HNTK7sMBQYw7UqZtpTY6wsCFK6JO6MmO/lo/EMO345k/h5G2MWpWemoswX4k7uahQUQptMidrFIxhj45KL251nPXJEpnwfKBcOtRCoMVYWhFVhZtb1i8Ea4lIxyQ2R+fFBdAU2FvpbXxsva45rI17VSiIqSjVI7Lm/7Dnf8bjYsQeAK+3bCMtpTtMqiI8NF9zRMH/hg45YB9GORLzsMGTHmOo5ZKoxVhaEO9ZuQEw41iCX0Io6z5nwBuwKtMaitMUnJgkYroU6Ga5AWyxasl17fOz1jkCN57Gx4Ji1o7GOmDvx/XjYgUtRVhJuLEFqy50T1roCcUnVNHNl9U6cIODC2tuQWA2MeUMWG4N83/sntFsfjdBeQseLcYDaQp3w8XiFc+ON2rCeikghVLK+zBgzdf/ziYY2KQtCPBHnXR2t/PDKFXq9BCCF+mgAgivCtvpadjfXc20ww6m+JCk/IOY6bK2vYUt9bcllrIZohIfXtHHwZh8DhXAIV0AMGBGaoxF2NdXTEotwMT3E6f4UQ0FIwnXY0VjHhtoE3dkcJ/uS9OV8PBE21dewo6EWtxCHHHNdHl7Txqn+FFfSQ4TGFhbf1VRfsj6qoix36t/6QVINrcSPPY3r5wjF4cqqHRzb+ha8IMeG/AA7t25Htv0rOPx9W9s4DGDNNtj3CDSvLtnuW1a3cqx3gLMD6RGHy4hYp62Y67CprobtDbVkg5CT/UmuD2YRoKMmzq6mOiKOw+mBNBeSg/jGjOh/a5GR3dFYR13E41R/klQ+IOYUxpiG0mPMQqGhTUpFGMjlOdmXojubxSksKe9orJteML0xNkHA689Auh/qmmDv22DTbXNy+louaGiTsqCEAZx6yZZCzA5aw3nHO6whnQaDvs+pvhTXh6yhXFMTZ2djnW7nFCinz/pmrMyZ7kyOFzp7isJ/DGcG0lwZzPDwmrapDfJL/whnDoJfqKTSMwTP/R3cvAwH3jOvsiuKUkQYwnc/D50XR0sh3jgP3/szuOd9sPPuSW9PFcXkD48GF1KDXBkc4uE17dSoQS6L7hkrc+a17r4JcbghkPEDTg+UKpNWRO8NOP3qqCEexs/bQuXJxVkIXFGWJZdPQdeliTWJgzy8/DXITx76c7SnH7/IEION4c2HhuO9U+cEWMmoMVbmRDrvMxSUjrMNgUupKeqbnj9qZ+OlMCFcODY3ARVFmT5nDtq6xKVwHLh6uuytoTF0ZcrcCyXzBCijqDFW5kSIQSaJwy2VKWcMQd4a3ZI3h+UHBkVRKk9+En0zpnRGrQJT6XoImq1uEtQYK3Oi1vNwythiAdoTU4QKrNkOJeqaAvb4NJ1GFEWpABt22dzRpQhDWL2p7K2eI9RGyu8JN0cjWulsEtQYK3PCEWFXY33JzDWOCDsb6ydvYO02qG+dWJDc8aBpNawqr/yKolSY7XdCND4uNhhroDfvhdqmSW+/rbmh5FjgCuxpnmIsWOGoMVbmzNaGWm5tbiDi2HhhB5sZ64HVLdRPlSFLHHjs52HjbmuAvaj9d/Nt8OhHNbRJURaSSAze93FYvdlOkL2oNcS77oUHfmzK21cn4tzZ2kTcdXDFGuEa1+Xu9mba4rH5l38Jo6FNSkXYkoiw6dolBm9cxHU9EptvhWib3Q++8iacec3uN23cA1v2jl0Ki8bhbT8NuQwMJe2xc0fgmb+CumbYeU/ZJAEzIZ33OZccJOX71Ec8NtfVjKlZrCgKUNtE/9t/lkvdN/GH0tQ2tbCxsZGY4zLkB5xPDdKfy1PjuWyuq6FhXOKbtbUJ1tTEbQEVE1Jz4yzy8pPl9X8WhIXCMVfSGURgXW2cjkR8SeeJ15FImTvpfvj6p3FyQ9QNhyidO2T3e/2cDZUYdsS6dgYOPwnv/Tgk6sa2E41DzzX43hfs/lTo2zfjN1+FO98Fex6YtYiXU4O81tOPMTbUonMoy9lkmjtbm1hXIue1oqxUTvYlOT2QIjRg3FqcVJY3Ul3sbqrneJ8tGRpifUIupAa5tamBrePySosIta7Ad78IXRcn6v/7PjEhN/V0yYchP7jeTdoPRkIqbwxlqY+keGB1K950Eg0tQpam1Mri4gd/a99oi2OF/RxcOQXXz431iPZz1ni/8MTEdgIfnvxze01Y8No0xnpcH/wO9HfNSrxsEPBaT78dXArHDNb782B3H7lp1FBVlJVAbzbH6YEUQZGuhMaWCj3aO0BQMMQwqkPH+gZI5Ut4WR9/HjovlNH/v5+1jMd7k6Ty/pjcBoExDOR9TvYlZ91utVFjrMyNoZRVuFIhC2FYOmzJhHDlDbssXczlU5OEOQVw6uVZiXg5PXl84+UqFhRXlMXEueQgwQyjj4yBC8kS+QROvjAxeQhYHb/8xpQJREr3ZbiUHqTUKBEauDCPNZHnGzXGytzIpCfUJZ0WjgO5cYozlCxvjE0I6b6Z9wNkgqBsDGRo7HlFUWDIn7kuGCid+Cc7ScIfx5n8fBkCM3k8s2/Mko1lVmOszI26JvvWOmMEEuNCHZo7JoZUDON60LZ+Fv1AYzQyoWTaSLMiWnlJUQo0xyIzNgqOQFMpHWpon+SuEvo/DVyB6CR7wgnXWbKxzGqMlbkRicH2u0p7RzruxPhhGA2VGP9GvWoT1DaWNsiOCztmV7hoTU28rDH2RFhTE59Vu4qy3ChXqlSwxqKUFjnISO3vMdzxDlu7eDxuBHbdN6sVNRFhR2NtSX12BXY21pW4a2mgxliZO3e/F9bttMrlRQqxiZ6t8nLnuwrHo6PHN90K+981sR0ReNdHoaFtNL4xEoNYDbzr52btfemK8GBHC3HXwRMpxD8KCdfhgY7WJR0OoSiVJOG53LuqGU9kjK40RD0e6mij1nNxC8c9EaKOw1tWtxB1S5iSjbvhjneW0P/bYP8js5Zxa30tm+oSOFCQxeY22FJfy6ZSk4IlgtYzVqYmDGyC+FSvzZa1Zpvd8xnP038Fl07Yc7e/E6JRa2Ab2uDsIettvf0uWLPVXp8bhCNPQ7qfcPVmujbcwWAYUuM4OAM3SaWTxGMxVq/dhDObfelxGGO4mcmR9gNqPZe2eHRJLGlpPWOloqR6rT6L2El0TcOES/ID3Vx/9fvkjVAbjbJq3RYkmyKsa+N8w2p6sz41EZcdDXUjoUTpm1cZunIG8SLUr95AtOfqOP33Yced0LG1Io+R8QM6M9YJbFUiRtxdGuUZZ13PWET+BHgc6DTG3Fbi/MPAPwDnCoe+bIz5zTlJqyweeq7Cdz5nDakJ7RJyNA6P/jNoLOwJ9XfCE787ek8AvPp1+1mc0fscBy68bvPftqyFg9+2t9e28sLaAwTXOwm8CAYBPJxIM44R5OpN7m1voTU+RZ7rKRAR2hMxJtvJWu6oPq9gTAjP/4M1jCJ2zTk0sPt+uOvdI9nust/4LNHOs4zx0DjzIulYPS/s+wCZXC/GjeCIcC45yN0t9bhPf4nG7gvEjMExBsEQimOXXsfo/1Gr/w/9ZOktrBkQ99zSy+NLlOksU38OeGyKa541xuwr/KjiLhfyOfjWn1iPaT9n44D9HAwOwDf/eNRxq9gQj2fYO9qE9v7Ah4snRgyx73g8t+/HyEZq8L1owRBbQqx3ZD40vNDZQ1a9nivB51B9XpkcfQbOH7Yx/EHeTrBDH069aGuKA5njLxLtPIvAmB+A5/d9gHSsnsCNjNHNFzt7SPRfxw0DPBPiFLTYMWFp/b90akT/lVGmNMbGmGcArfC+Ejl/pLyntJ+zS9LXz5U+PxlFbV5dtZ1QnClzUBsMF6aqjaxMierzCsWEcOwHYxPzDOPn4chTAERe/UbJ2282rScbSZTenjKGy6tvmb4sQR5OvTRpOcaVSKUcuO4XkcMi8g0RubVCbSrVpuda+XrCfg76OuH0a3Pqor+2laBcCcUiQgN92RIDiTIfqD4vN/LZyWuDp/oAcEK/pMf0QG0LpkzYYehG6K+fxebP0NLNljUfVMIYHwQ2GWPuAH4feKLchSLyMRF5RURe6eqaXWpDZQGpbSoffuBGbJzgmi1z6iKRTeGUytIzDgFqvKXhoLHEUX1ejnjRyVefYjY/u8GhlEtvIpu2y84lkDAgkZmhYQ1DGyWhjDBnY2yMGTDGpAqfvw5ERKStzLWfMcYcMMYcaG9fyW40S4Rt+yY/v3kvbNs/83aLBoUNN96Y9i2b62cX2qRMH9XnZYrjwtZ9ZeL+PbjlHgBy2+8sefvq7nNQ0kzbifLGq8dnJsuGXTZsURlhzsZYRDqkEB8iIvcU2uyea7vKIiBRDw/8uFXWYSV2PPtW/PBPWa9qgHt/ZPptelGoa7HhUUAsP8SdJ7+LE/g4JfaQBJvh59amBuq03OG8o/q8jLn7vTYConhbyItC6zq4/e3098NdH/sxenKNGMYWVXFMyL1Hv4Yb5Ef0dFg3b6mL4ZkAv5D4p/jeCXhRu+J23wfm4QGXNtMJbfpL4GGgTUQuA/8BiAAYYz4NfAj4hIj4wBDwU2apJgddiRgDyR7rVNXQNtFBY8sd0L4R3vihrZrUtBp23m0zZQFkBm0pxIc+DD/8GmRS9nhDG9Q0WkPeuq5QRi0PO++C9k3Wi7PvJrz+FOvSnTRffI7zux4m5URJeB4OkA58alyXzfW1MzbEQ35APgypjXhls2+tRFSflzm5jN3/TdRNLFEaicHjvwCXTtoQQ3Fgy+2wdgc4Dl/9Khw/Dl/yfpmP7vousVMvIiYgjMSRVZtpC3K8q/cUZ9feRq8fUhuLsrmxCREIfuyXGTx9GLl8itCLkmhqoybVjYgDTe3Q3211fsNum/RnJnkD/DwkuyGaGB13liGa9GMlc+0MPP/3tvKSiFWQu949vbSTvg/f+mO4eWn0mBeBt/20dRR56auFUojBRI9sETtDNgZufRDueHv5nNQzZCCX59WbfaTyPo4IBtjWUMuuxrolkeCjFJr0Q5kSPw8vfsVGQDguBAF0bIEHPzTRKJfgSnqIxx8TDv0gzr6HMnzyz3ppi0W4vzGO88ITcOVNjOOCn8Ng8J0Ib2y+m3Prbkc8DwM0RCLc2dZEfaVWsEwIr30XTjxvx4cwsC8DD/3EaI6DJcisk34oy5Sbl+F7fza2xNmwEXUc2FZ672iEr/0R9N0Ye8zPw/e+YI36ZGELxoyWTzv2rFWyOx+d3XMUMeQHPHu9G78wwQwL/54ZSBEaw63NEzMNKcqy4Mk/h87zo7G8YCfbX/80fOCXS76JfvnL8NRTkAl8rg6GHHvZOlQdeynG//hkAxjDhs43eNd2lx+/y0fC0eXpfDTO+bW3EbreyJp0Xy7Ps9dv8s617cQqkQ3rh1+HN18ZG47VfaXwTP/LtCYZSwk1xiuV175butZokIdXv22dPcq9rfbfnGiIx7Qxg/hBP2+LkO9925wdOs4MpMcUHB8Rx8DZZJqdjXVEJqn4oihLkp5rtqb4eL0zoU3Yc/G4XY4eRz4Pn/oU+L4LjDpH5nPC1z5XCxg89w7evuXUhHtjuSEa0930NK4ZczwIDeeSg+xqmnlFpjFkB+3WWKmxxPdtreRS+e2XMDoyrVQ6z5c/lxuyS9flOHe4srI4DnRfnXMznUPZso4jDkJfTuOUlWXIjXN2takUfg4ul45Y+PCH4fBh6NgYEI2PDVuKxkM2rElx+Dd/n5+85/UJ9zqhT1vflQnHQ+DGUHbGjzCBm5fLp8sMfbg8cYKw1FFjvFKZzIHCmMnPRytcctCY0qXWZojrTL4nrI5cyrLEjVi35pIIRMon1dmzB37nH2/i58fe7+eFL//377Nr3c2S9xlx8J3SY4RXCT0rVZJ1TCdzy1O/GFFjvFLZuq90ajuw3s+TBeTvvLuyskRi0Lp2zs1sqkuUNbiuCM2lCqArylJn457yb8auN2UugKuHa4jFDa5ncByD6xpiccO3Lt5BWLaYg3C1fdvE7gQ21VcgmceqjeW3ybxI5cegRYAa45XK7W+HeP3YpSBxrGG8//2T3+tF4ba3lj8XjU/TO1rsDPiBD1bEm3pDXQ31EW/CS4IrsL+tccl6UyvKpMRrbX3g8W+TXgQ23wZt60vfV+D5J+oZGhS27Mnzn7/czZZb8wwNCt/4xipSm+4ouWo1GK8nH4mPFoLAvpw3RiOsranAypnj2nFh/DO5EWheU3IPfKmjoU0rmeygTR5/9pD1aF6/yzpS1bdM7/7TB+HVb1onEceBdbvgwQ9aT+nXn4ELx+yMXWQ0D200YWfrJoRVm2xYU8vc34qHCYzh3ECa86lB8qGhNRZhZ1M9TUv4rVhDm5RpceVNOPqUzQeQaLBhg1vvmLIIy7598PiPhjz28V568jn8AL78B/Uc+l4Nrx8SG5P8+jOQ6sePJcgGIV5uiJstGziz40HS0VoijsOW+hq21NfiVHLSe/MyHPk+dF2yY8ct98At984sTnmRUU6f1RgvV668YT2m+27Yt90dB2Dvw+X3j7qvwnf+1BroCQhlc+p4MetQ4UUgEreOX64DsTrIJO29G3bbmft0jbwyBjXGK5zsIBz+Ppx9zUYftK23nsSrN5e/59m/gbOHKa23xfpc9Nn1RuuPx2ttCVU/Z7esTGgn2TWNsPetsP2uKY28UhqNM15JvPmKjRceDl0KfDj+nPVAfN8nJs4q+7vgq384SYOTTNj8gudkLrDZf8C6VOaLqvSdO2L7fvwXoKF1pk+jKCuXXAa++ke2hvhw8pwb5+E7n4O3fdhOdMfztU+PTcYzAVP6c3EYUbp/9HNxdaVktx1buq/CfT86/edQpkT3jJcbfh5e/trEGOLAt4p07sjEe7735/MsVCHJR5laqYqilOHki9YYjs9iF+Th+SfG7NkCkOqfwhBXgCAPp1+FAU1ZXknUGC83bpwvv3zkF5RoPMnS4QuVxdi3Y01zrCjT58xr5ZPo+DnovT722KHvzL9MYPX44gwqNSlTosZ4uTF+Bj3T8/NJqIZYUWZEmRrCgJ10B+PfmGeQ/W4umLC6Y8kyRI3xcmP1pvJK4kZg420Tj8cXKMfr6k3q9KEoM2HD7vKZqABaxqajLBtyWGkcD9btWJi+VghqjJcb0QTsfsvE+DwRiMZsCcPxPPih+ZfLjcBdj81/P4qynLj1wUKc7/jg+Qjse2SiM2brWluHfD5xPevJ3bpufvtZYagxXo7c+Sjsf+doTK/jwrqd8L5fsMfGs25HIfHGLN9aHdeGRDiF0AhxCv069lxzB7zr56B9w5weS1FWHDUN8N5P2HKITkGvEnVw7+Ow5y2l7/ng/woNcygx6BTGDGRUt4d12ovAjrvhHT8z+/aVkmho03JEBG59CHY/AJmUjTMuVREpDGxijtMHrXPXjgPQ12nDKTbtgU177TVBYKuk9N2wCTp23VtQTtfGMl47Y5e6d91nDa8XsVm4MmkIQ5vI/shTdj9r4x7Yfmfl81srynKlsQ3e/c+tXgZ5GwNcKmPdwE048QL0XIWmVfYtueca1DbCngcgUWvfqK+fs46c4tgkGq3rrZ6neuGNl21c8/pbYOt+q+PxWrtHnB2yRWTe+CF8+7NQ12J1XifZFUGN8XLGcezMuhR+Hr71x9b4+jl7rLiSU7LbKvYt99kY5dC3HpR9nXD+qA38P/YsBKE9B3D9LGzeC2/5Mft7JArf+hPr8Tncx83LNpvP+z5hBwlFUaZHNA6UmcRePAHP/JU1quOdvvo7rW5vuhVuXLAT9OEawb3Xoa7Z/lw/O6qnvdet3r/nXxTGEBe6z8DTXxrto/OSnczf/rD9UeaELlOvVI49O9ZIjifw7Uz86FN2Nj4ckmRC+/uh79kMPWGR96afs4b6SqFk27Hn7Cy9uI8gbweDF56Yh4dSlBVIPgvP/lVBT8t4X/t5u4qV7h81xGB1s7/L6uwYPS3o/9N/OXrdM+P7MPb3I0/ZSboyJ9QYr1ROvTw/YRB+ziYqADj1Uuk+jLFL28MZuxRFmT0XTzDBwasUxpQ21iYsb8STvdZYXzxRvt0wsEvXypxQY7xSmU9DOJw+b7I+HMfuPymKMjey6fmL+XVc6/uRHbT+H6Uw4diUmcqsUGO8UmlePT/tigPtm6buQybZz1YUZfq0rJ08FnkuhD40FpzBytU/9yK2/rAyJ9QYr1TueMfEWOTxOG4hjnHcEpgU6hCX8uh03dGQizveWboPNwJ7Hpy/AURRVhKrN0Nd09Q1wYfDk8YzHP5Y6viW2yFeA+0bob65dB+OB9vunI3kShFqjFcq62+Bu99rDWMkNqqkjjP6+8bdNja5oQW8qC2X6EXsTPnxf2njk11vNHQqloB3/NPRykzrdsA97yuUV4yNtrvjLrjj4ao9uqIsK0Tg0X9ms3G5EXCjjEygh3UvVmNj/fc8MFZn3Ygtb/rwT9sSqMV6umEX3Pf+0T7e9c/sG7IbKYwFURsR8e6f11DFCqD1jBcbvTfg6pv2y79+1/yUHBzuA7ExjBePW0errXfYY/kMtG2ws22wjh83L9s4xIbWsZl3Brqtx3Ssxs7QS82w/RxcO2uXvFZttkkLlGmj9YyXKH7OOj6l+6ChzRq3Sq8G+Xmrv+k+G56U7rf6WN8KG2+1RWBiNbB6y+gyc3bQxhqLwJptozkIAt8eH6//4+m9bp26ahrsG7OmuJ0RWs94sRMGNnTg8qmCZ6PAwW/b5Z/7frQyX/gwgGf+Gi6ftAY2DBmpZyqOjRns2AJv/8jY5SwRG9hfKri/oXXqCYMXtQORoqwUrp+DJ//M6lmQL7xNRuDRf145f40b5+F7X7B9+HnG1Cb2ojZO+B0/Yw1uMbEaG3M8Hnea+aabO+yPUlF0mXqxcOh7cPkNOzsNCxVRAt+WUHvj5cr0cfj71tgHfsH7skh5h+OHr5+FV75Zmf4UZSWSHbJGMp+1b8fG2H8zaZu5qhKez7kh+O7nR/tg3Aqnn7M/T/657VdZ9KgxXgyEoY3NDfITzwV5OPrM3Pswoc2oVaqPMf358OYrC1eKTVGWG2cOlq/b7ftw6WQF+jg0vdrgJrT6rCx61BgvBvKZyY3fYH8F+shBUCbbVikyqbn3qSgrkd4b5Se9Qd76WcyVvkn6GNOfb/d4lUWPGuPFQCQ2eVhCvHbufXhRG4IwLYzdV1IUZeY0tJQOIQJ7vBI52etby/dRjONa5zFl0aPGeDHguLD9rjIxgBFbn3jOfTjl+xgvy+a91ngrijJztpeoGT6MiK1cNle27Z/edSK2Gpuy6FFjvFg48G5oXlNkBMV6X67ZaguMV4K73m2z9ZQztF7UxhDf83hl+lOUlUiiHh76STvxHZ78uhGrX+/8WavXc+6jDh76cCGuuMQEezhhzwMf1OpoSwQNbVoseFF478dsPO7F4/ZNdvPe8nF8V960ZQ7XbLexwsP03rD1g5tW2zClYfI56L1mi5JnBuHSCbs03rTKllgLQ5sIpKbR7kc1d9h8s0MpaGyvzFK5oqwUNt0Kq/4tnH7N6mnzavs2G01MvHYoBRePQazWvjUPxwP7Plw4avd9N+8dm1ij/6bNjPX4L1iHsGS3XboG+7mu2baVGyrEBDda/feiVrc1NnjRocZ4MSEOrN1uf8px+RR8/y/Gli6sa4F3/gx8+0+sYg/jReGRn7MJPo79wCq5MVapH/wJ+9Y9TOdFePavRx23/LyVx4vYUIxNt8H9H6jMrF5RVgKJelv3uxyhD9/8LHRdHD0mAgfeC4MDtszpMC88ARt229Wtp/4Skj327TcsGOr73z+aejbw4aWvwlf/0Opw4Fuv6uEVsWgCHvzQWP1Xqs6Uy9Qi8ici0ikir5c5LyLyeyJyWkSOiIgmKZ0vBrpt/GI4zvM61QP/8HtjDTHYOMNvfsYa4iA/GpM4OABPfmHUy3KgG77zpzbDlp8frXdqQntP4MOF121SEmVJo/q8iPjWn441xGAnyz/82lhDPMylE/CV3x/1pB6Owjh/FJ75m9Hrnn8Czr5mz/m50fKIw7HHg/0F/b8xb4+mzJzp7Bl/DnhskvPvAXYUfj4GfGruYikleekfZ3dfqRAI37dJQMAq/lRxxYFv37ArEZahVJPPofpcfTKD0Hl+5veVShgS+HDllJ1MDw5Y4zwdfT7y5Mz7V+aNKY2xMeYZoGeSS94PfMFYXgSaRGRNpQRUiui6VMHGjE2nB3DtTPni4sWIU2EZlIVG9XmRcPXNyrY3rJs3r9jKaVNhivRfWRRUwpt6HVA8Ql8uHJuAiHxMRF4RkVe6uroq0PUKo9L7tcMJ4iPTrLgiMnqPslxRfV4IKu0QKQKR6Mz001NdXkxUwhiXcssrmafNGPMZY8wBY8yB9vb2CnS9wrjl3sq15Xqw8277eefdU9c2BjubXjeJc5myHFB9XgjWbq98Bac122H1pqnrGsNY/VcWBZUwxpeB4nI+64GrFWhXGc/et9myZaVoLDMY1hVqERcrqBuBhnbYVTDu2+8crVNaErHnHvjg9Iy2spRRfV4o7v9A6eOOR+k5EbYEafEKmRTrpmcN/EM/YY+VC19yI3a82HXfHIRXKk0lQpu+AvyiiHwJuBfoN8Zcq0C7yngcBz74K/DyN2wy+sC3wf8HHoMtd8Cpl+DQk7ZeqRexb9L732W9J19/1u5TeRHYcbfNyjOs1K5ni5OfPmgrRGWHoL4Zchn707rOhmi0llytVJYXqs8LxfY7bTzwi1+BgZtWv9fvgre8H/J5eP7vbRU1Y2yynvvfDy0dcO4onHzBRk+0rbOT9Ja1o+2uvwXe9wk4+rT11vaiEK+zUReR6ET9VxYFYqao/CEifwk8DLQBN4D/AEQAjDGfFhEB/gDroTkIfNQYM2WZEC1GrijTo1wx8lm2pfqsKFWknD5P+WZsjPnpKc4b4F/OQTZFURYI1WdFWZxobmpFURRFqTJqjBVFURSlyqgxVhRFUZQqo8ZYURRFUaqMGmNFURRFqTJqjBVFURSlyqgxVhRFUZQqo8ZYURRFUaqMGmNFURRFqTJqjBVFURSlyqgxVhRFUZQqo8ZYURRFUaqMGmNFURRFqTJqjBVFURSlyqgxVhRFUZQqo8ZYURRFUaqMGmNFURRFqTJqjBVFURSlyqgxVhRFUZQqo8ZYURRFUaqMGmNFURRFqTJqjBVFURSlynjVFmC+CcOQ7u5ufN+npaWFWCxWbZEURZklg4OD9Pf3E4vFaG5uRkSqLZKiVIRlbYyvXbvGSy+9RBiGiAhBELB161b27duH4+iigKIsFXzf56WXXuLatWs4joMxhng8zlve8haam5urLZ6izJlla5F6e3t5/vnnyeVy+L5PPp8nDEPOnTvHkSNHqi2eoigz4Pnnn+fatWuEYYjv+wRBQDqd5vvf/z6ZTKba4inKnFm2xvjEiRMEQTDheBAEnDlzhnw+XwWpFEWZKclkks7OTsIwnHAuDEPOnDlTBakUpbIsW2Pc3d1d9pyIkEwmF1AaRVFmS29vb9ltpTAM6ezsXGCJFKXyLFtjHIlEyp4zxhCNRhdQGkVRZstkugyoU6ayLFi2xnj79u24rlvyXF1dHXV1dQsskaIos2H16tVlvaZd12Xbtm0LLJGiVJ5la4y3bNlCS0vLGIPsOA6RSIR77723ipIpijITHMfh/vvvx3XdMUbZdV02bNjAqlWrqiidolSGZRva5Loub3vb27h06RJnzpzB9306OjrYtm0b0WgUY4zGKCrKEqGjo4NHH32UU6dO0d3dTSKRYPv27bS3t6suK8uCZWuMwc6oN23axKZNm8hmsxw6dIhvfOMbGGOIxWLs2bOHbdu2qSIryhKgvr6eAwcOAHDp0iVee+01BgcHAVizZg379++ntra2miIqyqyZ1jK1iDwmIqdE5LSI/FqJ8w+LSL+IHCr8/HrlRZ09vu/z3e9+l4sXLxKGIcYYMpkMhw8f5tixY9UWT1EWjKWuywBnz57l5ZdfJp1OY4zBGMO1a9f4zne+ozHHypJlSmMsIi7wh8B7gD3AT4vInhKXPmuM2Vf4+c0Kyzknzp8/TyaTwRgz5ngQBJw8eZJcLlclyRRl4VgOuhyGIYcPH56QQ8AYg+/7vPHGG1WSTFHmxnTejO8BThtjzhpjcsCXgPfPr1iV5dKlSyUTgIBdyu7q6lpgiRSlKix5Xe7r65swqR4mDEMuX768wBIpSmWYjjFeB1wq+v1y4dh47heRwyLyDRG5tVRDIvIxEXlFRF5ZSAM41Z6w7hkrK4SK6TJUR59VV5XlynSMcalv//ip6UFgkzHmDuD3gSdKNWSM+Ywx5oAx5kB7e/uMBJ0LmzZtKhtzbIxhIWVRlCpSMV2G6uhzY2Nj2WxcjuOwcePGBZFDUSrNdIzxZWBD0e/rgavFFxhjBowxqcLnrwMREWmrmJRzZOPGjdTW1k5QYtd1ufXWW6fM8KMoy4Qlr8uO43DnnXdOmFyLCNFolB07dlRJMkWZG9Mxxj8EdojIFhGJAj8FfKX4AhHpkML6kYjcU2i3fHLoBcZ1Xd75zneybds2PM9Gc9XV1XHPPfewa9euKkunKAvGktdlsJPrBx54gKamJsDq96ZNm3j00Uc1NaayZJkyztgY44vILwLfAlzgT4wxx0Tk44XznwY+BHxCRHxgCPgpU87LokIkk0lOnjxJZ2cnnuexbds2tmzZwsDAAM8//zzpdBqwihqLxRARampqqK2tJZ/P09zcTH19PQBdXV2cPHmS/v5+amtrueWWW1izZo3uTynLisWqy2EYcvHiRd58801yuRytra3s2rWLpqYmDh48yJkzZ0acthKJBCJCJBIhGo2SSCSIRqO0tLQQiUTI5XKcPn2aCxcuYIxh3bp17Ny5k0QiMZ+PoChzRuZZz8py4MAB88orr8zq3u7ubp5++mmCIBhRUtd1SSQSpFKpabUhIiNJQS5cuDDG23o43+2+fftmJZ+iVBIRedUYc6DackzGbPU5DEOee+45Ojs7R3RwWDej0ShDQ0PTasd1Xerr68lms2Sz2ZFyi47j4HkejzzyiOajVxYF5fR5yeWmNsbw4osv4vv+mBCHIAimbYiH2wmCgLNnz04IexquedzX11cpsRVFKcHVq1fp6uoao4PDujldQwxWZ/v6+hgaGhpT9zgMQ/L5PAcPHqyo3IpSaZacMU4mkwuSZScIAs6fPz/v/SjKSmY4b/x8Yozhxo0b896PosyFJWeM8/n8gu3l5vP5BelHUVYqC6VjIjLmjVlRFhtLzhg3NjaWzcBTSTzPY/Xq1fPej6KsZDo6OsrGDVeSWCymIYzKombJGWPP89ixY0fZJB4zYdhJZPxgMByzuG5dqeREiqJUiu3bt5fU5dmsfjmOU9Kwu67L7bffrtERyqJmyRljgL17944YZM/zcF2Xmpoa3vGOd7BmzZqS9wzHF4sInueNeFI/9thjI7PzSCSC4zi0trbyjne8oyIGX1GU8sTjcd7+9rfT0NCA67ojOrhlyxYeeeSRssZ12LAO639tbS0PP/ww9957L7FYDM/z8DyPSCTCHXfcwaZNmxb60RRlRizJesYiwu7du8nlcly/fh3XdYlGozz77LMArFu3biTOeOfOnTQ1NeH7Pp7ncebMGQYHB+no6GDLli14nseDDz7I0NAQ6XSaRCKhNVEVZQFpampi3759HDlyhGw2S1NTE9evX+fixYvU1tbS0NBAMpmkqamJ3bt3k8/n8TyP3t5erly5QjQaHdFzsPrf399PGIY0NTXppFpZEixJY9zb28t3v/vdsnvHV65cGfl88OBB6uvrWbduHcePHx+pf9rV1cXx48dHZuWJREITAyhKFXj66ae5cePGyO/FIU3JZJJkMglAKpXiypUr7N+/n+PHj5PL5fB9HxHh0qVLbN26lX379uE4Ds3NzQv+HIoyF5bkMvX3v//9aTtx+b5Pf38/r7/+OmEYjtzn+z7ZbJYf/OAHC+IQpijKRM6ePTvGEE9GGIYEQcArr7zC4ODgSKhScc6Aq1evTtGKoixOlpwx7u7unnG84GQhDZlMhp6enrmKpSjKLDh+/HjF2gqCgFOnTlWsPUVZSJacMe7v7694m4ODgxVvU1GUqclms5OeHxyM8G/+zbsZHJxeWJLqsrJUWXLGuKWlpaLtGWNGCkYoirKwTOWn8eqra7hypZGDB0tHSYxHdVlZqiw5Y9zU1DTjMmnlkgqICPX19SNemIqiLCy33377pOeffnrzmH/B6m2pmGHXddm9e3clxVOUBWNJelM/8sgjfPOb35xQ4GE8w9VfOjo6WLduHa+++ipg95Bd1yUej/PQQw8thMiKopRg/fr1bNu2jTNnzgDw0ktrOX581cj5kyfbAThxop3Pf/5OANasWcP69afZu/c0YRjiOA7GGG677TZWrVo1sRNFWQIsSmNsjKG7u5vBwUEaGhrGvLlevXqV69evs3v3bgYGBrh69eqIYR3eT25paRmpuLR+/Xp6e3s5evQot9xyC77vk8lkWL16NZs3bx6ZYff29pJMJqmpqaG1tVWz9ShKhchkMnR1deE4DqtWrRpJS5nL5XjjjTdwHId77rmHI0eOEIYe3/nOdoJAgFEdzOddvv717YDBdQ2/+quwf/9+Ojs7iUQi7Nq1ayQ/QD6fp7OzE2MM7e3tM15JU5RqsOiMcX9/P88++yy5XA4Y3dO96667eOaZZ0omlh8OUxqm2Dv6woULI5+LPTevXLnCxYsX2b9/Py+++CLJZHLEAMdiMR588EEaGxsr/nyKslIwxnDo0CHOnDkzslVkjOGOO+5gYGCA06dPT7jn/vsvsmFDH//P//MgfX1xcrnRISoa9WlqyvCrv/oD1q8fYLh8sud5XLhwgXvuuYd0Os3rr78+osthGLJjxw5Nh6kseqRaMbalipHn83m+9rWvjRjiYURkXmKBh5exi+OPh4lGozz++OMjaTQVpVqUK0a+mCilz8ePH+fEiRMTtpOmo8/pdISf//n3E4aj/h6OE/LZz/4DNTWlKz0NG/zxoYyu67J371527tw57edRlPminD4vKgeuCxculNwHnq8Jw3CygFLth2E45q1aUZTpE4Yhp06dmrU+nzzZRiwW4LoBjhPiOAHRaMCJE22T9lkqp0AQBCPZ9xRlsbKojPHNmzendMpaKHzfp7u7u9piKMqSJJPJzKl+8NNPb2ZoyGPz5j7+4398ki1b+shkPJ55ZnYFH3zfn7DipiiLiUW1BptIJOZtSXqmiIjmqlaUWRKJROakx9ev1/OhDx3jgx88geMYfuu3nuTv/m43P/zh7Mua6paTsphZVN/OrVu3cvr06UXxdiwibNmypdpiKMqSJBKJ0NHRwbVr12ZllH/7t7895nfHMfzETxznJ35i8vSZpSbzIsK6deu0epOyqFlUy9T19fXceuutY+qVigiu61bcMDqOg+d53HbbbSX727t3L3V1dRXtU1FWEnfddRfxeHyMEXRdl+bmZqLRaEX7cl2Xjo4OGhsbJ/SXSCTYv39/RftTlEqzqN6MAXbt2sWqVat48803SafTNDU1sW3bNiKRCJs2beLIkSMMDAzgOA6+789oX0pEaG5uxnEc2tvb2bZtGzU1NWzYsIE333yTvr4+6urq2LFjh5ZgU5Q5kkgkeOyxxzh//jyXL1/GdV02b95Me3s7xhhOnz7NuXPnyOVyRCKRGe/pDtcej0ajbN26lTVr1hCGIZcvX+b8+fMYY9iwYQObNm3SJWpl0bOoQpvGEwQBR44c4ezZs4D1wty4cSP79+8fSRwAcPToUU6ePFlyOUxE2LNnD7feemtlH0BRFoilGto0nq6uLg4ePDhSn7impob9+/ezZs1o3ulUKsXTTz9NOp0u2UZtbS1vf/vbqampqZzwirKALInQpvE899xznD17liAICIKAMAy5ePHimHrGr7/+OidOnCi7L2WM4dixYxw7dmwhRVcUpYienh6eeeYZ+vv7R0KQUqkUzz//PNevXwesx/M3v/nNsoYYIJ1O841vfGNOntqKshhZtMa4t7eXrq6uCc5cw0p8/fp1wjDkxIkT02qvknVTFUWZGYcPHy7pmBkEAYcOHQLg2LFj0zKyQRBw8uTJSouoKFVl0RrjGzdulFVM3/e5evUqqVRq2p6axhhSqVQlRVQUZZrcvHmz7LlkMkk+n+fy5cvTbu/ixYuVEEtRFg2L1hg7jjNpLlnXdcuWRpzsHkVRFp6p8kIPp6adLjPVfUVZ7Czab/TatWvLnnNdlw0bNlBXVzdtA+t5nibxUJQqsXbt2rIGua2tDc/z2LZt27Tb27FjR6VEU5RFwaI1xnV1dWzbtm2CsXVdlzVr1tDS0gLYWMbpMN3rFEWpPLfffnvJ8CLP80ZigLdv3z6tcoeJREIT8ijLjkUdfLdv3z6am5s5ceIE6XSaRCLBzp072bZt28gse/PmzXiex8GDB8lkMsDYLDzxeJy77rqLdetmn0ZPUZS5UVdXx6OPPsrrr7/OlStXAOjo6OC2226joaEBsEvP73vf+3jxxRdLZu4SEdauXct999234PIrynyzqI2xiLB582Y2b9486XXr169n/fr1CyOUoiizora2lnvvvXfSazzP48EHH1wgiRRl8TCtZWoReUxETonIaRH5tRLnRUR+r3D+iIjcWXlRFUWZK6rLirI4mdIYi4gL/CHwHmAP8NMismfcZe8BdhR+PgZ8qsJyKooyR1SXFWXxMp0343uA08aYs8aYHPAl4P3jrnk/8AVjeRFoEpE14xtSFKWqqC4ryiJlOsZ4HXCp6PfLhWMzvQYR+ZiIvCIir3R1dc1UVkVR5kbFdBlUnxWlkkzHGJcKDhyf9mo612CM+Ywx5oAx5kB7e/t05FMUpXJUTJdB9VlRKsl0vKkvAxuKfl8PXJ3FNWN49dVXb4rIhekIWUXagPJ5/JYvK/W5YXE++6YKtTMvugxLQp8X4//rQrFSn32xPndJfZ6OMf4hsENEtgBXgJ8C/sm4a74C/KKIfAm4F+g3xlybrFFjzKKfSovIK4u9dN18sFKfG5b9s8+LLsPi1+dl/v86KSv12Zfac09pjI0xvoj8IvAtwAX+xBhzTEQ+Xjj/aeDrwHuB08Ag8NH5E1lRlNmguqwoixeZbtWjlchSm1lVipX63LCyn305s5L/X1fqsy+15160uakXCZ+ptgBVYqU+N6zsZ1/OrOT/15X67EvqufXNWFEURVGqjL4ZK4qiKEqVUWOsKIqiKFVGjfE4RGSDiHxfRE6IyDER+dfVlmkhERFXRF4Tka9WW5aFRESaRORvReRk4f/+/mrLpMwd1WfV56Wiz4u6hGKV8IFfMcYcFJF64FUR+Y4x5ni1BVsg/jVwAmiotiALzO8C3zTGfEhEokBNtQVSKoLqs+rzktBnfTMehzHmmjHmYOFzEvtFLpmbd7khIuuB9wF/XG1ZFhIRaQDeCnwWwBiTM8b0VVUopSKoPqs+LxV9VmM8CSKyGdgPvFRlURaK/w/4d0BYZTkWmq1AF/CnhSW9PxaR2moLpVQW1ecVw5LUZzXGZRCROuDvgF82xgxUW575RkQeBzqNMa9WW5Yq4AF3Ap8yxuwH0sCvVVckpZKoPq8olqQ+qzEugYhEsIr7RWPMl6stzwLxAPCjInIeW+f2HSLy59UVacG4DFw2xgy/Mf0tVpmVZYDqs+ozS0Cf1RiPQ0QEu9dwwhjzO9WWZ6Ewxvxvxpj1xpjN2AICTxpjfqbKYi0IxpjrwCURuaVw6J3ASnHwWdaoPqs+s0T0Wb2pJ/IA8E+BoyJyqHDs3xtjvl49kZQF4F8BXyx4Xp5FCyQsF1SfVyZLTp81HaaiKIqiVBldplYURVGUKqPGWFEURVGqjBpjRVEURakyaowVRVEUpcqoMVYURVGUKqPGWFEURVGqjBpjRVEURaky/z/f+u9C/vlksQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here we will relabel the predicted labels_ to correct the coloring\n",
    "#[0,1,2] --> Original label per iris dataset which stands for setosa(0), versicolor(1), verginica(2)\n",
    "#[1,0,2] --> Predicted labels per kmeans setosa(1), versicolor(0), verginica(2)\n",
    "relabel = np.choose(kmeans.labels_,[1,0,2]).astype(np.int64)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(x=iris_df['petal length'], y=iris_df['petal width'], c=color_theme[iris.target], s=50)\n",
    "plt.title(\"Ground Truth Classification\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(x=iris_df['petal length'], y=iris_df['petal width'], c=color_theme[relabel], s=50)\n",
    "#plot the scaled centroids for our reference.\n",
    "plt.scatter(x=centroids[:,2], y=centroids[:,3], c='b', s=100, marker='*' )\n",
    "plt.title(\"K-Means Clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05021989, -0.88337647,  0.34773781,  0.2815273 ],\n",
       "       [-1.01457897,  0.85326268, -1.30498732, -1.25489349],\n",
       "       [ 1.13597027,  0.08842168,  0.99615451,  1.01752612]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that kmeans has learnt the clustering, lets try to predict a new data.\n",
    "test_df = pd.DataFrame([\n",
    "    [5.1,3.5,1.4,0.2], # this is setosa(predicted code 1)\n",
    "    [7.0,3.2,4.7,1.4], # this is versicolor(predicted code 0)\n",
    "    [5.9,3.0,5.1,1.8], # this is a virginica( predected code 2)\n",
    "    [5.4,3.9,1.3,0.4], # setosa(predicted code 1)\n",
    "    [5.5,2.3,4.0,1.3], # versicolor(predicted code 0)\n",
    "    [6.2,3.4,5.4,2.3], # virginica( predected code 2)\n",
    "])\n",
    "test_df = scaler.transform(test_df)\n",
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as you see setosa is correctly predeicted 100% times but sometimes versicolor and virginica are not predicted correctly.\n",
    "kmeans.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05021989, -0.88337647,  0.34773781,  0.2815273 ],\n",
       "       [-1.01457897,  0.85326268, -1.30498732, -1.25489349],\n",
       "       [ 1.13597027,  0.08842168,  0.99615451,  1.01752612]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering performance evaluation - https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation\n",
    "1. __from sklearn import metrics__\n",
    "1. Evaluating the performance of a clustering algorithm is not as trivial as counting the number of errors or the precision and recall of a supervised classification algorithm. In particular any evaluation metric should not take the absolute values of the cluster labels into account but rather if this clustering define separations of the data similar to some ground truth set of classes or satisfying some assumption such that members belong to the same class are more similar than members of different classes according to some similarity metric.\n",
    "2. __Adjusted Rand Index__: Given the knowledge of the ground truth class assignments labels_true and our clustering algorithm assignments of the same samples labels_pred, the adjusted Rand index is a function that measures the similarity of the two assignments, ignoring permutations and with chance normalization:\n",
    "    * see below code\n",
    "    * Perfect labeling is scored 1.0\n",
    "    * Bad labeling can be 0.0 or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7058823529411765\n",
      "0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "#label_true = [0,0,0,1,1,1]  \n",
    "#label_pred = [1,1,1,0,0,0] # sequence of clustering labels doesn't matter\n",
    "label_true = [0,0,0,1,1,1]  \n",
    "label_pred = [2,2,0,3,3,3] # we can premute the labels, we can leave it normalised.\n",
    "#label_true = [0,0,0,1,1,1]  \n",
    "#label_pred = [1,2,5,4,2,3] # score as negative\n",
    "print(metrics.adjusted_rand_score(label_true, label_pred))\n",
    "print(metrics.adjusted_rand_score(label_pred, label_true)) # this gives the same score as above, arguments are symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6201351808870379\n",
      "0.45994823920518635\n"
     ]
    }
   ],
   "source": [
    "label_true = y[0].tolist()\n",
    "label_pred = kmeans.labels_ # using relabel gives the same result\n",
    "\n",
    "print(metrics.adjusted_rand_score(label_true, label_pred))#Ground truth is known\n",
    "print(metrics.silhouette_score(X, kmeans.labels_, metric='euclidean')) #Ground truth is not known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.74      0.78      0.76        50\n",
      "           2       0.77      0.72      0.74        50\n",
      "\n",
      "    accuracy                           0.83       150\n",
      "   macro avg       0.83      0.83      0.83       150\n",
      "weighted avg       0.83      0.83      0.83       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we shouldn't be using classification report here as we know we are not performing classification we are doing clustering. \n",
    "#Just because we have used a classification example we can use it just for reference to above clustering score.\n",
    "print(classification_report(y, relabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and Variance and tradeoff \n",
    "We know that in ML we are trying to predict the function f(), given y and X.Here we are trying to predict the function f^() as close as possible to the __\"Ground truth\"__(true) function f().\n",
    "1. __Bias__ : Bias tells us how much our model __f^(x)__ is different from our ground truth model __f(x)__ if I use n different samples of training data from the dataset. As you can see if we use a linear regression for a model with ground truth as sinusidal wave. We will always get a stright line, which is very different from our ground truth, hence this has a __High Bias__. But for every different sample in dataset the linear line is pretty similar, hence it has __Low Variance__.\n",
    "<img src=\"images/image92.png\" align = \"middle\" style=\"width:300px; height:200px;\"/>\n",
    "2. __Variance__: Variance will tell how much my model will vary if I use n different samples of training data from the dataset. If we use a polinomial (say degree 25) we will have curve which will fit our ground truth function pretty nicely, hence we say the polinomial regression has __Low Bias__. But we will get more variance in the sinusidal curve if we use n differetn sample from the dataset, hence we say that this poli regression has __High Variance__.\n",
    "3. Overfitting happens when the model is too complex relative to the amount and noisiness of the training data. The possible solutions are:\n",
    "    * To simplify the model by selecting one with fewer parameters (e.g., a linear model rather than a high-degree polynomial model), by reducing the number of attributes/features in the training data or by constraining the model.\n",
    "    * to gather more training data.\n",
    "    * To reduce e noise in the traininf data (e.g fix data errors and remove outliers)\n",
    "    \n",
    "1. __high bias and low variance__: In this kind of modelling where the model misses the little attentions to training data and over generalise the algorithm are said to have __high Bias__ and are called as __underfitted__ in training phase. Since the generalization is good these model perform well in testing phase.\n",
    "<img src=\"images/image17.png\" align = \"middle\" style=\"width:300px; height:200px;\"/>\n",
    "<img src=\"images/image18.png\" align = \"middle\" style=\"width:300px; height:200px;\"/> \n",
    "12. __Underfitting__ : it occurs when your model is too simple to learn the underlying structure of the data. Reality is just more complex than the model, so its predictions are bound to be inaccurate. The main options to fix this problem are:\n",
    "    * Selecting a more powerful model, with more parameters\n",
    "    * Feeding better features to the learning algorithm (feature engineering)\n",
    "    * Reducing the constraints on the model (e.g., reducing the regularization hyperparameter)\n",
    "    \n",
    "2. __high variance and low bias__ : On the other hand if we are using a polynomial regression, it is super flexible and hugs the training set along the arc of the true function (hence have __low bias__). Here the polynomial regression pays lots of attention to the training data (so they have __high variance__ )and does not generalise well on data which it hasn't seen before. As a result, such model perform very well on training data but have high error rates on test data. This kind of model is said to be __overfitted__ in training phase, because the algorithm models th erandom noise in the training data, rather than the intended outputs.\n",
    "\n",
    "3. The fact here is Liner regression which has __high bias__, will have __low variance__ due to generalisation during training phase. And polynomial regression will have __low bias__ in training phase, but will have __high variance in__ testing phase.\n",
    "4. Another fact is its not possible to have a ideal model which will have low bais and low variance. Hence there has to be a __trade-off__ between the two. An __optimal balance of bias and variance would never overfit or underfit the model__. To build a good model, we need to find a good balance between bias and variance such that it minimizes the total error. \n",
    "                total error = Bias^2+Variance+Irreducible Error  \n",
    "\n",
    "6. But we are actually interested in Test Error - which is the error we get with the predicted data. We basically want to minimize this. To minimize the error we will have to have a good trade off point between Bias and Variance. So check the below image we are looking for this sweet spot the trade off at center which is th ideal model complexity. This is achieved through __Regularization__.\n",
    "  \n",
    "<img src=\"images/image16.png\" align = \"middle\" style=\"width:200px; height:200px;\"/> \n",
    "5. These Bias and Variance is seen mainly in predictive modelling of Supervised Learning Algorithm namely Classification and Regression.\n",
    "7. __Regularization__ : Constraining a model to make it simpler and reduce the risk of overfitting is called regularization. \n",
    "    * You want to find the right balance between fitting the training data perfectly and keeping the model simple enough to ensure that it will generalize well. Page 29 HOML by AG\n",
    "    * The amount of regularization to apply during learning can be controlled by a hyperparameter. A hyperparameter is a parameter of a learning algorithm (not of the model). As such, it is not affected by the learning algorithm itself; it must be set prior to training and remains constant during training. Tuning hyperparameters is an important part of building a Machine Learning system\n",
    "    * https://www.youtube.com/watch?v=gyGMaNUaeic\n",
    " \n",
    "6. Reference:\n",
    "    * Mitesh Khapra - https://www.youtube.com/watch?v=Y0m136XU65o\n",
    "    * Josh Stamer - https://www.youtube.com/watch?v=Y0m136XU65o\n",
    "    * https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation - https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "1. It is common practice when performing a __(supervised) machine learning__ experiment to hold out part of the available data as a test set X_test, y_test using train_test_split() method of scikit.\n",
    "2. __train_test_split__ - This is the simplest way to split the dataset. __Split arrays or matrices into random train and test subsets__. But problem with it is that since we split it randomly it may happen that the training data get overly saturated with one type of data and the model may have poor performance on test data. This will result in __overfitting__. That is were Cross-Vlidation comes in picture.\n",
    "    * https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split\n",
    "3. To solve the problem with train_test_split overfitting, yet another part of the dataset can be held out as a so-called “validation set”: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set. This is called as __Cross-Validation__. Its important to note that the trained model is trained using all the training dataset(inclusing validation) except the testing dataset.\n",
    "<img src='images/image93.png' style='width:300px;height:200px' />\n",
    "2.  __Cross validation__ allows us to avoid overfitting and used in hyperparameter tuning.\n",
    "2. There are different techniques in cross-validation. like K-fold(default basic approach), Stratified K-fold, . Leave One Out (LOO), Leave P Out(LPO) etc etc.\n",
    "3. __K-Fold CV/Default CV__: In k-fold cross-validation, you split the training data into k subsets of data (also known as folds). You train an ML model on all but one (k-1) of the subsets, and then evaluate the model on the subset that was not used for training. This process is repeated k times, with a different subset reserved for evaluation (and excluded from training) each time. Then the accuracy is averaged out. The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop.\n",
    "    * The __dis-advantages__ with this is that, what if one type of data overload in test/training fold. Then the accuracy of overall model will fall.  \n",
    "<img src=\"images/image94.png\" align = \"middle\" style=\"width:600px; height:250px;\"/> \n",
    "4. __Stratified K-fold CV__: In some cases, there may be a large imbalance in the response variables. For example, in dataset concerning price of houses, there might be large number of houses having high price. Or in case of classification, there might be several times more negative samples than positive samples. For such problems, a slight variation in the K Fold cross validation technique is made, such that each fold contains approximately the same percentage of samples of each target class as the complete set, or in case of prediction problems, the mean response value is approximately equal in all the folds. This variation is also known as Stratified K Fold. Another major difference between KFold and SKFold is that in stratified you need to supply both X and y labels to teh .split(), bacause Stratifying is done on the y lables. Where as in KFold just X si enough.\n",
    "5. __Time Series CV__: Splitting a time-series dataset randomly does not work because the time section of your data will be messed up. For a time series forecasting problem, we perform cross validation in the following manner.\n",
    "<img src=\"images/image20.png\" align = \"middle\" style=\"width:600px; height:150px;\"/> \n",
    "5. Reference:\n",
    "    * https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "    * john Stamer - https://www.youtube.com/watch?v=fSytzGwwBVw\n",
    "    * https://www.analyticsvidhya.com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       0.95      1.00      0.97        19\n",
      "           2       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        60\n",
      "   macro avg       0.98      0.98      0.98        60\n",
      "weighted avg       0.98      0.98      0.98        60\n",
      "\n",
      "***************************\n",
      "classification score:  0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "#Simplest method of train_test_split with out CV\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=32)\n",
    "clf = KNeighborsClassifier(n_neighbors=11, p=2, metric='euclidean')\n",
    "clf.fit(X_train, y_train)\n",
    "clf_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, clf_pred))\n",
    "print(\"***************************\")\n",
    "print(\"classification score: \", clf.score(X_test, y_test)) # .score() will first call a predict and then calculate the accuracy\n",
    "\n",
    "# Another Example Basic train_test_split wihtout CV using regression and diabettic dataset\n",
    "# X1, y1 = datasets.load_diabetes(return_X_y=True)\n",
    "# X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=32)\n",
    "# clf = LinearRegression()\n",
    "# clf.fit(X1, y1)\n",
    "# clf_pred = clf.predict(X1_test)\n",
    "# clf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic usage of KFold\n",
    "# see how the output is divided into 3 parts.\n",
    "kf = KFold(n_splits=3, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8] [0 1 2]\n",
      "[0 1 2 6 7 8] [3 4 5]\n",
      "[0 1 2 3 4 5] [6 7 8]\n",
      "***************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "***************************\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "X2 = [1,2,3,4,5,6,7,8,9]\n",
    "clf = KNeighborsClassifier(n_neighbors=3, p=2, metric='euclidean')\n",
    "for train_index, test_index in kf.split(X2):\n",
    "    print( train_index, test_index)\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "clf.fit(X_train, y_train)\n",
    "clf_pred = clf.predict(X_test)\n",
    "print(\"***************************\")\n",
    "print(classification_report(y_test, clf_pred))\n",
    "print(\"***************************\")\n",
    "print(clf.score(X_test, y_test))\n",
    "# Whole of the above functionality is summed in cross_val_score() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The simplest way to use cross-validation is to call the cross_val_score helper function on the estimator and the dataset.\n",
    "\n",
    "2. The following example demonstrates how to estimate the accuracy of a linear kernel support vector machine on the iris dataset by splitting the data, fitting a model and computing the score 5 consecutive times (with different splits each time):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93333333 1.         1.         0.96666667 1.        ]\n",
      "Accuracy: 0.98 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "# Keep in mind that we are giving X and y as the input and not X_train and y_train\n",
    "KnnClf = KNeighborsClassifier(n_neighbors=11, p=2, metric='euclidean')\n",
    "# cross_cal_score is just a method which uses either KFolf or StrtifiedKFold (Check the documentation which one is used when\n",
    "# then gives a list of score on each iteration on model. SO you can see min, ma and mean of the accuracy score.\n",
    "scores = cross_val_score(KnnClf, X, y, cv=5)  #cv=5 means 5 fold\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93333333 1.         1.         0.96658312 1.        ]\n",
      "Accuracy: 0.98 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "# By default, the score computed at each CV iteration is the score method of the estimator(here Kneighbours). \n",
    "# It is possible to change this by using the scoring parameter: \n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "scores = cross_val_score(KnnClf, X, y, cv=5, scoring='f1_macro')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "# In the case of the Iris dataset, the samples are balanced across target classes \n",
    "# hence the accuracy and the F1-score are almost equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97777778 0.93333333 0.93333333 0.91111111 0.97777778]\n",
      "Accuracy: 0.95 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "# Keep in mind that we are giving X and y as the input and not X_train and y_train\n",
    "# When the cv argument is an integer, cross_val_score uses the KFold or StratifiedKFold strategies by default, \n",
    "# the latter being used if the estimator derives from ClassifierMixin.\n",
    "DtreeClf = tree.DecisionTreeClassifier()\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "scores = cross_val_score(DtreeClf, X, y, cv=cv)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cross_validate function differs from cross_val_score in two ways:\n",
    "\n",
    "    * It allows specifying multiple metrics for evaluation.\n",
    "    * It returns a dict containing fit-times, score-times (and optionally training scores as well as fitted estimators) in addition to the test score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93333333, 1.        , 1.        , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KnnClf = KNeighborsClassifier(n_neighbors=11, p=2, metric='euclidean')\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)\n",
    "sorted(scores.keys())\n",
    "scores['test_recall_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining predictions by cross-validation and plotting\n",
    "# cross_val_predict returns an array of the same size as `y` where each entry\n",
    "# is a prediction obtained by cross validation:\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "clf = KNeighborsClassifier(n_neighbors=11, p=2, metric='euclidean')\n",
    "# clf = LinearRegression()\n",
    "# X, y = datasets.load_diabetes(return_X_y=True)\n",
    "predicted = cross_val_predict(clf, X, y, cv=10)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y, predicted, edgecolors=(0, 0, 0))\n",
    "ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratifies K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9333333333333333, 1.0, 1.0, 0.9666666666666667, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9800000000000001"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here SKF tries to create a balanced KFold.\n",
    "# we will use KNN here to find the accuracu using SKF\n",
    "clf = KNeighborsClassifier(n_neighbors=11, p=2, metric='euclidean') \n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None)  # n_splits is same as cv=5 above\n",
    "accuracy = []\n",
    "\n",
    "# NOte that in strtified K fold y is required, where as in Kfold its not\n",
    "# Thats because strtification happends on y values.\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    scores = accuracy_score(y_test, predictions)\n",
    "    accuracy.append(scores)\n",
    "    \n",
    "print(accuracy)\n",
    "np.array(accuracy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Card - [0.97777778 0.95555556 0.97777778 0.91111111 0.97777778] \n",
      "Mean - 0.96\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics\n",
    "# When the cv argument is an integer, cross_val_score uses the KFold or StratifiedKFold strategies by default, \n",
    "# the latter being used if the estimator derives from ClassifierMixin.\n",
    "# It is also possible to use other cross validation strategies by passing a cross validation iterator instead, for instance:\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0) # we can use \n",
    "score = cross_val_score(clf, X, y, cv=cv)\n",
    "print(\"Score Card - {} \\nMean - {}\".format(score, score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Card - [0.93333333 1.         1.         0.96666667 1.        ] \n",
      "Mean - 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "# using cross_val_score\n",
    "score = cross_val_score(clf, X, y, cv=skf)\n",
    "print(\"Score Card - {} \\nMean - {}\".format(score, score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.90909091, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.        , 0.09090909, 0.18181818, 0.        , 0.        ,\n",
       "       0.09090909, 0.18181818, 0.09090909, 0.        , 0.27272727])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)\n",
    "clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your connection.\n",
    "#cnx = sqlite3.connect('database.sqlite')\n",
    "#df = pd.read_sql_query(\"SELECT * FROM Player_Attributes\", cnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Checkout Data Science Regression documentation in my Google Drive before proceeding further.\n",
    "2. __Regression vs Classification__: In regression we predict the target which are numerical/continuous in nature and in classification we predict the targets which are categorical in nature. \n",
    "3. Regression allows us to model the relationship between 2 or more variables using algebra. The goal of linear regression is to create a model that minimizes the sum of squared errors (SSE). \n",
    "4. There are two kinds of variables:\n",
    "    * __Independent variable__: An independent variable is the variable that is changed or controlled in a scientific experiment to test the effects on the dependent variable. Here total bill is a independent variable.\n",
    "    * __Dependent variable__: A dependent variable is the variable being tested and measured in a scientific experiment. Here “tip” amount is a dependant variable.\n",
    "5. __Linear Regression__: Predicts one DV utilizing one IV.\n",
    "6. __Multiple Regression__: It's the same as linear regression. Here we will have more than one independent variable which will be utilized to predict the value of one depend variable.\n",
    "    * __OVERFITTING__ : Adding more independent variable to a multiple regression does not mean the regression will be better or offer better predictions ; in fact it can make things worse and this is called OVERFITTING. So to get a better prediction model the trick/idea is to pick the best independent variable.\n",
    "    * __Multicollinearity__ : When we have multiple independent variables to consider, there arises another problem where the independent variables will have some correlation among themself in addition to sharing a correlation with the dependent variable.Also since the independent variables are related to each other we are really not sure which one is actually explaining the variation in the dependent variable. We have to make sure we address Multicollinearity in regression problems but we cn ignore (i think cross check) multicollinearity in classification problems.\n",
    "7. __Logistic regression__: A binomial logistic regression (often referred to simply as logistic regression), predicts the probability that an observation falls into one of two categories of a __dichotomous dependent__ variable based on one or more independent variables that can be either continuous or categorical.\n",
    "8. Correlation: First step in calculating the regression line is to find out if there is a good correlation between the two variables (DV and IV, between IVs in case of MR)\n",
    "    * https://www.mathsisfun.com/data/correlation.html\n",
    "9. Evaluation Metrics for performance: \n",
    "    * __Error__: Error in a regression model is the distance between the actual value and the predicted value.\n",
    "    * __RMSE__ - Root Mean Squared Error is one of the way to measure the performance of the regression matrix.The RMSE is the square root of the variance of the residuals\n",
    "    * __SSE__ - Sum of sqaured errors - The distance of the data points from the “best fit” line is called the residuals/errors. When we square the residuals and sum them we get what is called as Sum of Squared Errors (SSE). The square root of SSE is called as RMSE.\n",
    "    * __SE__ - Standard Error - the grey shaded area represents the standard error (probably it’s the 95% confidence band which means that the standard error will be about half of the width). This indicates how uncertain we are about where the best fit line really “should” be, i.e. where it might be if we had a much larger sample so we could get rid of the statistical uncertainty.The simplest formula that expresses the relation between the two is SE=SD/sqrt(n) where n is the sample size and SD (standard deviation) is the square root of the mean squared error. SE = $\\frac{\\sqrt SSE}{\\sqrt n}$\n",
    "        * The standard error can be thought of as the average distance of the data point from the regression line in depedant variable units.\n",
    "11. The Anova Table in regression model analysis gives us the significance of teh overall model. Where as the regression table analysis gives us the stats about regression line.\n",
    "12. __F-value in Regression__: \n",
    "    * https://www.statisticshowto.com/probability-and-statistics/f-statistic-value-test/#Regression\n",
    "    * The F value in regression is the result of a test where the null hypothesis is that all of the regression coefficients are equal to zero. In other words, the model has no predictive capability. Basically, the f-test compares your model with zero predictor variables (the intercept only model), and decides whether your added coefficients improved the model. If you get a significant result, then whatever coefficients you included in your model improved the model’s fit.\n",
    "    * __Read your p-value first__. If the p-value is small (less than your alpha level), you can reject the null hypothesis. Only then should you consider the f-value. If you don’t reject the null, ignore the f-valu\n",
    "\n",
    "10. what does a p-value tell you in regression : \n",
    "    1.  The p-values help determine whether the relationships that you observe in your sample also exist in the larger population. \n",
    "    2. https://statisticsbyjim.com/regression/interpret-coefficients-p-values-regression/#:~:text=Regression%20analysis%20is%20a%20form,correlation%20with%20the%20dependent%20variable.\n",
    "0. Reference:\n",
    "    * https://www.youtube.com/watch?v=ZkjP5RJLQF4\n",
    "    * https://www.theanalysisfactor.com/assessing-the-fit-of-regression-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding correlation\n",
    "cor = tnic_df.corr()\n",
    "cor;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAEvCAYAAACpE9PoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3debgdVZ3u8e+bADIEAiIKQhjUMAsBwqReTSu0gjagIiCo4NBpngc13bbX1rZFxLavbWsrooBpQYK2gohDrp0GbCCIA5CAISFBhAsIITggyBiGnPPeP6oObHZOkjNUTu2qvB+eeqhaVbvqVznJ+e21atVask1ERES0y7i6A4iIiIjqJcFHRES0UBJ8RERECyXBR0REtFASfERERAslwUdERLRQEnxERMRaJOk8SX+QdPMq9kvSlyXdLmmhpH2ruG4SfERExNp1PvCG1ew/DJhcLtOBs6u4aBJ8RETEWmT7p8ADqznkSOACF64FNpe0zWivu95oT7Auefr+O1oz7N8Z+55adwiVWa7W/FjYql91h1CZZePb83OZ2KKfS5t+6c+4+1tr7QcznN/3G2z10r+hqHkPmGl75jAuty1wT8f20rLsvmGcYyVt+llHRESMuTKZDyehdxvsi8qovyEnwUdERHTr7xvLqy0FJnVsbwcsG+1J8ww+IiKiW9+KoS+jNxt4V9mb/iDgIdujap6H1OAjIiJWYvdXdi5J3wGmAS+QtBT4JLB+cR2fA8wBDgduBx4H3l3FdZPgIyIiuvVXl+Btv30N+w2cUtkFS0nwERER3SqswdclCT4iIqLb2HayWyuS4CMiIrqlBh8REdE+rqZ3fK2S4CMiIrpV2MmuLknwERER3dJEHxER0UIt6GS3xpHsJPVJWiDpZkkXS9p4LAJbGyRNk/TjVey7S9ILxjqmiIjoQe4f+tKjhjJU7XLbU2zvCTwFnLyWY1orJKW1IiIihmZsh6pdK4Y7Fv01wMsAJP1Q0g2SFkuaXpaNl3R+WdtfJOnvyvIPSloiaaGkC8uyTSSdJ2mepF9JOrIsP0nS9yVdKuk2SZ8buLik90r6jaS5kv5D0lfK8q0kXVKea56kV5blp0maKely4ILOG5G0paTLy2t/jcFn84mIiHVRf//Qlx415FptWQM+DLi0LHqP7QckbQTMk3QJsCOwbVnbR9Lm5bEfBXay/WRH2ceBK22/pyy7XtL/lPumAPsATwK3SjoT6AM+AewLPAJcCdxUHn8G8EXbP5O0PXAZsFu5bz/gVbaXS5rWcUufBH5m+3RJb+S5c/l23vf0gX1nfeGfed+7VjviYEREtIDd/GfwQ0nwG0laUK5fA5xbrn9Q0pvL9UnAZOBW4CVlQv4v4PJy/0LgPyX9EPhhWfaXwBGSPlxubwhsX65fYfshAElLgB2AFwBX236gLL8Y2Lk8/hBgd+mZSvhmkjYt12fbXj7Ifb0aeAuA7f+S9OBgN985z+/T998x6vl5IyKiAXr42fpQDSXBL7c9pbOgrAkfAhxs+3FJc4ENbT8oaW/g9RQD5x8DvAd4I0VCPQL4hKQ9KJrE32r71q5zH0hRcx/QV8a5uib0cWUsz0nkZcJ/bDWfS8KOiIiV9XDT+1CNdD74icCDZXLfFTgIoOyFPs72JZTN6ZLGAZNsXwV8BNgcmEDRjP4BlVlY0j5ruOb1wGskbVE+Lnhrx77LgfcPbEia0v3hQfwUOKE8/jBgiyF8JiIi1gUt6EU/0p7llwInS1pI0Sx/bVm+LfCNMqkDfAwYD3xL0kSKWvgXbf9Z0qeBLwELyyR/F/CmVV3Q9r2S/gW4DlgGLAEeKnd/EPhqGc96FMl7Tb39PwV8R9KNwNXA3UO9+YiIaLm+p+uOYNRUTEPbDJIm2H60rMH/ADjP9g/G6vptegZ/xr6n1h1CZZarNT8Wtupvz8scy8a35+cysUU/lza9Lzzj7m+ttR/ME9deNOS/wBsedGxP/gVp2s/6NEmHUHTIu5xnO+xFRERUp4eb3oeqUQne9ofXfFRERMQotaCTXaMSfERExJhoQYIfaS/6iIiI1nLf00Ne1kTSGyTdKul2SR8dZP9ESf9X0k3l6LDvruIekuAjIiK6VfSanKTxwFcpRoLdHXi7pN27DjsFWGJ7b2Aa8AVJG4z2FtJEHxER0a26JvoDgNtt3wFQzsdyJMWr3gMMbFq+Mj4BeAAY9Sw2qcFHRER0G0YNXtJ0SfM7ls65TbYF7unYXlqWdfoKxfwpy4BFwAx79N34U4OPiIjoNowafOecJYMY7B357nfsXw8sAF4LvBT4iaRrbD885CAGkRp8REREt+qGql1KMSHbgO0oauqd3g1834XbgTuBXUd7C6nBD0ObRn+bcePpdYdQmYNffmLdIVTm0OdNWvNBDbGxe3JwrxHZetRPQ3vHXs97aM0HBayo7Ic+D5gsaSfgXuA44PiuY+4GXgdcI+lFwC7AHaO9cBJ8REREt4pGsrO9QtL7KSZYG08xxPpiSSeX+88BPg2cL2kRRZP+P9i+f7TXToKPiIjoVuFAN7bnAHO6ys7pWF8G/GVlFywlwUdERHTLWPQREREt1IKhapPgIyIiuqUGHxER0ULV9aKvTRJ8REREN3ePRdM8SfARERHd8gw+IiKihZLgIyIiWiid7CIiIlqor6/uCEYtCT4iIqJbC5rox2w2OUkfl7RY0kJJCyQdWME5j5D00Yrie7SK80RERAv09w996VFjUoOXdDDwJmBf209KegGwwRA/u57tQV9ItD0bmF1dpBEREbTiGfxY1eC3Ae63/SSA7fttL5N0V5nskTRV0txy/TRJMyVdDlwg6TpJewycTNJcSftJOknSVyRNLM81rty/saR7JK0v6aWSLpV0g6RrJO1aHrOTpF9Kmifp02P05xAREQ3gfg956VVjleAvByZJ+o2ksyS9Zgif2Q840vbxwIXAMQCStgFebPuGgQNtPwTcBAyc96+Ay2w/DcwEPmB7P+DDwFnlMWcAZ9veH/jdqoKQNF3SfEnzr330tmHcckRENFYLmujHJMHbfpQiYU8H/ghcJOmkNXxstu3l5fp3gbeV68cAFw9y/EXAseX6ceU1JgCvAC6WtAD4GkVrAsArge+U699cTewzbU+1PfWgCZPXEHJERLRCX9/Qlx41Zr3obfcBc4G55aT2JwIrePZLxoZdH3ms47P3SvqTpL0okvjfDHKJ2cD/kfR8ii8TVwKbAH+2PWVVYY3wdiIios16uGY+VGNSg5e0i6TO6u8U4LfAXRTJGOCtazjNhcBHgIm2F3XvLFsJrqdoev+x7T7bDwN3SnpbGYck7V1+5OcUNX2AE4Z/VxER0Vppoh+yCcAsSUskLQR2B04DPgWcIekaYE3tHN+jSMjfXc0xFwHvKP8/4ATgvZJuAhYDR5blM4BTJM0DJg7vdiIiotXsoS89akya6MsOca8YZNc1wM6DHH/aIGW/pyte2+cD53dsfw9Q1zF3Am8Y5Hx3Agd3FH121XcQERHrlB6umQ/VmA10ExER0Rj9HvqyBpLeIOlWSbevanA2SdPKQeAWS7q6ilvIULURERHdKuodL2k88FXgUGApME/SbNtLOo7ZnOIV7jfYvlvSC6u4dhJ8REREF1fXRH8AcLvtOwAkXUjRF2xJxzHHA9+3fTeA7T9UceE00UdERHQbRhN954Bo5TK940zbAvd0bC8tyzrtDGxRjtJ6g6R3VXELqcFHRER0G8ZY9LZnUoyaOhgNUtb94H49ilfGXwdsBPxS0rW2fzPkIAaRBB8REdGtujHmlwKTOra3A5YNcsz9th8DHpP0U2BvYFQJPk30ERER3Vb0DX1ZvXnA5HKCsw0oxnPpngX1R8D/krSepI2BA4FbRnsLqcFHRER0q2i6WNsrJL0fuAwYD5xne7Gkk8v959i+RdKlwEKgH/i67ZtHe+0k+IiIiG4VTgNrew4wp6vsnK7tfwP+rbKLkgQ/LMvVu0MSDtfBLz+x7hAq88tFs+oOoTL77HF83SFU5mPjX1Z3CJV5YHzdEVRnn3tvrDuEyqxYi+eu8DW52iTBR0REdKuwBl+XJPiIiIhuSfAREREtVNFQtXVKgo+IiOji1OAjIiJaKAk+IiKihdKLPiIiooVSg4+IiGihJPiIiIj2cV+a6CMiItonNfiIiIj2yWtyERERbZQEv/ZI6gMWUcR4C3Ci7cdXcexpwKO2Pz92EUZERGs1/xE84+oOYDWW255ie0/gKeDkugOKiIh1g1f0D3npVb2c4DtdA7wMQNK7JC2UdJOkb3YfKOmvJc0r918iaeOy/G2Sbi7Lf1qW7SHpekkLynNOHtO7ioiI3tQ/jKVH9XyCl7QecBiwSNIewMeB19reG5gxyEe+b3v/cv8twHvL8lOB15flR5RlJwNn2J4CTAWWDnL96ZLmS5o//9HbK723iIjoTe73kJde1csJfiNJC4D5wN3AucBrge/Zvh/A9gODfG5PSddIWgScAOxRlv8cOF/SXwPjy7JfAv8o6R+AHWwv7z6Z7Zm2p9qeOnXCy6q8v4iI6FUtqMH3bCc7ymfwnQWSBKzp69L5wFG2b5J0EjANwPbJkg4E3ggskDTF9rclXVeWXSbpfbavrPg+IiKiYXq5Zj5UvVyDH8wVwDGStgSQ9PxBjtkUuE/S+hQ1eMpjX2r7OtunAvcDkyS9BLjD9peB2cBea/0OIiKi91VYg5f0Bkm3Srpd0kdXc9z+kvokHT36G+jtGvxKbC+W9Bng6vI1ul8BJ3Ud9gngOuC3FK/ZbVqW/1vZiU4UXxRuAj4KvEPS08DvgNPX+k1ERETP84pqziNpPPBV4FCKfl7zJM22vWSQ4/4VuKyaK/dwgrc9YRXls4BZXWWndayfDZw9yOfeMsjp/k+5REREPMPVPVs/ALjd9h0Aki4EjgSWdB33AeASYP+qLty0JvqIiIi1r7om+m2Bezq2l5Zlz5C0LfBm4JzRB/6sJPiIiIgu7h/60vk6dblM7ziVBjt91/aXgH+w3VflPfRsE31ERERdhtNEb3smMHMVu5cCkzq2twOWdR0zFbiweFGMFwCHS1ph+4dDj2JlSfARERFd3DdYxXtE5gGTJe0E3AscBxz/nGvZOw2sSzof+PFokzskwUdERKykqk52tldIej9F7/jxwHnlG2Enl/srfe7eKQk+IiKii/srq8Fjew4wp6ts0MRu+6SqrpsEHxER0aXC1+RqkwQfERHRxa6uBl+XJPiIiIguqcGvY7aq8JlM3Q593qQ1H9QQ++xx/JoPaohfLf523SFUZtre76s7hMrsMG5i3SFU5j+3nFZ3CI3QX10v+tokwUdERHSpspNdXZLgIyIiuiTBR0REtJCbPx18EnxERES31OAjIiJaKK/JRUREtFBfetFHRES0T2rwERERLZRn8BERES2UXvQREREtlBp8REREC/X1j6s7hFFLgo+IiOjShib65n9F6SDpzZIsade6Y4mIiObqt4a89KpWJXjg7cDPgOPqDiQiIprL1pCXXtWaBC9pAvBK4L2UCV7SOElnSVos6ceS5kg6uty3n6SrJd0g6TJJ29QYfkRE9BB76Euvak2CB44CLrX9G+ABSfsCbwF2BF4OvA84GEDS+sCZwNG29wPOAz4z2EklTZc0X9L8ax69be3fRURE1K7KJnpJb5B0q6TbJX10kP0nSFpYLr+QtHcV99CmTnZvB75Url9Ybq8PXGy7H/idpKvK/bsAewI/kQQwHrhvsJPangnMBDhn0jt6+LtaRERUpape9JLGA18FDgWWAvMkzba9pOOwO4HX2H5Q0mEUOefA0V67FQle0pbAa4E9JZkiYRv4wao+Aiy2ffAYhRgREQ1SYW3uAOB223cASLoQOBJ4JsHb/kXH8dcC21Vx4bY00R8NXGB7B9s72p5E8Y3ofuCt5bP4FwHTyuNvBbaS9EyTvaQ96gg8IiJ6T4VN9NsC93RsLy3LVuW9wH+PMnygJTV4iub4z3aVXQLsRvGHeTPwG+A64CHbT5Wd7b4saSLFn8OXgMVjF3JERPSq4fSOlzQdmN5RNLN8vAtFi/FKp1/Fef6CIsG/asgXX41WJHjb0wYp+zIUvettP1o2418PLCr3LwBePZZxRkREM/QP49jOvlqDWApM6tjeDljWfZCkvYCvA4fZ/tMwLr9KrUjwa/BjSZsDGwCftv27ugOKiIje5kEr3iMyD5gsaSfgXorXuI/vPEDS9sD3gXeWb4JVovUJfrDafURExOqsqGgAG9srJL0fuIyiA/h5thdLOrncfw5wKrAlcFb5ZtcK21NHe+3WJ/iIiIjhqrAGj+05wJyusnM61t9HMVZLpZLgIyIiugznGXyvSoKPiIjoUmUNvi5J8BEREV1Sg4+IiGihvtTgIyIi2qe/+fk9CT4iIqJbf2rw65Zl49szmdzGFb3j2Qs+Nv5ldYdQmWl7V/6mTG3m3vT1ukOozMMnvrvuECpz4/wN6g6hEdrw2z4JPiIioks62UVERLRQv5rfypkEHxER0aWv7gAqkAQfERHRJb3oIyIiWii96CMiIloovegjIiJaKE30ERERLZTX5CIiIlqoLzX4iIiI9kkNPiIiooWS4CMiIlqoDdN1jKs7gKGS9HFJiyUtlLRA0oGSvi5p93L/o6v43EGSris/c4uk08Y08IiIaJz+YSy9qhE1eEkHA28C9rX9pKQXABvYHsrUW7OAY2zfJGk8sMvajDUiIpqvyqFqJb0BOAMYD3zd9me79qvcfzjwOHCS7RtHe92m1OC3Ae63/SSA7fttL5M0V9LUgYMkfUHSjZKukLRVWfxC4L7yc322l5THnibpm5KulHSbpL8e43uKiIge1a+hL6tTViy/ChwG7A68faDlucNhwORymQ6cXcU9NCXBXw5MkvQbSWdJes0gx2wC3Gh7X+Bq4JNl+ReBWyX9QNLfSNqw4zN7AW8EDgZOlfTi7pNKmi5pvqT5Nz5ye6U3FRERvanCJvoDgNtt32H7KeBC4MiuY44ELnDhWmBzSduM9h4akeBtPwrsR/HN5o/ARZJO6jqsH7ioXP8W8Krys6cDUym+JBwPXNrxmR/ZXm77fuAqih9E97Vn2p5qe+q+m76supuKiIieNZwE31kRLJfpHafaFrinY3tpWcYwjxm2RjyDh6J5HZgLzJW0CDhxTR/p+Oz/A86W9B/AHyVt2X3MKrYjImIdNJxkYHsmMHMVuwdrxO8+/VCOGbZG1OAl7SJpckfRFOC3XYeNA44u148HflZ+9o1lBwYonm/0AX8ut4+UtGGZ8KcB89ZC+BER0TBVPYOnqI1P6tjeDlg2gmOGrSk1+AnAmZI2B1YAt1M013+v45jHgD0k3QA8BBxblr8T+KKkx8vPnmC7r8z51wP/BWwPfNr2qP9AIyKi+SrsRT8PmCxpJ+Be4DiKSmin2cD7JV0IHAg8ZPu+0V64EQne9g3AKwbZNa3jmAnl6ie6Pnvcak79G9vTV7M/IiLWQf0VPbG1vULS+4HLKF6TO8/2Ykknl/vPAeZQvCJ3O8Vrcu+u4tqNSPARERFjqcoBbGzPoUjinWXndKwbOKXCSwLrcIK3fVrdMURERG9qQ4/rdTbBR0RErEovD0E7VEnwERERXVao+XX4JPiIiIguzU/vSfARERErSRN9REREC1X1mlydkuAjIiK6ND+9J8FHRESsJE3065iJQxh0uCm2XlF3BNV5YHzdEVRnh3ET6w6hMg+fWMlgXD1hs1nfqDuEymy214frDqER+lpQh0+Cj4iI6JIafERERAs5NfiIiIj2SQ0+IiKihfKaXERERAs1P70nwUdERKxkRQtSfBJ8REREl3Syi4iIaKF0souIiGih1OAjIiJaqA01+HF1BxAREdFr+uwhL6Mh6fmSfiLptvL/WwxyzCRJV0m6RdJiSTOGcu4k+IiIiC79eMjLKH0UuML2ZOCKcrvbCuDvbe8GHAScImn3NZ24EQleUp+kBZJulnSxpI0rOOdJkr5SRXwREdEuHsZ/o3QkMKtcnwUctVIs9n22byzXHwFuAbZd04kbkeCB5ban2N4TeAo4eagflNSiucYiImIs9A9jkTRd0vyOZfowLvUi2/dBkciBF67uYEk7AvsA163pxE3sZHcNsBeApB8Ck4ANgTNszyzLHwX+HXg98PeSngTOADYBngReV57rxZIuBV4K/MD2R8byRiIiojcNp+m9zD0zV7Vf0v8AWw+y6+PDiUnSBOAS4G9tP7ym4xuV4CWtBxwGXFoWvcf2A5I2AuZJusT2nygS+c22T5W0AfBr4Fjb8yRtBiwvPz+F4pvQk8Ctks60fU/XNacD0wGO3uIADpoweW3fZkRE1KzK1+RsH7KqfZJ+L2kb2/dJ2gb4wyqOW58iuf+n7e8P5bpNaaLfSNICYD5wN3BuWf5BSTcB11LU5Aeybx/FHwTALsB9tucB2H7Y9opy3xW2H7L9BLAE2KH7wrZn2p5qe2qSe0TEumGsetEDs4ETy/UTgR91HyBJFHnvFtv/PtQTN6UGv9z2lM4CSdOAQ4CDbT8uaS5FUz3AE7b7Bg5l1fMGPNmx3kdz/jwiImItGsPZ5D4LfFfSeykqsG8DkPRi4Ou2DwdeCbwTWFRWdgH+0fac1Z24yQltIvBgmdx3pXh1YDC/pnjWvn/ZRL8pzzbRR0RErGSsBropHyu/bpDyZcDh5frPKCqrw9LkBH8pcLKkhcCtFM30K7H9lKRjgTPLZ/XLKWr+ERERg8pQtWPE9oRByp6k6HC3xuPL5+/dNfzzy2XgmDeNNs6IiGiHMWyiX2sakeAjIiLGkkffea52SfARERFd+lKDj4iIaJ800UdERLRQmugjIiJaKDX4iIiIFsprchERES1UwRC0tUuCj4iI6JIm+oiIiBZKgl/HtOkPa6/nPVR3CJXZ594b6w6hMv+55bS6Q6jMjfM3qDuEymy214frDqEy+y78fN0hNEJ60UdERLRQavAREREtlF70ERERLdTnsZowdu1Jgo+IiOiSZ/AREREtlGfwERERLZRn8BERES3U34Im+nF1BxAREdFrPIz/RkPS8yX9RNJt5f+3WM2x4yX9StKPh3LuJPiIiIgufe4f8jJKHwWusD0ZuKLcXpUZwC1DPXESfERERJd+e8jLKB0JzCrXZwFHDXaQpO2ANwJfH+qJk+AjIiK6DKeJXtJ0SfM7lunDuNSLbN8HUP7/has47kvAR4AhNxmkk11ERESX4dTMbc8EZq5qv6T/AbYeZNfHh3J+SW8C/mD7BknThhpXoxO8pD5gUUfRUbbvqimciIhoiSpfk7N9yKr2Sfq9pG1s3ydpG+APgxz2SuAISYcDGwKbSfqW7Xes7rpNb6JfbntKx3LXUD4kafxajisiIhqsz31DXkZpNnBiuX4i8KPuA2x/zPZ2tncEjgOuXFNyh+Yn+JVI2lHSNZJuLJdXlOXTJF0l6duUtX5J75B0vaQFkr6WxB8REVAMVTvUZZQ+Cxwq6Tbg0HIbSS+WNGc0J250Ez2wkaQF5fqdtt9M0bxxqO0nJE0GvgNMLY85ANjT9p2SdgOOBV5p+2lJZwEnABd0XqDsLDEd4JgtDuAVEyav/buKiIhajdVQtbb/BLxukPJlwOGDlM8F5g7l3E1P8MttT+kqWx/4iqQpQB+wc8e+623fWa6/DtgPmCcJYCMGefbR2XnijO3f0fyhjSIiYo0y2Uxv+jvg98DeFI8gnujY91jHuoBZtj82hrFFREQDZKja3jQRuM92P/BOYFXP1a8Ajpb0QnhmuMAdxijGiIjoYWM1VO3a1MYa/FnAJZLeBlzFc2vtz7C9RNI/AZdLGgc8DZwC/HbMIo2IiJ5UwRC0tWt0grc9YZCy24C9Ooo+VpbPpatjgu2LgIvWXoQREdFEeQYfERHRQm14Bp8EHxER0SU1+IiIiBYaq/fg16Yk+IiIiC6pwUdERLRQetFHRES0UDrZRUREtFCa6CMiIlqol0eoG6ok+IiIiC6pwUdERLRQG57Bqw3fUtpG0vRymtrGy730ptxLb8q9RJXaOJtcG0yvO4AK5V56U+6lN+VeojJJ8BERES2UBB8REdFCSfC9qU3PrXIvvSn30ptyL1GZdLKLiIhoodTgIyIiWigJPiIiooWS4CMiIlooCT4iIqKFMlRtzSQ9f3X7bT8wVrHEyiS9FFhq+0lJ04C9gAts/7neyIZH0ouAfwFebPswSbsDB9s+t+bQRkTS1sABgIF5tn9Xc0ijImlbYAc6fifb/ml9EY2MJAEnAC+xfbqk7YGtbV9fc2jrpPSir5mkOyl+SQnYHniwXN8cuNv2TjWGN2SSHoFVT79ke7MxDKcykhYAU4EdgcuA2cAutg+vM67hkvTfwDeAj9veW9J6wK9sv7zm0IZN0vuAU4ErKf6tvAY43fZ5tQY2QpL+FTgWWAL0lcW2fUR9UY2MpLOBfuC1tneTtAVwue39aw5tnZQafM0GErikc4DZtueU24cBh9QZ23DY3hRA0unA74BvUvzyPQHYtMbQRqvf9gpJbwa+ZPtMSb+qO6gReIHt70r6GEB5T31r+lCP+t/APrb/BCBpS+AXQCMTPHAUxZfGJ+sOpAIH2t534N+I7QclbVB3UOuqPIPvHfsPJHcA2/9NUTNpmtfbPsv2I7Yftn028Na6gxqFpyW9HTgR+HFZtn6N8YzUY2UiNICkg4CH6g1pxJYCj3RsPwLcU1MsVbiDZv6dGszTksbz7N+zrShq9FGD1OB7x/2S/gn4FsU/jncAf6o3pBHpk3QCcCHFfbydZ5sdm+jdwMnAZ2zfKWknip9R03yI4vHCSyX9HNgKOLrekEbsXuA6ST+i+Dt2JHC9pA8B2P73OoMbKklnUsT/OLBA0hXAM7V42x+sK7ZR+DLwA+CFkj5D8Xfsn+oNad2VZ/A9ouxs90ng1WXRT4FPNa2TnaQdgTOAV1L88vo58Le276ovqmqUzxMn2V5YdywjUT5334Xi0cmttp+uOaQRkfTJ1e23/amximU0JJ24uv22Z41VLFWStCvwOoq/Z1fYvqXmkNZZSfARqyFpLnAERWvXAuCPwNW2P1RnXMMl6S2DFD8ELLL9h7GOpyrll64/u5Xa/gYAAAsKSURBVMG/yCRtAjxhu6/cHg88z/bj9UY2PJLGAQtt71l3LFFIE33NJP1fVt/7vFE9aSXtDJwNvMj2npL2Ao6w/c81hzZSE20/XPbc/obtT0pqYg3+vcDBwFXl9jTgWmBnSafb/mZdgQ2VpFOB79r+taTnAf8NTAFWSDre9v/UG+GIXUHRofbRcnsj4HLgFbVFNAK2+yXdJGl723fXHU8kwfeCz9cdQMX+g6KX89cAbC+U9G2gqQl+PUnbAMcAH687mFHoB3az/Xt45r34s4EDKR4H9XyCp3iV7NPl+okUnYS3AnYGZgFNTfAb2h5I7th+VNLGdQY0CtsAiyVdDzw2UNi0ikpbJMHXzPbVZZPcLNvvqDueCmxs+/pivItnrKgrmAqcTvH++89sz5P0EuC2mmMaiR0HknvpD8DOth+Q1JRn8U91NMW/HvhO2ax9S9m/oKkek7Sv7RsBJO0HLK85ppFqRP+HdUWT/1G0hu0+SVtJ2sD2U3XHM0r3l6O/DbwmczRwX70hjZzti4GLO7bvoJmv/V0j6cc8ey9vBX5aPv9tyqh8T0raE/g98BfAhzv2NbXGCzADuFjSsnJ7G4rWisaxfXXdMcSzkuB7x13AzyXN5rlNW4145afDKcBMYFdJ9wJ3Ugx200iSNqR4fr0HsOFAue331BbUyJwCvAV4Vbl9PbCN7ccokmUTzAC+R9Es/0XbdwJIOhxo4uBDAx3TNgB25dk3HH7d4DccDgLOBHajuK/xwGNNHcmy6ZLge8eychlHs0d++63tQ8qa4Tjbj6zxE73tm8CvKZqET6f4stK4135sW9L/o3jmfgzFF69L6o1qeGxfR5EIu8vnAHNW/kTvKzumfcH2wcDNdcdTga8Ax1G0FE0F3gVMrjWidVhek+sxkjYpa1WNJOlu4FLgIuDKJr++BCDpV7b3kbTQ9l6S1gcus/3aumMbivKthuMoBhz6E8XP5cO2d6g1sFEoR+T7JEVrhIGfUYxF38SBoZD0KWAh8P0W/HuZb3vqwL+XsuwXthv1RkBbZKjaHiHpYElLKGuHkvaWdFbNYY3ELhS9mU8B7pT0FUmvWsNnetlAU+mfy+e/EykmnmmKX1MMOvJXtl9l+0yaPbIgFKMk/pGiH8HR5fpFtUY0Oh+iqPE+KelhSY9IerjuoEbo8XLs+QWSPifp74BN6g5qXZUE3zu+RNEM/CcA2zfx7Kh2jWF7ue3v2n4LsA+wGdDkjjczy8FUPkEx1OsS4HP1hjQsb6WY/OcqSf8haWCEsSZ7vu1P276zXP6ZYvbFRrK9qe1xtjewvVm53dRn1u+kyCvvp+hLNIlmdkpthTTR9whJ19k+cKBJuCy7yfbedcc2XJJeQ9EL+DBgHnCR7UY9722bsk/EURRN9a+leG/8B7YvrzWwEZD0eWA+8N2y6GhgD9urHcK2l5VfIifz3I6cjZkPPoPb9KYk+B4h6XvAv1N0UjkI+CAw1fZxtQY2TOX89gsofvnObmp/goGJS1algW83PKOc9+BtwLFN6UsAIOkRimfuomj2HXjUMB54tKm13nKUxBnAdhT/dg4Cftmwn82Ntvct1y+xnVp7D0gv+t5xMsUkLdtSTId5OcVz7KbZ23ZTnx92avKbDKtVTmD0tXJpDNtt/ZnMAPYHrrX9F+VkLU0bMKbzsc9LaosiniMJvkfYvp9mvy/+EdufAz4jaaVmoaZNfdmUGcnWJZJ2Lceh33ew/QMjwTXQE7afkISk55X3uEvdQQ2TV7EeNUqC7xGSvjxI8UPAfNs/Gut4RmDg3fD5tUZRMUmzgBm2/1xubwF8oYED3bTBh4DpwBc6yjqTSWOatLsslbQ58EPgJ5IepBgTo0n2Lnv+C9io4y0AUQzD0MjHJ02XZ/A9QtJMikE8OocSXUzRC/UO239bV2zDIWkf240cVWwwnZ0eV1cWa5+kA4C7bf+u3D6R4t/JXcBp5aOHRis7qE4ELm3BsNVRsyT4HiHpSuAvba8ot9ejeA5/KMWc3bvXGd9QSbqKYizti4ELbS+uOaRRkXQTMM32g+X28ynmg395vZGteyTdCBxSTpDzaor34T9AMWXsbraPrjXAYSqHQT4ZeBmwCDh34N9/RBXSRN87tqXoGfxQub0J8OJyIpon6wtreMpOQltTDIc6U9JmFK/JNXW62C8Av5R0MUVz8DHAZ+oNaZ01vqOWfiwws3z98hJJC2qMa6RmUQykdA3FK6W7U3S4i6hEEnzv+BzF6E9zKZ5bvRr4l/L95UbNc102oX65rM1/BDiVhs4Hb/sCSfMpnu8KeIvtJTWHta4aL2m9spb7Oorn8QOa+Lts94GWIEnnUkwAFFGZJv6jaCXb50qaAxxAkUj+0fZAR5v/XV9kwyNpN4ra1dEUo/JdCPx9rUGNwCDNp+ek+bR23wGulnQ/xXzp1wBIehnPtnw1yTMzxtleITV9gMHoNXkG30MkbQvsQMcXryaNZgUg6VqKX8QXd3xBaRxJF/Hc5tO7mtLRsc3K6Ui3AS4fGESpnFBnQtNek5PUx7NTQwvYCHic9DyPiiTB9whJ/0pR810M9JfFtn1EfVENj6TxwAW2G/s+/wBJizqaT9cDrh8YqSsiognSRN87jgJ2sd2YDnXdyg6BW0raoAWv+KT5NCIaLQm+d9wBrA80NsGXfgv8XNJsnm1+bOLY7QMDd8BzB+9I82lENEISfO94nKIX/RV0JPmmDfFKMQLXMoopIxs7drjt8XXHEBExGnkG3yPKUblWYnvWWMcSERHNlwTfQyRtBGxv+9a6Yxmp8t33wSabaeo44RERjZQm+h4h6a+AzwMbADtJmgKc3qRe9KUPd6xvSDFWeN4fj4gYY6nB9whJN1CMljZ3YCKTzle1mkzS1bZfU3ccERHrktTge8cK2w91vY7VuG9f5WQsA8YBU4GtawonImKdlQTfO26WdDzFeNuTgQ8Cv6g5ppG4gWe/mKygmMrzvbVFExGxjhpXdwDxjA8Ae1C8Ivcd4GGgMUOjStpf0ta2d7L9EuBTwK/LJZOzRESMsTyD70HlkK+b2H54jQf3iLbN1R0R0XSpwfcISd+WtFk5Pexi4FZJjZlFjlXM1W37ExQzskVExBhKgu8du5c19qOAOcD2wDvrDWlYxpeTskAxV/eVHfvS1yMiYozlF2/vWF/S+hQJ/iu2n5bUpOcnbZurOyKi0ZLge8fXKHqc3wT8VNIOFB3tGsH2Z8px9Afm6h74cjKO4ll8RESMoXSy62GS1rOdUeAiImLY8gy+R0iaUXayk6Rzy17pGb89IiJGJAm+d7yn7GT3l8BWwLuBz9YbUkRENFUSfO8YGKP2cOAbtm/qKIuIiBiWJPjecYOkyykS/GWSNgX6a44pIiIaKp3seoSkcRSjvt1h+8+StgS2tb2w5tAiIqKB8ppcj7DdL+lOYGdJG9YdT0RENFsSfI+Q9D5gBrAdsAA4CPgl6UkfEREjkGfwvWMGsD/wW9t/AewD/LHekCIioqmS4HvHE7afAJD0PNu/BnapOaaIiGioNNH3jqWSNgd+CPxE0oPAsppjioiIhkov+h4k6TXAROBS20/VHU9ERDRPEnzNyh7zJ1PMmb4IODfjz0dExGglwddM0kXA0xTTqx5G0cluRr1RRURE0yXB10zSItsvL9fXA663vW/NYUVERMOlF339nh5YSdN8RERUJTX4mknqAx4b2AQ2Ah4v1217s7pii4iI5kqCj4iIaKE00UdERLRQEnxEREQLJcFHRES0UBJ8REREC/1/Z5hEQJoK+aQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sbs.heatmap(cor);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation - get_dummies() : We know that Algorithms cannot handle str or text data. So each variable should be converted into a integer. Before that lets see what kind of categorical variables exists\n",
    "1. __Nominal Variable__: These variables have values(string values) which are not related to each other. Say if we denote Men=1 and Women=2 and Children=3, then there is no relation like 1+2 = 3 or order like 1<2<3 (which would mean men<women<children) . And we want the algorithm to make sure it does not assume this kind of relation. So we cannot denote by integers. So we use what is called as __one hot encoding__ in case of Nominal Variable.\n",
    "2. __Ordinal Variable__: These variables have a order/relation amoung the values. Say ex. high, medium, low if we denote by 1, 2, 3. Then for sure hihg(1) > medium(2) > low(3).  We use __Ordinal Encoding__ to convert these values. Label encoding assigns each unique value to a different integer\n",
    "<img src=\"images/image58.png\" align = \"middle\" style=\"width:500px; height:200px;\"/>   \n",
    "3. __One hot Encoding__: Here we create one columnn for each of the value in the Nominal Variable. One-hot encoding creates new columns indicating the presence (or absence) of each possible value in the original data. We use OHE from sklearn to get teh job done.\n",
    "    * We set handle_unknown='ignore' to avoid errors when the validation data contains classes that aren't represented in the training data, and\n",
    "    * setting sparse=False ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix).\n",
    "4. __get_dummies__ : Also does the same job of encoding but OHE has better parameters and perfor better in production.\n",
    "5. __Label Encoder__ : Encode __target labels__ with value between 0 and n_classes-1. This transformer should be used to encode target values, i.e. y, and not the input X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amsterdam', 'paris', 'tokyo']\n",
      "[2 2 1]\n",
      "['tokyo', 'tokyo', 'paris']\n"
     ]
    }
   ],
   "source": [
    "# Label Encoder Ex: say we have a string labels in our target variable 'y'\n",
    "y = [\"paris\", \"paris\", \"tokyo\", \"amsterdam\"] # y has to be a series only or list ..dataframe is not allowed\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "print(list(le.classes_)) # Holds the label for each class. Each value will be encoded by its position 0=amsterdam to n-1=tokyo\n",
    "print(le.transform([\"tokyo\", \"tokyo\", \"paris\"]))\n",
    "print(list(le.inverse_transform([2, 2, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Veena</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amit</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seema</td>\n",
       "      <td>40</td>\n",
       "      <td>female</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age     sex  rating\n",
       "0  Veena   32  female     Low\n",
       "1   amit   35    male    High\n",
       "2  seema   40  female  Medium"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct={\n",
    "    'name':['Veena', 'amit', 'seema'],\n",
    "    'age': [32, 35, 40],\n",
    "    'sex': ['female', 'male', 'female'],\n",
    "    'rating': ['Low', 'High', 'Medium']\n",
    "}\n",
    "df = pd.DataFrame(dct)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'sex', 'rating'], dtype='object')"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in big df's use this to find the coumns which has text fields.\n",
    "s = (df.dtypes == 'object')\n",
    "s[s].index  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between LabelEncoder() and OridinalEncoder()\n",
    "both have the same functionality. A bit difference is the idea behind. OrdinalEncoder is for converting features, while LabelEncoder is for converting target variable.\n",
    "\n",
    "That's why OrdinalEncoder can fit data that has the shape of (n_samples, n_features) while LabelEncoder can only fit data that has the shape of (n_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "[array(['High', 'Low', 'Medium'], dtype=object)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>rating</th>\n",
       "      <th>Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Veena</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amit</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seema</td>\n",
       "      <td>40</td>\n",
       "      <td>female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age     sex  rating  Encoded\n",
       "0  Veena   32  female     Low      1.0\n",
       "1   amit   35    male    High      0.0\n",
       "2  seema   40  female  Medium      2.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordinal encoder\n",
    "print(type(df[['rating']]))\n",
    "print(type(df['rating']))\n",
    "X = df[['rating']] # df[[]] gives df, \n",
    "# X = df['rating'] # df[] gives series is not allowed in ordinalencoder.\n",
    "encoder = OrdinalEncoder()\n",
    "df['Encoded'] = encoder.fit_transform(X)\n",
    "print(encoder.categories_)\n",
    "df # here ordinal coding is done alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['Low', 'Medium', 'High'], dtype=object), array(['male', 'female'], dtype=object)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>rating</th>\n",
       "      <th>Encoded</th>\n",
       "      <th>En_rating</th>\n",
       "      <th>En_sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Veena</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amit</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seema</td>\n",
       "      <td>40</td>\n",
       "      <td>female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age     sex  rating  Encoded  En_rating  En_sex\n",
       "0  Veena   32  female     Low      1.0          0       1\n",
       "1   amit   35    male    High      0.0          2       0\n",
       "2  seema   40  female  Medium      2.0          1       1"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OrdinalEncoder with proper order.\n",
    "X = df[['rating', 'sex']] # df[[]] gives df, \n",
    "# X = df['rating'] # df[] gives series thats not allowed in ordinalencoder.\n",
    "categories = [['Low', 'Medium', 'High'], ['male', 'female']]\n",
    "encoder = OrdinalEncoder(dtype=int, categories=categories)#Define all unique categories in the order you want them to be encoded\n",
    "df[['En_rating', 'En_sex']] = encoder.fit_transform(X)\n",
    "print(encoder.categories_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]] (3, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>rating</th>\n",
       "      <th>Encoded</th>\n",
       "      <th>En_rating</th>\n",
       "      <th>En_sex</th>\n",
       "      <th>Is_F</th>\n",
       "      <th>Is_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Veena</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amit</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seema</td>\n",
       "      <td>40</td>\n",
       "      <td>female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age     sex  rating  Encoded  En_rating  En_sex  Is_F  Is_M\n",
       "0  Veena   32  female     Low      1.0          0       1   1.0   0.0\n",
       "1   amit   35    male    High      0.0          2       0   0.0   1.0\n",
       "2  seema   40  female  Medium      2.0          1       1   1.0   0.0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding a Nominal varible using ONE HOT ENCODING.\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "df[['Is_F', 'Is_M']] = OH_encoder.fit_transform(df[['sex']]) # This gives a ndarray of (rows,features) with two columns one for male one for female\n",
    "print(OH, OH.shape) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['female', 'male'], dtype=object), array(['High', 'Low', 'Medium'], dtype=object)]\n",
      "[[1. 0. 0. 1. 0.]\n",
      " [0. 1. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 1.]]\n",
      "['x0_female' 'x0_male' 'x1_High' 'x1_Low' 'x1_Medium']\n",
      "['sex_female' 'sex_male' 'rating_High' 'rating_Low' 'rating_Medium']\n"
     ]
    }
   ],
   "source": [
    "# OHE with multiple columns encoding\n",
    "X = df[['sex', 'rating']]\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH = OH_encoder.fit_transform(X)\n",
    "print(OH_encoder.categories_)\n",
    "print(OH) # each category will be a column. So 1st col is female, next male...per this OH_encoder.categories_\n",
    "print(OH_encoder.get_feature_names()) # Return feature names for output features.\n",
    "print(OH_encoder.get_feature_names(['sex', 'rating'])) # Return feature names for output features. This uses your list as prefix\n",
    "# rather than using x0, x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['female', 'male'], dtype=object), array(['High', 'Low', 'Medium'], dtype=object)]\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "['sex_male' 'rating_Low' 'rating_Medium']\n"
     ]
    }
   ],
   "source": [
    "# OHE has options to drop categoris in a feature check the documentation.\n",
    "# see how it drops the first category in each feature (first in alphabetically) per OH_encoder.categories_\n",
    "X = df[['sex', 'rating']]\n",
    "OH_encoder = OneHotEncoder(handle_unknown='error', sparse=False, drop='first') # handle_unknown='error' this time \n",
    "# this below 'if_binary' will drop the first category in each feature with two categories\n",
    "# OH_encoder = OneHotEncoder(handle_unknown='error', sparse=False, drop='if_binary')\n",
    "OH = OH_encoder.fit_transform(X)\n",
    "print(OH_encoder.categories_)\n",
    "print(OH)\n",
    "print(OH_encoder.get_feature_names(['sex', 'rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sex_female  sex_male  rating_High  rating_Low  rating_Medium\n",
      "0           1         0            0           1              0\n",
      "1           0         1            1           0              0\n",
      "2           1         0            0           0              1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>rating</th>\n",
       "      <th>Encoded</th>\n",
       "      <th>En_rating</th>\n",
       "      <th>En_sex</th>\n",
       "      <th>Is_F</th>\n",
       "      <th>Is_M</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>rating_High</th>\n",
       "      <th>rating_Low</th>\n",
       "      <th>rating_Medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Veena</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amit</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seema</td>\n",
       "      <td>40</td>\n",
       "      <td>female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age     sex  rating  Encoded  En_rating  En_sex  Is_F  Is_M  \\\n",
       "0  Veena   32  female     Low      1.0          0       1   1.0   0.0   \n",
       "1   amit   35    male    High      0.0          2       0   0.0   1.0   \n",
       "2  seema   40  female  Medium      2.0          1       1   1.0   0.0   \n",
       "\n",
       "   sex_female  sex_male  rating_High  rating_Low  rating_Medium  \n",
       "0           1         0            0           1              0  \n",
       "1           0         1            1           0              0  \n",
       "2           1         0            0           0              1  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummies = pd.get_dummies(df[['sex', 'rating']])\n",
    "# print(dummies) # then add this df to the original df\n",
    "# df = pd.concat([df, dummies], axis='columns')\n",
    "df #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>rating</th>\n",
       "      <th>Encoded</th>\n",
       "      <th>En_rating</th>\n",
       "      <th>En_sex</th>\n",
       "      <th>Is_F</th>\n",
       "      <th>Is_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Veena</td>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amit</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seema</td>\n",
       "      <td>40</td>\n",
       "      <td>female</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age     sex  rating  Encoded  En_rating  En_sex  Is_F  Is_M\n",
       "0  Veena   32  female     Low      1.0          0       1   1.0   0.0\n",
       "1   amit   35    male    High      0.0          2       0   0.0   1.0\n",
       "2  seema   40  female  Medium      2.0          1       1   1.0   0.0"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that its very important in ML Algorithms to not have duplicate variables conveying the same information\n",
    "# That will result into multicollinearity issue. So two of the variables out of the three 'se', 'female', 'male'\n",
    "# convey the same information. We cannot keep 'sex' as its str and so we can delete 'sex' and 'male'/'female'\n",
    "# df.drop(columns = ['sex_female', 'sex_male', 'rating_High', 'rating_Low', 'rating_Medium'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_boston(return_X_y=True) # boston housing price dataset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "regression = LinearRegression()\n",
    "regression.fit(X_train, y_train)\n",
    "pred = regression.predict(X_test)\n",
    "RMSE = sqrt(mean_squared_error(y_test, pred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor\n",
    "With the same X,y split we can see that DCRegressor always did a better job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCreg = tree.DecisionTreeRegressor(random_state=0)\n",
    "DCreg.fit(X_train, y_train)\n",
    "pred = DCreg.predict(X_test)\n",
    "RMSE = sqrt(mean_squared_error(y_test, pred))\n",
    "RMSE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Modelling:\n",
    "1. A probabilistic method or model is based on the theory of probability or the fact that randomness plays a role in predicting future events.\n",
    "2. Read notes on Probability and Statistics before proceding further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifiers:\n",
    "1. In machine learning, naïve Bayes classifiers are a family of simple __\"probabilistic classifiers\"__ based on applying Bayes' theorem with strong (naïve) __independence__ assumptions between the features. They are among the simplest Bayesian network models.\n",
    "2. Naive Bayes calssifier uses Bayes Theorem:\n",
    "    __P(A|B) = $\\frac{P(B|A)*P(A)}{P(B)}$__\n",
    "3. Different Naive Bayes' classifier:   \n",
    "   * __Multi-variate Bernoulli Naive Bayes__: The binomial model is useful if your feature vectors are binary (i.e., 0s and 1s). One application would be text classification with a bag of words model where the 0s 1s are \"word occurs in the document\" and \"word does not occur in the document\".\n",
    "   * __Multinomial Naive Bayes__ The multinomial naive Bayes model is typically used for discrete counts. E.g., if we have a text classification problem, we can take the idea of bernoulli trials one step further and instead of \"word occurs in the document\" we have \"count how often word occurs in the document\", you can think of it as \"number of times outcome number x_i is observed over the n trials\"\n",
    "   * __Gaussian Naive Bayes__ Here, we assume that the features follow a normal distribution. Instead of discrete counts, we have continuous features (e.g., the popular Iris dataset where the features are sepal width, petal width, sepal length, petal length).\n",
    "4. https://www.youtube.com/watch?v=Q8l0Vip5YUw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo add your Titanic notebook link here  as an example to Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction:\n",
    "1. The sklearn.feature_extraction module can be used to extract features in a format supported by machine learning algorithms from datasets consisting of formats such as text and image.\n",
    "2. https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Imputer: \n",
    "1. we use SimpleImputer to replace missing values with the some aggregate value along each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct={\n",
    "    'name':['Veena', 'amit', 'seema', 'ranju'],\n",
    "    'age': [32, 35, 40, 50],\n",
    "    'sex': ['female', 'male', 'female', 'male'],\n",
    "    'height': [np.nan, 5.6, 5.6, 5.0],\n",
    "    'weight': [116, 160, 134, np.nan]\n",
    "}\n",
    "df = pd.DataFrame(dct)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit_transform(df[['height']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='constant')\n",
    "imp_mean.fit_transform(df[['height']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColumnTransformer:\n",
    "1. Similar to how a pipeline bundles together preprocessing and modeling steps, we use the ColumnTransformer class to bundle together different preprocessing steps. The code below:\n",
    "    * imputes missing values in numerical data, and\n",
    "    * imputes missing values and applies a one-hot encoding to categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this applies simpleimputer to columns 1,3,4 and OHE to 2\n",
    "t = [('num', SimpleImputer(strategy='mean'), [1,3,4]), ('cat', OneHotEncoder(), [2])]\n",
    "# Any columns not specified in the list of transformers are dropped from the dataset by default; \n",
    "# this can be changed by setting the remainder argument.\n",
    "transformer = ColumnTransformer(t, remainder='passthrough')\n",
    "#The order of the columns in the transformed feature matrix follows the order of how the columns are \n",
    "# specified in the transformers list. \n",
    "t_df = transformer.fit_transform(df) # this gives a array\n",
    "# https://stackoverflow.com/questions/54592115/appending-the-columntransformer-result-to-the-original-data-within-a-pipeline\n",
    "pd.DataFrame(t_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline :\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use titanic data to show piplelining\n",
    "df = tnic_df\n",
    "print(df.columns)\n",
    "df = df.drop(['PassengerId', 'Parch', 'Ticket', 'Fare'], axis='columns') # lets take few columns for analysis\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sepearte Target\n",
    "y = df['Survived']\n",
    "X = df.drop(['Survived'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into training and testing data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate the categorical and numerical data\n",
    "categorical_cols = [cname for cname in X_train.columns if X_train[cname].dtype =='object']\n",
    "numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']]\n",
    "print(categorical_cols, numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define Preprocessing Step\n",
    "# impute missing values in numerical and  impute+OHE in categorical data\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle then into Preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2:Define the Model\n",
    "model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: Create and Evaluvate the Pipeline\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of test data, get predictions\n",
    "# see how all the preprocessing is done in a simple way using pieline\n",
    "preds = my_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "score = accuracy_score(y_test, preds)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train[['Name', 'Sex', 'Cabin', 'Embarked']]\n",
    "print(data.shape)\n",
    "# print(init.head(5))\n",
    "print(data['Embarked'].isnull().value_counts())\n",
    "print('***************************************')\n",
    "imp = SimpleImputer(strategy='most_frequent')\n",
    "imp_data = imp.fit_transform(data)\n",
    "print(imp_data.shape)\n",
    "# imp_data[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHE = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OHE_data = OHE.fit_transform(imp_data)\n",
    "OHE_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets include the name column\n",
    "data = X_train[['Name', 'Sex', 'Cabin', 'Embarked']]\n",
    "print(\"Before\", data.shape)\n",
    "imp_data = imp.fit_transform(data)\n",
    "OHE = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OHE_data = OHE.fit_transform(imp_data)\n",
    "print(OHE_data.shape) # see how 700ish columns are added each name is OHencoded. Which is not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train[['Sex', 'Cabin', 'Embarked']]\n",
    "print(\"Before\", data.shape)\n",
    "imp_data = imp.fit_transform(data)\n",
    "OHE = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OHE_data = OHE.fit_transform(imp_data)\n",
    "print(OHE_data.shape) # 2(sex)+106(cabin)+3(Embarked) = 111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning -  Bagging  and Boosting:\n",
    "1. One of the big disadvantage of decision tree classfier is that these kind of classifier works great with the data (training data) used to create them, but they are not flexible when it comes to classifying new samples. So we go with Ensemble Classifier.\n",
    "3. Ensemble Learning: Here we use multiple learning algorithm at the same time to increase accuracy. We can also use same algorithm different many times to get a ensemble model (Random forest classification). Ensemble method gives better accuracy, Higher consistncy(avoids overfitting) and also reduces bias-variace error. You decide on using the ensemble model if you find that the results of ensemble model(compared to single model) is worth the extra training. We can use ensemble model on classification and regression model.\n",
    "<img src=\"images/image60.png\" align = \"middle\" style=\"width:400px; height:150px;\"/>\n",
    "2. BootStrap aggregating or Bagging: It is one of the ensemble method. Here Multiple  models of learning algorithms are trained with subsets of DataSet Randomly picked  from the Training dataset.\n",
    "<img src=\"images/image61.png\" align = \"middle\" style=\"width600px; height:250px;\"/>\n",
    "3. Boosting: The approach is same as Bagging with little difference. In here we train a model with subset of training dataset and test the model using testing dataset. Then based on the results we will train the model again with subset of training dataset , but this time it includes each datapoint of the testing dataset with wrong predictions.\n",
    "<img src=\"images/image62.png\" align = \"middle\" style=\"width600px; height:250px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier:\n",
    "1. This is one of the Ensemble Classifier. Random forest combines the simplicity of decision tree with flexibity that results in vast improvement in accuracy.\n",
    "2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
